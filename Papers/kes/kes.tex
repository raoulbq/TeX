\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem*{theorem*}{Theorem}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{color}
\definecolor{linkcol}{rgb}{0,0,0.4}
\definecolor{citecol}{rgb}{0.5,0,0}
\usepackage[pagebackref,hyperindex=true]{hyperref}
\hypersetup{colorlinks=true,linkcolor=linkcol,citecolor=citecol,urlcolor=linkcol}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{footnote}
\usepackage{placeins}
\usepackage{subfloat}
\usepackage{array}
\usepackage{ragged2e}
\newcolumntype{x}[1]{>{\RaggedRight\hspace{0pt}}p{#1}}

\include{header_math}

\synctex=1
\parindent 0pt

%opening
\title{Exhaustive search for higher-order Kronrod-Patterson Extensions}
\author{R. Bourquin}

\begin{document}

\maketitle

\section{Kronrod-Patterson Extensions}

\subsection{Mathematical principles}

The $n$ nodes $\{\gamma_i\}_{i=1}^{n}$ of any Gauss quadrature rule for a
given density distribution $\omega(t)$ can be found as the roots of a
polynomial $P_n$ of degree $n$. The existence of corresponding weights
$\{\omega_i\}_{i=1}^{n}$ is the ensured by the following theorem from
\cite{mehrotra-papp} originally stated by Kronrod in \cite{kronrod}:

\begin{theorem}
  \label{th:existence_weights}
  For every probability density function $\omega(t)$ and every set
  $\{\gamma_i\}_{i=1}^{n} \subset \mathbb{R}$ of $n$ nodes there exists
  a set of unique weights $\{\omega_i\}_{i=1}^{n}$ such that the quadrature
  Formula for integration with respect to $\omega(t)$ has a polynomial
  degree of exactness of at least $n-1$. These weights are the unique solution
  of the linear system of equations:
  \begin{equation}
    \label{eq:linsys_for_weights}
    \sum_{i=1}^n \omega_i \gamma_i^k = \int_{\Omega} t^k \omega(t) \di{t}
  \end{equation}
  for $k = 0, \ldots, n-1$.
\end{theorem}

Next we need another theorem giving the conditions under which we can
extend a given set of nodes by a bunch of new nodes.

\begin{theorem}
  \label{th:defining_extension}
  Let $\omega(t)$ be the probability density function of a distribution
  supported on $\Omega \subseteq \mathbb{R}$ with finite moments. Let $P_n(t)$
  be a univariate polynomial of degree $n$ with $n$ distinct real roots,
  and suppose that there exists a polynomial $E_p$ of degree $p$ satisfying:
  \begin{equation}
    \label{eq:defining_extension}
    \int_\Omega P_n(t) E_p(t) t^i \omega(t) \di(t) = 0
  \end{equation}
  for all $i = 0, \ldots, p-1$. Assume further that the roots of $E_p$
  are all real and of multiplicity one, and distinct from
  those of $P_n$. Then there exists a quadrature formula supported on the
  roots of $P_n E_p$, whose degree of polynomial exactness is at least
  $n + 2p -1$.
\end{theorem}

A simple proof of this theorem is given in the original article \cite{mehrotra-papp}.

\marginpar{
\cite{laurie}
\cite{patterson1968}
}


\FloatBarrier
\subsection{Algorithmic procedure}

The main algorithm consists of three steps building upon each other.

\begin{itemize}
  \item Given the polynomial $P_n(t)$ of degree $n$ defining the rule
    with nodes $\{\gamma_i\}_{i=1}^{n}$ and weights $\{\omega_i\}_{i=1}^{n}$.
  \item Choose $p \geq 1$.
    Find a new polynomial $E_p(t)$ with $\deg E_p = p$ such that:
    \begin{equation}
      \int_{\Omega} P_n(t) \, E_p(t) \, t^i \, \omega(t) \, \di{t} = 0
    \end{equation}
    for all $i = 0, \ldots, p-1$, see theorem \ref{th:defining_extension}.
    We require that $E_p$ is monic and obtain a square linear system.
    If this system is solvable, then the extension $E_p$ exists.
    \marginpar{Go into details with "exists`` and the like}
    Otherwise we can \emph{not} extend the given $n$ point rule by
    adding exactly $p$ new nodes to a $n+p$ point rule.
  \item Compute the roots $\{\gamma^\prime_i\}_{i=1}^{p}$ of $E_p$.
    If not all roots lie within the region $\Omega$ then this extension
    does not construct a valid quadrature rule.
  \item Compute the weights $\{\omega^\prime_i\}_{i=1}^{n+p}$ for the new
    quadrature rule. It is important to note that the weights of the old
    unextended rule usually will change too. Hence it is not possible to
    compute only new weights $\{\omega^\prime_i\}_{i=n+1}^{p}$ but we must
    recompute all $n+p$ weights at once. For the unified final set of nodes:
    \begin{equation}
      \{\gamma_i\}_{i=1}^{n+p} := \{\gamma_i\}_{i=1}^{n} \cup \{\gamma^\prime_i\}_{i=1}^{p}
    \end{equation}
    we compute the weights by formula \eqref{eq:linsys_for_weights}:
    \begin{equation}
      \sum_{i=1}^{n+p} \omega^\prime_i t_i^k = \int_{\Omega} t^k \omega(t) \di(t)
    \end{equation}
    for all $k=0, \ldots, n+p-1$. This is again a linear system
    of equations. The right hand side we have the moments of the
    distribution $\omega(t)$. It can happen that some of the weights
    are negative. This might affect the overall stability on the quadrature
    rule but is tolerated for now.
\end{itemize}

The steps for computing a single extension $E_p$ of $P_n$ are shown in pseudo-code
in algorithm \eqref{alg:find_extension}. Another version computing iteratively
multiple nested extensions is shown in \eqref{alg:find_multiextension}.


\subsection{Finding extensions}

The general degree $p$ monic polynomial $E_p$ with symbolic coefficients is
written as:

\begin{equation}
  E_p(t) := t^p + \sum_{k=0}^{p-1} a_k t^k
\end{equation}

and we need to determine the set of coefficients $\{a_i\}_{i=0}^{p-1}$.
Applying next the theorem \ref{th:defining_extension} from above and starting
with the integral formulation \eqref{eq:defining_extension} we find step by step:

\begin{equation}
\begin{split}
  \int_\Omega P_n(t) E_p(t) t^i \omega(t) \,\di(t)
  & = \int_\Omega P_n(t) \left(t^p + \sum_{k=0}^{p-1} a_k t^k\right) t^i \omega(t) \,\di(t) \\
  & = \int_\Omega P_n(t) t^p t^i \omega(t) \,\di(t)
    + \int_\Omega P_n(t) \left(\sum_{k=0}^{p-1} a_k t^k\right) t^i \omega(t) \,\di(t) \\
  & = \sum_{k=0}^{p-1} a_k \int_\Omega P_n(t) t^k t^i \omega(t) \,\di(t)
    + \int_\Omega P_n(t) t^p t^i \omega(t) \,\di(t) \,.
\end{split}
\end{equation}

Now it is time to remember that this integral should equate zero. Hence we find
from the last line the following linear system $\mat{A} \vec{a} = \vec{r}$
for the unknown coefficients $\vec{a} := \{a_i\}_{i=0}^{p-1}$ as:

\begin{equation}
  \label{eq:linsys_for_extension}
  \begin{bmatrix}
    {}     & \vdots                                        & {} \\
    \hdots & \int_\Omega P_n(t) t^k t^i \omega(t) \,\di(t) & \hdots \\
    {}     & \vdots                                        & {} \\
  \end{bmatrix}
  \begin{pmatrix}
    a_0 \\
    \vdots \\
    a_k \\
    \vdots \\
    a_{p-1}
  \end{pmatrix}
  =
  \begin{pmatrix}
  \vdots \\
  - \int_\Omega P_n(t) t^p t^i \omega(t) \,\di(t) \\
  \vdots \\
  \end{pmatrix}
\end{equation}

where the first index $i = 0, \ldots, p-1$ runs along a column
and the second index $k = 0, \ldots, p-1$ runs along any row
of the $p \times p$ matrix. On the right hand side we have essentially
a bunch of moments of the probability density distribution $\omega(t)$.
Provided a closed form for the moment generating function exists,
this vector can be computed very easily.


\subsection{Rational moments}

A limitation of our current implementation (see section \ref{sec:implementation_aspects})
is that we can work only with distributions $\omega(t)$ that have rational moments.
However, in case of the most important distributions used as weight functions for
defining the Legendre, Chebyshev, Laguerre and Hermite orthogonal polynomials this
is a well known truth and summarized in table \ref{eq:orthogonal_polynomials} below.

\begin{savenotes}
\begin{table}[h!]
  \centering
  \begin{tabular}{|l|l|l|l|}
    \hline
    Distribution  & $\omega(t)$    & $t \in \Omega$      & Polynomial $P_n(t)$ \\
    \hline
    Uniform       & $1$            & $[-1, 1]$           & Legendre $P_n$ \\
    Chebyshev $T$ & $\frac{1}{\sqrt{1-x^2}}$ & $[-1, 1]$ & Chebyshev $T_n$ \\
    Chebyshev $U$\footnote{The Wigner semicircle distribution up to normalization.}
                  & $\sqrt{1-x^2}$ & $[-1, 1]$           & Chebyshev $U_n$ \\
    Exponential   & $\exp(-t)$     & $[0, \infty]$       & Laguerre $L_n$ \\
    Normal        & $\exp(-t^2)$   & $[-\infty, \infty]$ & Hermite $H_n$ \\
    Normal        & $\exp\!\left(-\frac{t^2}{2}\right)$
                  & $[-\infty, \infty]$                  & Hermite $H_n$ \\
    \hline
  \end{tabular}
  \caption{\label{eq:orthogonal_polynomials}
  Domain and weight function of classical orthogonal polynomials.}
\end{table}
\end{savenotes}

By explicit computation one can easily show that the following closed
form expressions for the moments hold:

\begin{savenotes}
\begin{align}
  \int_{-1}^{1} t^n \di{t} & = \frac{1 + (-1)^n}{n + 1} =
  \begin{cases}
    \frac{2}{n + 1} & \quad n \quad \mathrm{even} \\
    0               & \quad n \quad \mathrm{odd}
  \end{cases} \label{eq:moments_legendre} \\
  \int_{-1}^{1} t^n \frac{1}{\sqrt{1-t^2}} \di{t} & =
  \begin{cases}
    \frac{2 \sqrt{\pi}}{n} \frac{\Gamma\left(\frac{n+1}{2}\right)}
                                {\Gamma\left(\frac{n}{2}\right)} & \quad n \quad \mathrm{even}
                                                                   \footnote{For $n=0$ one takes the limes
                                                                   or replaces $n\Gamma\left(\frac{n}{2}\right)$
                                                                   by $2\Gamma\left(\frac{n}{2}+1\right)$} \\
    0                                                            & \quad n \quad \mathrm{odd}
  \end{cases} \label{eq:moments_chebyshevt} \\
  \int_{-1}^{1} t^n \sqrt{1-t^2} \di{t} & =
    \begin{cases}
      \frac{\sqrt{\pi}}{2} \frac{\Gamma\left(\frac{n+1}{2}\right)}
                                {\Gamma\left(2+\frac{n}{2}\right)} & \quad n \quad \mathrm{even} \\
      0                                                            & \quad n \quad \mathrm{odd}
  \end{cases} \label{eq:moments_chebyshevu} \\
  \int_{0}^{\infty} t^n \exp(-t) \di{t} & = \Gamma\left(n + 1\right) \label{eq:moments_laguerre} \\
  \int_{-\infty}^{\infty} t^{n} \exp\left(-\frac{t^{2}}{2}\right) \di{t} & =
  \begin{cases}
    2^{\frac{n}{2}} \sqrt{2} \,\Gamma\left(\frac{n+1}{2}\right) & \quad n \quad \mathrm{even} \\
    0                                               & \quad n \quad \mathrm{odd}
  \end{cases} \label{eq:moments_hermite_pro} \\
  \int_{-\infty}^{\infty} t^n \exp(-t^2) \di{t} & =
  \begin{cases}
    \Gamma\left(\frac{n + 1}{2}\right) & \quad n \quad \mathrm{even} \\
    0                                  & \quad n \quad \mathrm{odd}
  \end{cases} \label{eq:moments_hermite_phy}
\end{align}
\end{savenotes}

In the case of the Hermite polynomial we find that for even $n$:

\begin{equation}
  \Gamma\left(\frac{n + 1}{2}\right) =
  \frac{\sqrt{\pi}}{2^{\frac{n}{2}}} \prod_{i=1}^{\frac{n}{2}} (2 i - 1)
\end{equation}

The constant transcendental factor $\sqrt{\pi}$ will luckily drop out in our final equations
because it is contained in every entry of the matrix $\mat{A}$ as well as the right hand
side $\vec{r}$. This is a trick that allows us to omit any constant irrational or transcendental
factor.

\begin{algorithm}
  \caption{Compute an extension $E_p$ of degree $p$ over $P_n$}
  \label{alg:find_extension}
  \begin{algorithmic}
    \Procedure{ComputeExtension}{$P_n(x)$, $p$}
    \State $\mat{A} := \textsc{BuildMatrix}(P_n, p)$
    \Comment Construct the linear system as in \eqref{eq:linsys_for_extension}
    \State $\vec{r} := \textsc{BuildRHS}(P_n, p)$
    \State $\{a_i\}_{i=0}^{p-1} := \textsc{SolveLinear}(\mat{A}, \vec{r})$
    \If{$\exists i: a_i \neq 0$}
    \Comment Check if system is solvable
      \State $E_p = t^p + \sum_{i=0}^{p-1} a_i t^i$
    \Else
      \State $E_p \equiv 0$
    \EndIf \\
    \Return $E_p$
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}
  \caption{Compute a tower of $k$ extensions
           $P_n \subset E_{p_1} \subset E_{p_2} \subset \ldots \subset E_{p_k}$ }
  \label{alg:find_multiextension}
  \begin{algorithmic}
    \Procedure{ComputeExtensionTower}{$P_n(x)$, $[p_1, \ldots, p_k]$}
    \State $P_0 := P_n$
    \For{$i = 1, \ldots, k$}
      \State $E_i := \textsc{ComputeExtension}(P_{i-1}, p_i)$
      \State $P_i := P_{i-1} \cdot E_i$
    \EndFor \\
    \Return $E := \prod_{i=1}^k E_i$
    \EndProcedure
  \end{algorithmic}
\end{algorithm}


\subsection{Computing nodes}

Computing the nodes amounts to finding all roots of a possibly high degree
polynomial. In classical numerics there are various stability issues related
to this task and a general solution is often not possible. Using arbitrary precision
ball arithmetic as defined by van der Hoeven in \cite{vdH:ball:greifswald, vdH:ball}
we can avoid almost all of these issues by just increasing the precision
whenever necessary. By making use of the rigorous error bounds inherent in any ball
we can easily decide when we have to increase precision to obtain fully accurate
results in the end.

The following routine is shown here just for the sake of completeness. Internally
we pass on by calling a suitable function from the \texttt{arb} library introduced below.
The function called uses the Durand-Kerner method according to the library documentation.
An assumption required for this method to work is that the polynomial is square-free
which is necessary for all valid extensions anyway.

\begin{algorithm}
  \caption{Compute the nodes up to a given precision $b_{\gamma}$}
  \begin{algorithmic}
    \Procedure{ComputeNodes}{$P_n(x)$, $b_{\gamma}$}
    \State $\{\gamma_i\}_{i=1}^{n} := \textsc{FindAllRoots}(P_n(x), b_{\gamma})$ \\
    \Return $\{\gamma_i\}_{i=1}^{n}$
    \EndProcedure
  \end{algorithmic}
\end{algorithm}


\subsection{Computing weights}

In this section we will look at the computation of weights in more detail.
Although not really complicated a systematic understanding is inevitable for
a correct implementation.

Given a set of nodes $\{\gamma_i\}_{i=1}^{n} \in \mathbb{R}$ we want
to find the corresponding weights $\vec{\omega} := \{\omega_i\}_{i=1}^{n} \in \mathbb{R}$.
We start with the equation \eqref{eq:linsys_for_weights} shown above:

\begin{equation}
  \sum_{i=1}^{n} \omega_i \gamma_i^k = \int_{\Omega} t^k \omega(t) \di{t} \,
  \quad k = 0, \ldots, n-1
\end{equation}

This yields the following inhomogeneous linear system $\mat{A} \vec{\omega} = \vec{r}$:

\begin{equation}
  \label{eq:linsys_for_weights_matrix}
  \begin{bmatrix}
    \gamma_1^0     & \hdots & \gamma_i^0     & \hdots & \gamma_n^0 \\
    \vdots         & {}     & \vdots         & {}     & \vdots \\
    \gamma_1^k     & \hdots & \gamma_i^k     & \hdots & \gamma_n^k \\
    \vdots         & {}     & \vdots         & {}     & \vdots \\
    \gamma_1^{n-1} & \hdots & \gamma_i^{n-1} & \hdots & \gamma_n^{n-1}
  \end{bmatrix}
  \begin{pmatrix}
    \omega_1 \\
    \vdots \\
    \omega_i \\
    \vdots \\
    \omega_n
  \end{pmatrix}
  =
  \begin{pmatrix}
  \int_{\Omega} t^0 \omega(t) \,\di{t} \\
  \vdots \\
  \int_{\Omega} t^k \omega(t) \,\di{t} \\
  \vdots \\
  \int_{\Omega} t^{n-1} \omega(t) \,\di{t}
  \end{pmatrix}
\end{equation}

where $k = 0, \ldots, n-1$ is the row index and $i = 1, \ldots, n$
is the column index of the matrix $\mat{A}$. This system is square
and of shape $n \times n$. Theorem \ref{th:existence_weights} assures there is
a unique solution. Given that the nodes are in general algebraic numbers
and can not be resolved formally we computed approximations by complex
balls. Even in case we knew the nodes in closed form, there is obviously
no way to solve this system within the rationals and we would have to resort
to the algebraic number field. Therefore we approximate the weights by complex
balls the same way. Computing the solution vector $\vec{\omega}$ to a target
precision of $b_{\omega}$ bits is actually not straight forward. The reason is
that we know the nodes with a precision of $b_{\gamma}$ bits only. It can then
happen that this is not precise enough to solve the system and retrieve $b_{\omega}$
bits for the weights.

The way out of this dilemma consist of an iterative ansatz. First we try to
solve the system and then check the precision $b_{\omega}^{\prime}$ of the
weights. If $b_{\omega}^{\prime} \geq b_{\omega}$ then the precision goal was
met and we can stop. Otherwise we double the required precision
$b_{\gamma}^{\prime} := 2 b_{\gamma}$ and recompute the nodes first. After
that we can retry solving this system and see if the precision goal is met
this time. If not we let the algorithm iterate until the goal of $b_{\omega}$ bits
is eventually fulfilled or an upper bound hit. The procedure is shown in pseudo-code
in listing \ref{alg:compute_weights}.

\begin{algorithm}
  \caption{Compute the weights up to a given precision $b_{\omega}$}
  \label{alg:compute_weights}
  \begin{algorithmic}
    \Procedure{ComputeWeights}{$P_n(x)$, $\omega(t)$, $b_{\omega}$}
      \State $b_{\gamma} := \frac{1}{2} b_{\omega}$
      \Repeat
        \State $b_{\gamma} := 2 b_{\gamma}$
        \State $\{\gamma_i\}_{i=1}^{n} := \textsc{ComputeNodes}(P_n(x), b_{\gamma})$
        \State $\mat{A} := \textsc{BuildMatrix}(\{\gamma_i\}_{i=1}^{n})$
        \State $\vec{r} := \textsc{BuildRHS}(\omega(t))$
        \State $\{\omega_i\}_{i=1}^{n} := \textsc{SolveLinear}(\mat{A}, \vec{r})$
        \State $b^{\prime}_{\omega} := \textsc{CheckAccuracy}(\{\omega_i\}_{i=1}^{n})$
      \Until{$b^{\prime}_{\omega} \geq b_{\omega}$} \\
      \Return $\{\omega_i\}_{i=1}^{n}$
    \EndProcedure
  \end{algorithmic}
\end{algorithm}


\FloatBarrier
\subsection{Validation of nodes and weights}
\label{sec:validation_nodes_weights}


Validation of the extensions computed is necessary and happens in
two separate steps where the second one is optional. Even if we
can solve equation \eqref{eq:linsys_for_extension} and algorithm
\ref{alg:find_extension} does return a non-vanishing polynomial $E_p$,
this does not guarantee we have found a suitable extensions.
As an example we look at possible extensions of the Gauss-Hermite rule
given by the polynomial $H_3 = 8t^3 - 12t$. Searching for an extension
$E_4$ of degree 4 we get the polynomial $E_4 = t^4 - 5t^2 - \frac{5}{4}$.
Computing the roots and therewith the quadrature nodes algebraically we get:
\begin{align*}
  t &= \pm\sqrt{\sqrt{\frac{15}{2}}+\frac{5}{2}} \approx \pm 2.288801605\\
  t &= \pm \imath \sqrt{\frac{1}{2} \left(\sqrt{30}-5\right)} \approx \pm 0.4884800789 \imath \,.
\end{align*}
Numerical computation with at least 20 digits of precision by ball arithmetic gives:
\begin{table}[h]
  \centering
  \begin{tabular}{|l|l|}
  \hline
  Midpoint & Radius \\
  \hline
  $-2.2888016051 - 2.12589347958 \cdot 10^{-128}\imath$   & $\pm (6.24 \cdot 10^{-63}, 6.24 \cdot 10^{-63}\imath)$ \\
  $2.2888016051 + 1.55755275766 \cdot 10^{-128}\imath$    & $\pm (6.24 \cdot 10^{-63}, 6.24 \cdot 10^{-63}\imath)$ \\
  $-4.76485148133 \cdot 10^{-129} - 0.488480078945\imath$ & $\pm (8.42 \cdot 10^{-64}, 8.42 \cdot 10^{-64}\imath)$ \\
  $-4.75946861246 \cdot 10^{-129} + 0.488480078945\imath$ & $\pm (8.42 \cdot 10^{-64}, 8.42 \cdot 10^{-64}\imath)$ \\
%   $-2.2888016051038216989 + 9.0133709461704339673e-65\imath$  & $\pm (4.12e-31, 4.12e-31\imath)$ \\
%   $2.2888016051038216989 + 1.3445251464279069435e-64\imath$  & $\pm (4.12e-31, 4.12e-31\imath)$ \\
%   $-1.6077784669939595885e-66 - 0.48848007894471046411\imath$ & $\pm (8.6e-32, 8.6e-32\imath)$ \\
%   $1.7455978790703967984e-64 + 0.48848007894471046411\imath$ & $\pm (8.6e-32, 8.6e-32\imath)$ \\
  \hline
  \end{tabular}
\end{table}
Obviously two of the nodes are complex-valued. This is actually guaranteed because
the balls that contain the roots do not intersect with the real line.
Hence this is not a valid extension.
Looking for an extension of order 5 we see that there is none. The next higher extension
which exists is $E_6 = t^6 -\frac{105}{8}t^4 + \frac{315}{8}t^2 - \frac{315}{32}$.
Computing the roots of $E_6$ again up to at least 20 digits precision by ball arithmetic gives:
\begin{table}[h]
  \centering
  \begin{tabular}{|l|l|}
  \hline
  Midpoint & Radius \\
  \hline
  $-2.95921077906 - 2.41239124804 \cdot 10^{-194}\imath$  & $\pm (2.48 \cdot 10^{-62}, 2.48 \cdot 10^{-62}\imath)$ \\
  $-2.0232301911 + 8.64516353565 \cdot 10^{-224}\imath$   & $\pm (3.03 \cdot 10^{-62}, 3.03 \cdot 10^{-62}\imath)$ \\
  $-0.524033547487 + 1.58006659246 \cdot 10^{-187}\imath$ & $\pm (3.72 \cdot 10^{-63}, 3.72 \cdot 10^{-63}\imath)$ \\
  $0.524033547487 + 2.19180934901 \cdot 10^{-193}\imath$  & $\pm (2.09 \cdot 10^{-63}, 2.09 \cdot 10^{-63}\imath)$ \\
  $2.0232301911 - 2.0066613913 \cdot 10^{-197}\imath$     & $\pm (4.13 \cdot 10^{-62}, 4.13 \cdot 10^{-62}\imath)$ \\
  $2.95921077906 - 6.84940421565 \cdot 10^{-194}\imath$   & $\pm (2.3 \cdot 10^{-62}, 2.3 \cdot 10^{-62}\imath)$ \\
%   $-2.9592107790638377223 + 1.7977637202018041576e-94\imath$  & $\pm (1.8e-30, 1.8e-30\imath)$ \\
%   $-2.0232301911005156592 - 2.0407955812719218635e-117\imath$ & $\pm (2.89e-30, 2.89e-30\imath)$ \\
%   $-0.52403354748695764515 - 2.4545467326488632765e-91\imath$ & $\pm (2.59e-31, 2.59e-31\imath)$ \\
%   $0.52403354748695764515 + 1.8726705418768793309e-95\imath$ & $\pm (2.59e-31, 2.59e-31\imath)$ \\
%   $2.0232301911005156592 + 1.4630238608413119772e-97\imath$  & $\pm (2.26e-30, 2.26e-30\imath)$ \\
%   $2.9592107790638377223 - 3.9794249014883685781e-96\imath$  & $\pm (1.8e-30, 1.8e-30\imath)$ \\
  \hline
  \end{tabular}
\end{table}
The imaginary parts are tiny and we safely assume that the roots are indeed all real.
This result is in principle not guaranteed, the balls do all intersect the real line
but also extend into the complex plane. However we can recompute these numbers with higher
precision and obtain smaller radii up to a point where we are satisfied with the result.

To validate an extension $E_p$ of $P_n$ we first check that the roots $\{\gamma_i\}_{i=1}^p$ of
this polynomial $E_p$ actually lie within the region $\Omega$.
The subset $\Omega$ of $\mathbb{R}$ is the region where the original polynomials $P_n$ are orthogonal
and where we want the quadrature to happen, see table \ref{eq:orthogonal_polynomials} for details.
Explicitly stated, we require that:
\begin{equation}
  \{\gamma_i\}_{i=1}^p \subset \Omega \,.
\end{equation}

The second step in the validation of an extension concerns the weights.
While we infer from \eqref{eq:linsys_for_weights_matrix} that the weights are all
real, they can still be negative. Negative weights can affect the stability
of a quadrature rule. For that reason one usually drops rules having negative
weights. By requiring that:
\begin{equation}
  \omega_i > 0 \quad i=1, \ldots, p+n
\end{equation}
we can filter out invalid extensions.
These steps apply in the same way also to nested towers
$P_n \subset E_{p_1} \subset E_{p_2} \subset \ldots \subset E_{p_k}$
of extensions. The nodes can be validated for each level $k$ independently.
In contrast, the weights need to be computed and examined in the end for
all levels together.


\FloatBarrier
\subsection{Implementation aspects}
\label{sec:implementation_aspects}

The whole algorithm is implemented in \texttt{C} and relies heavily
on the computational number theory library \texttt{flint} \cite{flint, Hart2010}.
This library provides among many other things highly efficient exact rational
numbers with arbitrary large numerator and denominator integers. Therefore we
have the complete arithmetics of the field $\mathbb{Q}$ available. It also
implements the polynomial rings $\mathbb{Z}[x]$ and $\mathbb{Q}[x]$ and hence we
can compute and express the polynomials defining the nodes of our nested extension
tower. There are at least two reasons we require an efficient implementation of
$\mathbb{Q}[x]$. First we need to be able to do fast arithmetics with polynomials,
specifically multiplication and checking whether a given polynomial is indeed square-free.
Second, the coefficients grow exponentially large and we must use arbitrary precision
rational numbers for expressing them. Other things we use from \texttt{flint} are
matrices over $\mathbb{Z}$ and $\mathbb{Q}$. The matrices module provides us with means
to solve linear systems by integral or rational arithmetic using a specially adapted
fraction free version of Gauss elimination.

Given all that we can check whether an extension $E_p$ to any given rule $P_n$
exists by using only exact rational arithmetic. The price we pay is that we can
handle only distributions $\omega(t)$ that have rational moments.

Johansson implemented arbitrary-precision floating point ball arithmetic in a
library called \texttt{arb} \cite{arb}. This library enables us to compute and
refine the nodes to any number of bits precision while always obtaining rigorous
error radii for each floating point ball computed. In detail, the library implements,
among some more things, real and complex floating point balls, polynomials having
ball-valued coefficients and matrices with balls as entries. Furthermore this library plays
very well together with \texttt{flint} making it the ideal choice for our purpose.
However it should not be neglected that all this comes at a higher cost
in computation time compared to normal hardware-accelerated floating point arithmetic.
The comparison has to be made against \emph{software} based arbitrary precision floating
point arithmetic as for example implemented in the GNU \texttt{MPFR} library \cite{mpfr}.
In that case the ball arithmetic of \texttt{arb} is claimed to be usually much less than
a factor of 2 slower than the plain \texttt{MPFR} floating point numbers. This is
actually very good and a perfectly fair price to pay for the additional confidence put
into the computed numbers. Even though \texttt{arb} is highly optimized, computing many
roots to a high working precision can still take some time.


\FloatBarrier
\section{Direct Search for single Extensions}

In this section we will consider only single Kronrod extensions. Given a polynomial
$P_n$ of either Legendre, Chebyshev, Laguerre or Hermite type and of degree $n$, we compute
the extension $E_p$ of order $p$ for some suitable choice of $p$. We make use of algorithm
\ref{alg:find_extension} to obtain the polynomial $E_p$ defining the extension in
the first place. Next we compute nodes and weights. If requested, validity checks
are performed to ensure that the nodes are within the region of integration:
\begin{equation}
  \forall i = 1, \ldots, n+p: \gamma_i \in \Omega \subseteq \mathbb{R}
\end{equation}
and that the weights are positive:
\begin{equation}
  \forall i = 1, \ldots, n+p: \omega_i > 0 \,.
\end{equation}

Since the aim of this work is an exhaustive search for valid rules we apply
this computation for a series of increasing $n$ and test all $p$ up to some
upper bound. This then guarantees that we have found all extensions of
some given Gauss type rule $P_n$ up to extension order $p_{\textrm{max}}$.
To cover as much as possible the range of rules used in practice we set
$n_{\mathrm{max}} = 100$ and also $p_{\textrm{max}} = 100$. In the extreme case
there is now a polynomial of degree $200$ defining a rule with the same number
of node-weight pairs.

\begin{algorithm}
  \caption{Exhaustive search up to $n_{\textrm{max}}$ and $p_{\textrm{max}}$}
  \label{alg:exhaustive_search}
  \begin{algorithmic}
    \Procedure{ExhaustiveSearch}{$n_{\textrm{max}}$, $p_{\textrm{max}}$}
      \State $\mat{M} \in \{0,1\}^{n \times p}$
      \Comment Bitmap for storing the found rules
      \For{$n = 1, \ldots, n_{\textrm{max}}$}
        \State Get $P_n(t)$
        \Comment Suitable orthogonal polynomial of order $n$
        \For{$p = n+1, \ldots, p_{\textrm{max}}$}
          \State $E_p := \textsc{ComputeExtension}(P_n, p)$
          \If{$E_p \not\equiv 0$}
            \State $\mat{M}_{n,p} := 1$
          \Else
            \State $\mat{M}_{n,p} := 0$
          \EndIf
        \EndFor
      \EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

The output of this algorithm applied to the three polynomial classes mentioned
above is shown in the figures \ref{fig:map_leg_100_100}, \ref{fig:map_lag_20_100}
and \ref{fig:map_herm_50_100}.


\marginpar{Some explanation for each polynomial case}
\marginpar{todo: replot with negative weights included}
\marginpar{Consider even larger maps?}


\subsection{Existence and non-existence results}

From the rather sparse theory on this subject we know only of very few rigorous
existence results for Kronrod-Patterson extensions.

In the Legendre case there is a proof saying that for each $n$ there is
always an extension with $p = n + 1$ \cite{szegoe}. This is recovered by our
computation and shows up in figure \ref{fig:map_leg_100_100} as the first upper
diagonal line. Additionally to their existence, these rules also have positive
weights in all cases as shown in \cite{monegato1978}. The existence theorems can
be generalized to hold also for Chebyshev, Gegenbauer and ultimatively Jacobi
polynomials \cite{gautschi-notaris, gautschi, notaris1990, monegato1978_2}.

\begin{figure}
  \centering
  \includegraphics[width=0.6\textwidth]{./img/map_leg_100_100.png}
  \caption{Map of the extensions $E_p$ of Gauss-Legendre quadrature rules
           $P_n$ for $n \leq 100$ and $p$ up to $100$.}
  \label{fig:map_leg_100_100}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.6\textwidth]{./img/map_chebt_100_100.png}
  \caption{Map of the extensions $E_p$ of Gauss-Chebyshev quadrature rules
           $T_n$ for $n \leq 100$ and $p$ up to $100$.}
  \label{fig:map_chebt_50_50}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.6\textwidth]{./img/map_chebu_100_100.png}
  \caption{Map of the extensions $E_p$ of Gauss-Chebyshev quadrature rules
           $U_n$ for $n \leq 100$ and $p$ up to $100$.}
  \label{fig:map_chebu_100_100}
\end{figure}

For Laguerre polynomials there are no classical Kronrod extensions with $p = n+1$
at all. Higher order extensions are very sparse too, we could not find extensions
for any $12 < n \leq 100$ while keeping $p \leq 150$. There is no strong reason to
believe this would change if allowing for even higher $p$. Apart from that, such
rules would probably be of no practical use anyway.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{./img/map_lag_20_100.png}
  \caption{Map of the extensions $E_p$ of Gauss-Laguerre quadrature rules
           $L_n$ for $n \leq 20$ and $p$ up to $100$. The part from
           $20 < n \leq 100$ not shown here does not contain any single
           valid extension.}
  \label{fig:map_lag_20_100}
\end{figure}

In the case of Hermite polynomials our computation indeed reveals the three possible
classical Kronrod rules for $n=1, p=2$ and $n = 2, p = 3$ and $n = 4, p = 5$. This
can be seen in the very top left corner of figure \ref{fig:map_herm_50_100} and is
in perfect agreement with the literature \cite{monegato1976, kahaner-monegato, vladislav}.
In fact if we examine the three rules more closely, we will find that the case
$n = 4, p = 5$ does not have positive weights and is in turn ruled out by the
authors of the aforementioned papers.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{./img/map_herm_50_100.png}
  \caption{Map of the extensions $E_p$ of Gauss-Hermite quadrature rules
           $H_n$ for $n \leq 50$ and $p$ up to $100$. The part from
           $50 < n \leq 100$ not shown here does not contain any single
           valid extension.}
  \label{fig:map_herm_50_100}
\end{figure}


\FloatBarrier
\section{Recursive Enumeration of nested Extensions}


In the last section we computed a single extensions $E_p$ over a
given rule $P_n$. This is enough in case of adaptive quadrature where all one
wants is to make an error estimate of the Gaussian quadrature by evaluation
of another quadrature rule having higher order. In that case the property of
nested nodes $\{\gamma_i\}_{i=1}^n \subset \{\gamma_i\}_{i=1}^{n+p}$ can reduce
computation cost.

Another use case however is the construction of quadrature
rules for higher dimensional integrals. For the number of dimensions in the
range from $4$ up to some ten this can be done efficiently by the well known
Smolyak construction.


Given an initial polynomial $P_n$ of degree $n$, we want to find the set of all
extension towers\footnote{By abuse of notation, let $E_{p_k}$ denote the polynomial
of degree $p_k$ as well as the abstract extension over $E_{p_{k-1}}$ defined by it.}
%$P_n \subset E_{p_1} \subset E_{p_2} \subset \ldots \subset E_{p_k}$
$P_n \equiv E_{p_0} \subset E_{p_1} \subset \ldots \subset E_{p_k} \subset \ldots \subset E_{p_{k_{\textrm{max}}}}$
%$P = P_0 \subset P_1 \subset \ldots \subset P_k \subset \ldots \subset P_{k_{\textrm{max}}}$
over $P_n$ having finite height $k_{\textrm{max}}$. Additionally we truncate this
potentially infinite set by requiring that the degrees $p_k$ of all polynomials $E_{p_k}$
never exceed a fixed upper bound $p_{\textrm{max}}$. This will in turn give a finite tree
of nested extensions. In the end, we denote a single extension from this set
by $\mathcal{K} = (n, p_1, \ldots, p_{k_{\textrm{max}}}) \in \mathbb{N}^{{k_{\textrm{max}}}+1}$.

Given the polynomial $P_{k-1}(x) := \prod_{i=0}^{k-1} E_{p_i}(x)$ fixing the lower part of this tower,
we can call algorithm \ref{alg:recursive_search} with $P_{k-1}$ to compute recursively the remaining
upper layers $k, \ldots, k_{\textrm{max}}$ as far as they exist. This algorithm will perform a
flat exhaustive search on layer $k$ and then call itself for the next layer $k+1$. To get this
process started, we make an initial call for $k=1$ with $P_{0} := P_n \equiv E_{p_0}$ as shown
in \ref{alg:exhaustive_recursive_search}.

\begin{algorithm}
  \caption{Recursive search for extensions over $P_{k-1}$ on layer $k$}
  \label{alg:recursive_search}
  \begin{algorithmic}
    \Procedure{RecursiveSearch}{$P_{k-1}$, $p_{\textrm{max}}$, $k$, $k_{\textrm{max}}$}
    \State {}
    \Comment Search for possible extensions of $P_{k-1}$ of order $p \leq p_{\textrm{max}}$
    \For{$p = 1, \ldots, p_{\textrm{max}}$}
      \State $E_p := \textsc{ComputeExtension}(P_{k-1}, p)$
      \If{$E_p \not\equiv 0$}
        \State $\mathrm{valid} := \textsc{ValidateRoots}(E_p)$
      \Else
        \State $\mathrm{valid} := \mathrm{false}$
      \EndIf
      \If{$\mathrm{valid} = \mathrm{true}$}
        \State {}
        \Comment Valid extension $E_p$ of order $p$ found for $P_{k-1}$ on layer $k$
        \State $p_k := p$
        \State $\mathcal{K} := (p_0, \ldots, p_{k-1}, p_k) \in \mathbb{N}^{k+1}$
        \State $\mathcal{R} := \mathcal{R} \cup \mathcal{K}$
        \If{$k < k_{\textrm{max}}$}
          \State {}
          \Comment Follow the recursion down, descending to new layer $k+1$
          \State $P_{k} := P_{k-1} E_p$
          \State $\textsc{RecursiveSearch}(P_{k}, p_{\textrm{max}}, k+1, k_{\textrm{max}})$
        \Else
          \State {}
          \Comment Maximum recursion depth reached, not descending
        \EndIf
      \Else
        \State {}
        \Comment No valid extension of order $p$ found for $P_{k-1}$ on layer $k$
      \EndIf
    \EndFor
    \State {}
    \Comment Maximal extension order $p_{\textrm{max}}$ reached, ascending
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}
  \caption{Exhaustive recursive search up to $p_{\textrm{max}}$ and $k_{\textrm{max}}$}
  \label{alg:exhaustive_recursive_search}
  \begin{algorithmic}
    \Procedure{ExhaustiveRecursiveSearch}{$P$, $p_{\textrm{max}}$, $k_{\textrm{max}}$}
      \State $\mathcal{R} := \{\}$
      \Comment Storage for all the rules $\mathcal{K}$ found
      \State $p_0 := \deg P$
      \State $\textsc{RecursiveSearch}(P, p_{\textrm{max}}, 1, k_{\textrm{max}})$
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

We denote by $\mathcal{Q}[p_0, \ldots, p_k]$ the quadrature rule and explicitly
the nodes and weights that can be computed from the nested Kronrod extension
$\mathcal{K} = (p_0, \ldots, p_k)$. Of course $\mathcal{Q}[n]$ is simple the
original quadrature rule we started with. In all cases considered here this
will be a Gauss rule of order $n$ having $n$ points.

\begin{figure}
  \centering
  \includegraphics[width=0.8\linewidth]{./img/graph_hermite_1_100_6_part.png}
  \caption{Part of the tree of nested higher order Kronrod Extensions of the
  single point Gauss-Hermite rule $\mathcal{Q}[1]$. On the top right corner
  we recognize the rules of highest nesting degree found so far.}
  \label{fig:graph_1_100_6_part}
\end{figure}


\begin{table}[h]
  \centering
  \begin{tabular}{|x{1cm}|x{10cm}|}
  \hline
  $P_n$ & $\mathcal{K} = (p_0, p_1, \ldots, p_k)$ \\
  \hline
  $P_1$ $k \geq 6$ &
  $(1,2,4,8,16,32,64)$,
  $(1,2,4,8,30,46,92)$,
  $(1,2,4,14,22,44,88)$,
  $(1,2,4,14,22,44,90)$,
  $(1,4,6,12,24,48,96)$ \\
  \hline
  $P_2$ $k \geq 5$ &
  $(2,3,6,12,44,68)$,
  $(2,3,6,22,34,68)$,
  $(2,3,10,16,32,64)$,
  $(2,3,10,16,32,66)$,
  $(2,3,16,22,44,88)$,
  $(2,3,16,22,44,90)$,
  $(2,4,6,22,35,70)$,
  $(2,4,6,22,36,70)$,
  $(2,4,6,22,36,71)$,
  $(2,4,6,22,36,72)$,
  $(2,4,6,29,42,84)$,
  $(2,4,14,20,40,82)$,
  $(2,4,15,22,44,88)$,
  $(2,4,15,22,44,90)$,
  $(2,4,16,22,44,90)$,
  $(2,4,16,22,45,92)$,
  $(2,6,9,32,50,100)$,
  $(2,6,16,25,50,100)$,
  $(2,7,10,20,40,80)$ \\
  \hline
  $P_3$ $k \geq 5$ &
  $(3,4,8,16,32,64)$,
  $(3,4,8,30,46,92)$,
  $(3,4,14,22,44,88)$,
  $(3,4,14,22,44,90)$ \\
  \hline
  $P_4$ $k \geq 5$ &
  $(4,5,10,20,40,80)$ \\
  \hline
  $P_5$ $k \geq 4$ &
  $(5,6,12,24,48,96)$,
  $(5,6,12,24,48)$,
  $(5,6,12,46,70)$,
  $(5,6,22,34,68)$,
  $(5,6,34,46,92)$ \\
  \hline
  $P_6$ $k \geq 4$ &
  $(6,7,14,28,56)$,
  $(6,7,14,30,58)$,
  $(6,7,14,54,82)$,
  $(6,7,26,40,80)$,
  $(6,8,14,29,58)$,
  $(6,8,14,30,58)$,
  $(6,8,14,30,59)$,
  $(6,8,14,55,84)$,
  $(6,8,14,56,84)$,
  $(6,8,14,56,85)$,
  $(6,8,15,54,84)$,
  $(6,8,26,40,80)$,
  $(6,8,26,40,81)$,
  $(6,8,26,40,82)$ \\
  \hline
  $P_7$ $k \geq 4$ &
  $(7,8,16,32,64)$,
  $(7,8,16,34,66)$,
  $(7,8,16,62,94)$,
  $(7,8,16,64,96)$,
  $(7,8,30,46,92)$ \\
  \hline
  $P_8$ $k \geq 4$ &
  $(8,9,18,36,72)$,
  $(8,9,18,38,74)$ \\
  \hline
  $P_9$ $k \geq 4$ &
  $(9,10,20,40,80)$,
  $(9,10,20,42,82)$ \\
  \hline
  $P_{10}$ $k \geq 4$ &
  $(10,11,22,44,88)$,
  $(10,11,22,46,90)$,
  $(10,12,22,45,90)$,
  $(10,12,22,45,92)$,
  $(10,12,24,46,93)$,
  $(10,12,24,47,94)$,
  $(10,12,24,47,96)$,
  $(10,12,24,48,94)$,
  $(10,12,24,48,95)$,
  $(10,12,24,48,96)$ \\
  \hline
  \end{tabular}
  \caption{Nested higher order Kronrod extensions $\mathcal{K}$ of the Legendre polynomials $P_n$.
  The table lists the most deeply nested extensions for $n \leq 10$ which were found.
  The maximal order $p_{\mathrm{max}}$ was set to $100$ and the recursion limit $k_{\mathrm{max}}$
  was never reached. Notice that extensions and especially highly nested extensions are very
  abundant in the case of Legendre polynomials.}
\end{table}


\begin{table}[h]
  \centering
  \begin{tabular}{|x{1cm}|x{10cm}|}
  \hline
  $T_n$ & $\mathcal{K} = (p_0, p_1, \ldots, p_k)$ \\
  \hline
  $T_1$ $k \geq ?$ &
  computing \\
  \hline
  $T_2$ $k \geq ?$ &
  computing \\
  \hline
  $T_3$ $k \geq 5$ &
  $(3,4,6,12,24,48,96)$,
  $(3,4,6,12,24,48)$,
  $(3,4,6,12,24,96)$,
  $(3,4,6,12,48,72)$,
  $(3,4,6,12,72,96)$,
  $(3,4,6,24,36,72)$,
  $(3,4,6,36,48,96)$,
  $(3,4,12,18,36,72)$,
  $(3,4,18,24,48,96)$,
  $(3,6,10,18,36,72)$,
  $(3,10,12,24,48,96)$ \\
  \hline
  $T_4$ $k \geq 5$ &
  $(4,5,8,16,32,64)$,
  $(4,5,8,16,64,96)$,
  $(4,5,8,32,48,96)$,
  $(4,5,16,24,48,96)$,
  $(4,8,13,24,48,96)$ \\
  \hline
  $T_5$ $k \geq 4$ &
  $(5,6,10,20,40,80)$,
  $(5,6,10,20,40)$,
  $(5,6,10,20,80)$,
  $(5,6,10,40,60)$,
  $(5,6,10,60,80)$,
  $(5,6,10,80,100)$,
  $(5,6,20,30,60)$,
  $(5,6,20,60,90)$,
  $(5,6,30,40,80)$,
  $(5,6,40,50,100)$,
  $(5,10,16,30,60)$,
  $(5,10,16,60,90)$,
  $(5,10,30,46,90)$,
  $(5,16,20,40,80)$,
  $(5,20,26,50,100)$ \\
  \hline
  $T_6$ $k \geq 4$ &
  $(6,7,12,24,48,96)$,
  $(6,7,12,24,48)$,
  $(6,7,12,24,96)$,
  $(6,7,12,48,72)$,
  $(6,7,12,72,96)$,
  $(6,7,24,36,72)$,
  $(6,7,36,48,96)$,
  $(6,12,19,36,72)$,
  $(6,19,24,48,96)$ \\
  \hline
  $T_7$ $k \geq 4$ &
  $(7,8,14,28,56)$,
  $(7,8,14,56,84)$,
  $(7,8,28,42,84)$,
  $(7,14,22,42,84)$ \\
  \hline
  $T_8$ $k \geq 4$ &
  $(8,9,16,32,64)$,
  $(8,9,16,64,96)$,
  $(8,9,32,48,96)$,
  $(8,16,25,48,96)$ \\
  \hline
  $T_9$ $k \geq 4$ &
  $(9,10,18,36,72)$ \\
  \hline
  $T_{10}$ $k \geq 4$ &
  $(10,11,20,40,80)$ \\
  \hline
  \end{tabular}
  \caption{Nested higher order Kronrod extensions $\mathcal{K}$ of the Chebyshev polynomials $T_n$.
  The table lists the most deeply nested extensions for $n \leq 10$ which were found.
  The maximal order $p_{\mathrm{max}}$ was set to $100$ and the recursion limit $k_{\mathrm{max}}$
  was never reached. The Chebyshev polynomials also possess a rich structure of deeply nested extensions.}
\end{table}


\begin{table}[h]
  \centering
  \begin{tabular}{|x{1cm}|x{10cm}|}
  \hline
  $U_n$ & $\mathcal{K} = (p_0, p_1, \ldots, p_k)$ \\
  \hline
  $U_1$ $k \geq ?$ &
  computing \\
  \hline
  $U_2$ $k \geq 5$ &
  $(2,3,6,12,24,48,96)$,
  $(2,3,6,12,24,48)$,
  $(2,3,6,12,24,96)$,
  $(2,3,6,12,48,72)$,
  $(2,3,6,12,72,96)$,
  $(2,3,6,24,36,72)$,
  $(2,3,6,36,48,96)$,
  $(2,3,12,18,36,72)$,
  $(2,3,18,24,48,96)$,
  $(2,6,9,18,36,72)$,
  $(2,9,12,24,48,96)$ \\
  \hline
  $U_3$ $k \geq 5$ &
  $(3,4,8,16,32,64)$,
  $(3,4,8,16,64,96)$,
  $(3,4,8,32,48,96)$,
  $(3,4,16,24,48,96)$,
  $(3,8,12,24,48,96)$ \\
  \hline
  $U_4$ $k \geq 4$ &
  $(4,5,10,20,40,80)$,
  $(4,5,10,20,40)$,
  $(4,5,10,20,80)$,
  $(4,5,10,40,60)$,
  $(4,5,10,60,80)$,
  $(4,5,10,80,100)$,
  $(4,5,20,30,60)$,
  $(4,5,20,60,90)$,
  $(4,5,30,40,80)$,
  $(4,5,40,50,100)$,
  $(4,10,15,30,60)$,
  $(4,10,15,60,90)$,
  $(4,10,30,45,90)$,
  $(4,15,20,40,80)$,
  $(4,20,25,50,100)$ \\
  \hline
  $U_5$ $k \geq 4$ &
  $(5,6,12,24,48,96)$,
  $(5,6,12,24,48)$,
  $(5,6,12,24,96)$,
  $(5,6,12,48,72)$,
  $(5,6,12,72,96)$,
  $(5,6,24,36,72)$,
  $(5,6,36,48,96)$,
  $(5,12,18,36,72)$,
  $(5,18,24,48,96)$ \\
  \hline
  $U_6$ $k \geq 4$ &
  $(6,7,14,28,56)$,
  $(6,7,14,56,84)$,
  $(6,7,28,42,84)$,
  $(6,14,21,42,84)$ \\
  \hline
  $U_7$ $k \geq 4$ &
  $(7,8,16,32,64)$,
  $(7,8,16,64,96)$,
  $(7,8,32,48,96)$,
  $(7,16,24,48,96)$ \\
  \hline
  $U_8$ $k \geq 3$ &
  $(8,9,18,36,72)$,
  $(8,9,18,36)$,
  $(8,9,18,72)$,
  $(8,9,36,54)$,
  $(8,9,54,72)$,
  $(8,9,72,90)$,
  $(8,18,27,54)$,
  $(8,18,54,81)$,
  $(8,27,36,72)$,
  $(8,36,45,90)$ \\
  \hline
  $U_9$ $k \geq 3$ &
  $(9,10,20,40,80)$,
  $(9,10,20,40)$,
  $(9,10,20,80)$,
  $(9,10,40,60)$,
  $(9,10,60,80)$,
  $(9,10,80,100)$,
  $(9,20,30,60)$,
  $(9,20,60,90)$,
  $(9,30,40,80)$,
  $(9,40,50,100)$ \\
  \hline
  $U_{10}$ $k \geq 3$ &
  $(10,11,22,44,88)$,
  $(10,11,22,44)$,
  $(10,11,22,88)$,
  $(10,11,44,66)$,
  $(10,11,66,88)$,
  $(10,22,33,66)$,
  $(10,22,66,99)$,
  $(10,33,44,88)$ \\
  \hline
  \end{tabular}
  \caption{Nested higher order Kronrod extensions $\mathcal{K}$ of the Chebyshev polynomials $U_n$.
  The table lists the most deeply nested extensions for $n \leq 10$ which were found.
  The maximal order $p_{\mathrm{max}}$ was set to $100$ and the recursion limit $k_{\mathrm{max}}$
  was never reached. The Chebyshev polynomials also possess a rich structure of deeply nested extensions.}
\end{table}


\begin{table}[h]
  \centering
  \begin{tabular}{|x{1cm}|x{10cm}|}
  \hline
  $L_n$ & $\mathcal{K} = (p_0, p_1, \ldots, p_k)$ \\
  \hline
  $L_1$ $k \geq 3$ &
  $(1,3,5,12,24)$,
  $(1,3,5,12,25)$,
  $(1,3,5,12,26)$,
  $(1,3,5,9)$,
  $(1,3,5,10)$,
  $(1,3,5,11)$,
  $(1,3,5,12)$,
  $(1,3,5,23)$,
  $(1,3,5,24)$,
  $(1,3,5,25)$,
  $(1,3,5,28)$,
  $(1,3,5,29)$,
  $(1,3,5,45)$,
  $(1,3,5,46)$,
  $(1,3,5,47)$,
  $(1,3,5,69)$,
  $(1,3,5,70)$,
  $(1,3,5,80)$,
  $(1,3,6,43)$,
  $(1,3,6,91)$,
  $(1,3,6,92)$,
  $(1,3,6,93)$,
  $(1,3,7,90)$,
  $(1,3,7,91)$,
  $(1,3,8,89)$,
  $(1,3,8,90)$,
  $(1,5,11,68)$ \\
  \hline
  $L_2$ $k \geq 2$ &
  $(2,4,7,29)$,
  $(2,4,8,86)$,
  $(2,4,9,86)$,
  $(2,4,7)$,
  $(2,4,8)$,
  $(2,4,9)$,
  $(2,4,10)$,
  $(2,4,13)$,
  $(2,4,21)$,
  $(2,4,22)$,
  $(2,4,23)$,
  $(2,4,30)$,
  $(2,4,41)$,
  $(2,4,42)$,
  $(2,4,43)$,
  $(2,4,44)$,
  $(2,4,45)$,
  $(2,4,47)$,
  $(2,4,53)$,
  $(2,4,68)$,
  $(2,4,69)$,
  $(2,4,70)$,
  $(2,4,71)$,
  $(2,4,72)$,
  $(2,4,73)$,
  $(2,4,74)$,
  $(2,4,96)$,
  $(2,4,97)$,
  $(2,5,29)$,
  $(2,5,30)$,
  $(2,5,38)$,
  $(2,5,39)$,
  $(2,5,48)$,
  $(2,6,50)$,
  $(2,6,51)$,
  $(2,6,54)$,
  $(2,6,79)$,
  $(2,6,80)$,
  $(2,7,49)$,
  $(2,7,77)$,
  $(2,9,48)$,
  $(2,10,58)$ \\
  \hline
  $L_3$ $k \geq 2$ &
  $(3,6,41)$,
  $(3,6,42)$,
  $(3,6,43)$,
  $(3,6,44)$,
  $(3,6,50)$,
  $(3,7,57)$,
  $(3,7,58)$,
  $(3,7,94)$ \\
  \hline
  $L_4$ $k \geq 2$ &
  $\emptyset$ \\
  \hline
  $L_5$ $k \geq 2$ &
  $(5,9,39)$, $(5,9,40)$ \\
  \hline
  $L_6$ $k \geq 2$ &
  $\emptyset$ \\
  \hline
  $L_7$ $k \geq 2$ &
  $\emptyset$ \\
  \hline
  $L_8$ $k \geq 2$ &
  $(8,15,26)$ \\
  \hline
  $L_9$ $k \geq 2$ &
  $\emptyset$ \\
  \hline
  $L_{10}$ $k \geq 2$ &
  $\emptyset$ \\
  \hline
  \end{tabular}
  \caption{Nested higher order Kronrod extensions $\mathcal{K}$ of the Laguerre polynomials $L_n$.
  The table lists the most deeply nested extensions for $n \leq 20$ which were found.
  The maximal order $p_{\mathrm{max}}$ was set to $100$ and the recursion limit $k_{\mathrm{max}}$ was never reached.
  For this type of polynomial, deeply nested rules are extremely rare.}
\end{table}


\begin{table}[h]
  \centering
  \begin{tabular}{|x{1cm}|x{10cm}|}
  \hline
  $H_n$ & $\mathcal{K} = (p_0, p_1, \ldots, p_k)$ \\
  \hline
  $H_1$ $k \geq 4$ &
  $(1,2,6,10,16,68)$,
  $(1,2,6,10,18,66)$,
  $(1,2,6,10,18,68)$,
  $(1,2,6,10,16)$,
  $(1,2,6,10,18)$,
  $(1,2,6,10,22)$,
  $(1,2,6,10,24)$,
  $(1,2,6,10,96)$,
  $(1,2,6,12,28)$,
  $(1,2,6,12,34)$,
  $(1,2,6,12,36)$,
  $(1,2,6,12,48)$,
  $(1,2,6,14,22)$,
  $(1,2,6,14,24)$,
  $(1,2,6,14,28)$,
  $(1,2,6,14,32)$,
  $(1,2,6,14,34)$,
  $(1,2,6,14,78)$,
  $(1,2,6,14,80)$,
  $(1,2,6,14,82)$,
  $(1,2,6,24,36)$,
  $(1,2,6,24,40)$,
  $(1,2,6,24,44)$,
  $(1,4,8,14,96)$,
  $(1,8,14,22,90)$ \\
  \hline
  $H_2$ $k \geq 4$ &
  $(2,3,4,8,24)$,
  $(2,3,4,8,50)$,
  $(2,3,4,8,52)$,
  $(2,3,4,8,54)$,
  $(2,3,4,8,56)$,
  $(2,3,4,8,78)$,
  $(2,3,4,8,80)$,
  $(2,3,4,8,82)$,
  $(2,3,4,8,84)$,
  $(2,3,4,16,98)$,
  $(2,3,4,18,98)$,
  $(2,3,4,20,30)$,
  $(2,3,4,20,32)$,
  $(2,3,4,20,34)$,
  $(2,3,4,20,36)$,
  $(2,3,4,20,38)$,
  $(2,3,4,20,40)$,
  $(2,3,6,16,24)$,
  $(2,3,6,16,26)$,
  $(2,3,6,16,90)$,
  $(2,3,6,16,92)$,
  $(2,3,6,16,98)$ \\
  \hline
  $H_3$ $k \geq 3$ &
  $(3,6,10,16,68)$,
  $(3,6,10,18,66)$,
  $(3,6,10,18,68)$,
  $(3,6,10,16)$,
  $(3,6,10,18)$,
  $(3,6,10,22)$,
  $(3,6,10,24)$,
  $(3,6,10,96)$,
  $(3,6,12,28)$,
  $(3,6,12,34)$,
  $(3,6,12,36)$,
  $(3,6,12,48)$,
  $(3,6,14,22)$,
  $(3,6,14,24)$,
  $(3,6,14,28)$,
  $(3,6,14,32)$,
  $(3,6,14,34)$,
  $(3,6,14,78)$,
  $(3,6,14,80)$,
  $(3,6,14,82)$,
  $(3,6,24,36)$,
  $(3,6,24,40)$,
  $(3,6,24,44)$ \\
  \hline
  $H_4$ $k \geq 3$ &
  $(4,5,10,36,56)$,
  $(4,5,10,36)$,
  $(4,5,10,38)$,
  $(4,5,10,46)$,
  $(4,5,10,48)$,
  $(4,5,10,52)$,
  $(4,5,10,54)$,
  $(4,5,22,42)$,
  $(4,5,30,48)$ \\
  \hline
  $H_5$ $k \geq 3$ &
  $(5,8,14,96)$ \\
  \hline
  $H_6$ $k \geq 3$ &
  $(6,9,14,68)$,
  $(6,9,16,66)$,
  $(6,9,16,68)$ \\
  \hline
  $H_7$ $k \geq 3$ &
  $\emptyset$ \\
  \hline
  $H_8$ $k \geq 3$ &
  $(8,11,18,66)$ \\
  \hline
  $H_9$ $k \geq 3$ &
  $(9,14,22,90)$ \\
  \hline
  $H_{10}$ $k \geq 3$ &
  $\emptyset$ \\
  \hline
  \end{tabular}
  \caption{Nested higher order Kronrod extensions $\mathcal{K}$ of the Hermite polynomials $H_n$.
  The table lists the most deeply nested extensions for $n \leq 20$ which were found.
  The maximal order $p_{\mathrm{max}}$ was set to $100$ and the recursion limit $k_{\mathrm{max}}$ was never reached.}
\end{table}

\marginpar{cite smolyak, complexity bound in nesting?}


\FloatBarrier
\section{Genz-Keister Multidimensional Construction}


Genz and Keister found an explicit construction by which efficient
special quadrature rules for an arbitrary number
of dimensions can be built. The resulting rules are
called \emph{fully-symmetric} for reasons that will become
clear later. In this section we review this construction of Genz
and Keister as given in \cite{genz, genz_keister}. We follow mostly their
development but focus mainly on the computational aspects and less
the theoretical derivation. Additionally we extend the construction
to Gauss-Chebyshev quadrature (both kinds) and analyze the resulting rules.


\subsection{The construction}

The quadrature rule $Q^{D,K}$ of \emph{level} $K \geq 0$ and
for use in $D$ dimensions is defined as:
\begin{equation} \label{eq:gk_basic_formula}
  \int_\Omega f(\vec{x}) \di{x} =:
  I[f] \approx Q^{D,K}[f]
       := \sum_{\mathbf{p} \in \mathcal{P}}
            f\left(\Gamma_{\mathbf{p}}\right)
            \omega_{\mathbf{p}}
\end{equation}
where $\mathcal{P}$ is the set of all integer partitions as defined below.
The node sets $\Gamma$ and weights $\omega$ are indexed by partitions
$\mathbf{p} \in \mathcal{P}$.
Define the set $\mathcal{P}$ of all admissible integer partitions
$\mathbf{p} := (\mathbf{p}_{1}, \ldots, \mathbf{p}_{D}) \in \mathbb{N}_{0}^{D}$
having $D$ parts (some of which can be zero) and $|\mathbf{p}| \leq K$
with $K \geq 0$ as:
\begin{equation} \label{eq:partition_set_def}
  \mathcal{P} :=
  \left\{
    \mathbf{p} \,
    \middle| K \geq \mathbf{p}_{1} \geq \cdots \geq \mathbf{p}_{D} \geq 0
    \wedge
    |\mathbf{p}| \leq K
  \right\}
  \,.
\end{equation}
An algorithm for computing that set $\mathcal{P}$
is shown in \eqref{alg:ca_enumerate_integer_partitions}.
Before we look deeper into the details of this construction,
we need to introduce the set $\Lambda$ of so called \emph{generators}:
\begin{equation}
  \Lambda := \{\lambda_{0}, \lambda_{1}, \ldots, \lambda_{J}\}
\end{equation}
where we require that $\lambda_{0} \equiv 0$ and all $\lambda_{i}$ be
pair-wise distinct. There are obviously $J+1$ real non-negative generators.
A single quadrature point $\gamma \in \mathbb{R}^D$ is then an ordered
multiset of size $D$ of elements from $\Lambda$. Note that $\gamma$ is not
just a subset because elements are allowed to appear multiple times. The
specific items are then selected by an integer vector $\mathbf{k} \in \mathbb{N}_0^D$,
explicitly:
\begin{equation}
  \gamma_\mathbf{k} := \Lambda_\mathbf{k} = \left(\lambda_{k_1}, \ldots, \lambda_{k_D}\right) \,.
\end{equation}
We define $\delta$ as the number of components of $\gamma_\mathbf{k}$ that are 0.
As we require that only $\lambda_0$ is zero, $\delta$ is equivalent to the number
of zeros in $\mathbf{k}$.
Next we define the set $\overline{\gamma_\mathbf{k}}$ containing all
possible sign flips:
\begin{equation}
  \overline{\gamma_\mathbf{k}} \assign
  \sigma \gamma_\mathbf{k} =
  \{
  \left(\sigma_1 \gamma_1, \ldots, \sigma_D \lambda_D\right)
  \}_{\sigma \in \{-1,0,1\}^D}
\end{equation}
where $\sigma_d \in \{-1, 1\}$ or $\sigma_d = 0$ if and only if $\gamma_d = 0$.
The point $\gamma_\mathbf{k}$ gets mirrored into all $2^D$ orthants by $\sigma$.
Clearly, this set $\overline{\gamma_\mathbf{k}}$ is of size $2^{D-\delta}$ for
the reason that some points coincide with their own mirror images.

At this point we can go back and understand
the notation of equation \eqref{eq:gk_basic_formula}
where $\Gamma_\mathbf{p}$ stands for a whole set of nodes given by:
\begin{equation}
  \Gamma_\mathbf{p} \assign
  \bigcup_{\mathbf{q} \in \mathcal{S}_\mathbf{p}} \overline{\gamma_\mathbf{q}}
\end{equation}
and $\mathcal{S}_\mathbf{p}$ is the set of all permutations of the $D$
elements of $\mathbf{p} \in \mathcal{P}$. An algorithm for the enumeration
of all permutations is given in \eqref{alg:ca_enumerate_permutations}.
Finally we find:
\begin{equation}
  f\left(\Gamma_\mathbf{p}\right) \assign
  \sum_{\mathbf{q} \in \mathcal{S}_p}
  \sum_{\gamma \in \overline{\gamma_\mathbf{q}}}
  f\left(\gamma_1, \ldots, \gamma_D\right) \,.
\end{equation}

What remains is the explanation of $\omega_\mathbf{p}$. The formula $(2.4)$
given in \cite{genz} looks quite simple but the efficient implementation needs
some care. For every admissible partition $\mathbf{p} \in \mathcal{P}$ the
corresponding weight can be computed by:
\begin{equation} \label{eq:gk_weight_def}
  \omega_{\mathbf{p}} := 2^{-(D-\delta)}
                         \sum_{|\mathbf{k}| \leq K - |\mathbf{p}|}
                         \prod_{d=1}^{D}
                           \frac{a_{\mathbf{k}_{d}+\mathbf{p}_{d}}}{P(\mathbf{k}_{d},\mathbf{p}_{d})}
\end{equation}
where we define the denominator:
\begin{equation} \label{eq:gk_weight_def_denom}
  P(\mathbf{k}_{d},\mathbf{p}_{d}) :=
  \prod_{\substack{i=0 \\
                   i\neq\mathbf{p}_{d}}}
       ^{\mathbf{k}_{d}+\mathbf{p}_{d}}
    \left( \lambda_{\mathbf{p}_{d}}^{2}-\lambda_{i}^{2} \right)
\end{equation}
and use the multi-index $\mathbf{k} \in \mathbb{N}_{0}^{D}$. Note that the
prefactor is exactly $1 / |\overline{\gamma_\mathbf{k}}|$.
Algorithm \eqref{alg:ca_enumerate_lattice_points} implements a procedure
for enumeration of all relevant multi-indices.
This formula above presents us with several parts we need to compute.
Some of these parts can even be tabulated once for a maximal and
fixed $J$ value and independent of the dimension $D$.
Let us start with the numerator. There we need the value $a_i$ which is defined
as follows:
\begin{equation} \label{eq:gk_def_ai}
  a_{i} := \int_\Omega p_{i}(x) w(x) \di{x}, \quad i = 0, \ldots, J+1
\end{equation}
and the domain $\Omega$ and the weight function $w(x)$ are chosen
appropriately (see below). The polynomials $p_{i}(x)$ are defined as:
\begin{equation}
\begin{split}
  p_{0}(x) & := 1 \\
  p_{i}(x) & := \prod_{j=0}^{i-1} \left(x^{2} - \lambda_{j}^{2}\right)
\end{split}
\end{equation}
where the empty product equals 1. It holds that $\deg p_i = 2i$.
Since all the real numbers $\lambda_{j}$ are known we can indeed
expand the product and write $p_i$ as $\sum_{j=0}^{2i} c_j x^j$
for some coefficients $c_j$. This enables us to compute the integral
in equation \eqref{eq:gk_def_ai} term-wise by using linearity:
\begin{equation}
  a_i = \sum_{j=0}^{2i} c_j \int_\Omega x^j w(x) \di{x} = \sum_{j=0}^{2i} c_j M_j
\end{equation}
where $M_j$ is the $j$-th moment and chosen according to table
\eqref{eq:orthogonal_polynomials} and the explicit formulae shown thereafter.
For the Legendre, Chebyshev and Hermite case, the explicit formulae are
\eqref{eq:moments_legendre}, \eqref{eq:moments_chebyshevt}, \eqref{eq:moments_chebyshevt}
and \eqref{eq:moments_hermite_phy}.
Optionally we can replace very small values by zero. As we will see later
it is important to be able to decide whether $a_{i} = 0$. Because we
compute with real numbers (either floating point numbers or real ball arithmetic)
we can however never solve this problem exactly like in rational arithmetic.

\begin{algorithm}[h!]
  \caption{Compute table $\vec{A}$ of $a_{i}$ factors}
  \label{alg:gk_compute_a_values}
  \begin{algorithmic}
    \Procedure{ComputeAValues}{$\Lambda$, $\vec{M}$}
      \State $\vec{A} := \vec{0} \in \mathbb{R}^{J+1}$
      \State $p := 1$
      \For{$i=0, \ldots, J+1$}
        \State $a := 0$
        \For{$c_j$ in $\sum_{j=0}^{2i} c_j x^j = p$}
          \State $a := a + c_j \vec{M}_j$
        \EndFor
%         \For{$d = 0, \ldots, \deg p$}
%           \State $a := a + \textsc{Coefficient}(p, d) \, \vec{M}_d$
%         \EndFor
        \State $\vec{A}_i := a$
        \State $p := p \left(x^2 - \lambda_i^2\right)$
      \EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

Computing the denominator as defined in \eqref{eq:gk_weight_def_denom}
is straight forward. Since we required the $\lambda_i$ to be pairwise
distinct this value never becomes zero and division poses no issue.

We notice that the product in formula \eqref{eq:gk_weight_def} only depends on
$\mathbf{p}_{d} =: \xi$ and the sum $\mathbf{p}_{d}+\mathbf{k}_{d} =: \eta$.
Therefore we can precompute a table of size $J+1 \times J+1$ indexed by $(\xi, \eta)$
whose entries are given by:
\begin{equation}
  \mat{T}_{\xi, \eta} := \frac{a_{\mathbf{k}_{d}+\mathbf{p}_{d}}}{P(\mathbf{k}_{d},\mathbf{p}_{d})} \,.
\end{equation}
In the example below, the top left corner of $\mat{T}$ is shown and we only
ever need the upper right triangular part:

\begin{center}
\begin{tabular}{|c|cccc|}
  \hline
  {}    & $\eta=0$ & $\eta=1$ & $\eta=2$ & $\eta=3$ \\
  \hline
  $\xi=0$ & $\frac{a_0}{1}$
          & $\frac{a_1}{(\lambda_0^2-\lambda_1^2)}$
          & $\frac{a_2}{(\lambda_0^2-\lambda_1^2)(\lambda_0^2-\lambda_2^2)}$
          & $\frac{a_3}{(\lambda_0^2-\lambda_1^2)(\lambda_0^2-\lambda_2^2)(\lambda_0^2-\lambda_3^2)}$ \\
  $\xi=1$ & 0
          & $\frac{a_1}{(\lambda_1^2-\lambda_0^2)}$
          & $\frac{a_2}{(\lambda_1^2-\lambda_0^2)(\lambda_1^2-\lambda_2^2)}$
          & $\frac{a_3}{(\lambda_1^2-\lambda_0^2)(\lambda_1^2-\lambda_2^2)(\lambda_1^2-\lambda_3^2)}$ \\
  $\xi=2$ & 0
          & 0
          & $\frac{a_2}{(\lambda_2^2-\lambda_0^2)(\lambda_2^2-\lambda_1^2)}$
          & $\frac{a_3}{(\lambda_2^2-\lambda_0^2)(\lambda_2^2-\lambda_1^2)(\lambda_2^2-\lambda_3^2)}$ \\
  $\xi=3$ & 0
          & 0
          & 0
          & $\frac{a_3}{(\lambda_3^2-\lambda_0^2)(\lambda_3^2-\lambda_1^2)(\lambda_3^2-\lambda_2^2)}$ \\
  \hline
\end{tabular}
\end{center}

Given the list $\Lambda$ of generators and all the values $a_{i}$ collected into
the list $\vec{A}$ we can compute the table $\mat{T}$ efficiently by algorithm
\eqref{alg:gk_compute_weight_factors}. By the use of this table, the implementation
of formula \eqref{eq:gk_weight_def} transforms into a series of trivial table
look-up steps. However, precomputation of $\mat{T}$ is expensive for larger $J$
but on the other hand needs to be done only once for each $\Lambda$ and $w(x)$.
The numerator and denominator of the entries in $\mat{T}$ can become really large
numbers (remember that most moments include gamma functions) while their quotient
stays within reasonable range for floating point representation. For this reason
one can compute $\mat{T}$ to high precision with specialized software packages
like \texttt{flint} \cite{flint, Hart2010} and afterwards use these tabulated
values during usual floating point computations.

\begin{algorithm}[h!]
  \caption{Compute table $\mat{T}_{\xi,\eta}$ of weight factors}
  \label{alg:gk_compute_weight_factors}
  \begin{algorithmic}
    \Procedure{WeightFactors}{$\Lambda$, $\vec{A}$}
      \State $n := |\Lambda|$
      \State $\mat{T} \in \mathbb{R}^{n\times n}$
      \Comment Compute $T$ row by row
      \For{$\xi = 0, \ldots, n-1$}
        \State $t := 1$
        \For{$\eta = 0, \ldots, n-1$}
          \If{$\xi \neq \eta$}
            \State $t := t \left(\lambda_{\xi}^{2} - \lambda_{\eta}^{2}\right)$
          \EndIf
          \If{$\eta \geq \xi$}
            \State $\mat{T}_{\xi,\eta} := \frac{a_{\eta}}{t}$
          \EndIf
        \EndFor
      \EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

At the end of the day we arrive at the following two algorithms
\eqref{alg:gk_compute_nodes} and \eqref{alg:gk_compute_weights}
for computing the node set $\Gamma_\mathbf{p}$ and weights $\omega_\mathbf{p}$
for an arbitrary given partition $\mathbf{p} \in \mathcal{P}$.

\begin{algorithm}[h!]
  \caption{Compute nodes $\Gamma_\mathbf{p}$ for given $\mathbf{p} \in \mathcal{P} \subset \mathbb{N}_0^D$}
  \label{alg:gk_compute_nodes}
  \begin{algorithmic}
    \Procedure{Nodes}{$\mathbf{p}$, $\Lambda$}
      \State $\Gamma_\mathbf{p} := \{\}$
      \State $\delta := \textsc{NumberOfZeros}(\mathbf{p})$
      \State $\mathcal{S} := \textsc{Permutations}(D, \mathbf{p})$
      \For{$\mathbf{q} \in \mathcal{S}$}
        \For{$v = 0, \ldots, 2^{(D - \delta)}-1$}
          \State $u := 0$
          \For{$d = 0, \ldots, D-1$}
            \State $\gamma_d := \Lambda_{\mathbf{q}_d}$
            \If{$\mathbf{q}_d \neq 0$}
              \Comment Compute sign flip
              \If{$\lfloor\frac{v}{2^u}\rfloor \mod 2 = 1$}
                \State $\gamma_d := - \gamma_d$
              \EndIf
              \State $u := u + 1$
            \EndIf
          \EndFor
          \State $\Gamma_\mathbf{p} := \Gamma_\mathbf{p} \cup \gamma$
        \EndFor
      \EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[h!]
  \caption{Compute weight $\omega_\mathbf{p}$ for given $\mathbf{p} \in \mathcal{P} \subset \mathbb{N}_0^D$}
  \label{alg:gk_compute_weights}
  \begin{algorithmic}
    \Procedure{Weights}{$\mathbf{p}$, $K$, $\mat{T}$}
      \State $\delta := \textsc{NumberOfZeros}(\mathbf{p})$
      \State $\omega_\mathbf{p} := 0$
      \State $\mathcal{L} := \textsc{EnumerateLatticePoints}(D, K - |\mathbf{p}|)$
      \For{$\mathbf{k} \in \mathcal{L}$}
        \State $w := 1$
        \For{$d = 0, \ldots, D-1$}
          \State $w := w \, \mat{T}_{\mathbf{p}_d, \mathbf{k}_d + \mathbf{p}_d}$
        \EndFor
        \State $\omega_\mathbf{p} := \omega_\mathbf{p} + w$
      \EndFor
      \State $\omega_\mathbf{p} := 2^{-(D-\delta)} \omega_\mathbf{p}$
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

The last ingredient we need is the integer sequence $\vec{z} = (z_0, \ldots, z_J)$ defined as:
\begin{equation}
  \begin{split}
    z_0 & = 0 \\
    z_i & = l \quad \Leftrightarrow \quad a_{i+k} = 0 \quad \forall \, k = 0, \ldots, l-1 \,.
  \end{split}
\end{equation}

The reasoning behind this sequence and the specific definition summarizes to
the fact that we like to get many summands with $\omega_{\mathbf{p}} = 0$ in
equation \eqref{eq:gk_basic_formula}. Looking at the definition of the weights
in equation \eqref{eq:gk_weight_def} we have a sum-product structure. A single
product becomes zero if the numerator $a_{\mathbf{k}_d+\mathbf{p}_d} = 0$. This
then must happen for all summands in the sum. A simple algorithm to find $\vec{z}$
is given in \eqref{alg:gk_compute_zsequence} below. It is limited in rigor because
of the zero test on floating point numbers.

\begin{algorithm}[h!]
  \caption{Compute the $\vec{z}$ sequence}
  \label{alg:gk_compute_zsequence}
  \begin{algorithmic}
    \Procedure{CompueZSequence}{$\vec{A}$}
      \State $\vec{z} := \vec{0} \in \mathbb{R}^{J+1}$
      \State $v := 0$
      \For{$i = 0, \ldots, J$}
        \If{$v = 0$}
          \While{$\vec{A}_{i+v} = 0$}
            \State $v := v + 1$
          \EndWhile
        \Else
          \State $v := v - 1$
        \EndIf
        \State $\vec{z}_i := v$
      \EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

Finally, we cite theorem 3.1 from \cite{genz} but omit the proof:

\begin{theorem*}
  \label{th:zero_weights}
  A fully symmetric rule using a generator set $\Lambda$ has weights $\omega_{\mathbf{p}} = 0$
  if $|\mathbf{p}| + |\vec{z}(\mathbf{p})| > K$.
\end{theorem*}

This theorem tells us which partitions $\mathbf{p}$ we can omit when assembling
the quadrature rule. The full algorithm for the construction of fully symmetric quadrature
rules in $D$ dimensions and of level $K$ is shown in \eqref{alg:gk_construction}.
The whole procedure is general in the sense that we can apply it to both the Legendre and
Hermite cases as it was already done in \cite{genz} and \cite{genz_keister} respectively.
Further we can repeat the very same computations for both kinds of Gauss-Chebyshev
quadrature which is new. As we have seen in the last section there exists a plethora
of nested higher order Kronrod extensions for some orthogonal polynomials. Each of these
can serve as the basis $\mathcal{K}$ for the generator set $\Lambda$. Genz and Keister used in
the Hermite case the Kronrod extensions $\mathcal{K} = (1, 2, 6, 10, 16)$ and $\mathcal{K} = (1, 2, 8, 20)$.
One should note that not all rules are equally well suited. A criterion on the expected
\emph{sparsity} of the final rule is the number of zero elements in the $\vec{z}$ sequence.
The more non-zero elements the better but unfortunately such sequences are rare.
Additionally there appears the question of stability which was discussed in \cite{genz}.
Novak and Ritter show in \cite{novak_ritter}, section 6, that the Genz-Keister construction
produces quadrature rules which are of classical Smolyak form. This is convenient
for two reasons. First, we can construct $D$ dimensional rules either by direct full
Genz-Keister construction or by Smolyak construction applied to the set of one-dimensional
Genz-Keister rules. Second, the convergence and error analysis from Smolyak theory is
also valid for this construction.

\marginpar{Note about more rules}

\begin{algorithm}[h!]
  \caption{Genz-Keister construction}
  \label{alg:gk_construction}
  \begin{algorithmic}
    \Procedure{GenzKeisterConstruction}{$D, K$}
      \State $\Gamma := \{\}$
      \Comment Nodes and weights as ordered sets
      \State $\Omega := \{\}$
      \State $ $
      \Comment Precompute fundamental tables
      \State $\Lambda := \textsc{ComputeGenerators}(\mathcal{K})$
      \State $\vec{M} := \textsc{ComputeMoments}()$
      \State $\vec{A} := \textsc{ComputeAValues}(\Lambda, \vec{M})$
      \State $\mat{T} := \textsc{WeightFactors}(\Lambda, \vec{A})$
      \State $ $
      \Comment Construct multi-dimensional rule
      \State $\mathcal{P} := \textsc{EnumeratePartitions}(D, K)$
      \For{$\mathbf{p} \in \mathcal{P}$}
        \If{$|\mathbf{p}| + |\vec{z}(\mathbf{p})| \leq K$}
          \State $\Gamma_\mathbf{p} := \textsc{Nodes}(\mathbf{p}, \Lambda)$
          \State $\omega_\mathbf{p} := \textsc{Weights}(\mathbf{p}, K, \mat{T})$
          \State $\Gamma := \Gamma \cup \Gamma_\mathbf{p}$
          \State $\Omega := \Omega \cup \omega_\mathbf{p}$
          \Comment Add $|\Gamma_\mathbf{p}|$ times the weight $\omega_\mathbf{p}$
        \EndIf
      \EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}


\subsubsection{Combinatorial Algorithms}


In this section we summarize the combinatorial algorithms that
can be used during the Genz-Keister construction. In the programming
language \texttt{python} they can be implemented very efficiently by
the use of \texttt{yield} statements inside so called \emph{generator expressions}.

The algorithm \eqref{alg:ca_enumerate_integer_partitions} can
be used for enumeration of the set $\mathcal{P}$ defined in
\eqref{eq:partition_set_def}. This works for any given value
of $D \geq 1$ and maximal element size $K \geq 0$. The elements
$\mathbf{p} \in \mathcal{P}$ will be generated by increasing value
of $|\mathbf{p}|$ until the boundary $K$ is hit.

\marginpar{Cite partition paper?}

\begin{algorithm}[h!]
  \caption{Enumerate the set $\mathcal{P}$ of all integer partitions}
  \label{alg:ca_enumerate_integer_partitions}
  \begin{algorithmic}
    \Procedure{EnumeratePartitions}{$D$, $K$}
      \State $\mathcal{P} := \{\}$
      \State $\mathbf{p} := \vec{0} \in \mathbb{N}_{0}^{D}$
      \While{$|\mathbf{p}| \leq K$}
        \State $\tau := \mathrm{false}$
        \State $p := \mathbf{p}_{0}$
        \For{i = 1, \ldots D-1}
          \State $p := p + \mathbf{p}_i$
          \If{$\mathbf{p}_{0} \leq \mathbf{p}_{i} + 1$}
            \State $\mathbf{p}_{i} := 0$
          \Else
            \State $\mathbf{p}_{0} := p - i (\mathbf{p}_{i} + 1)$
            \For{j = 1, \ldots, i}
              \State $\mathbf{p}_{j} := \mathbf{p}_{i} + 1$
            \EndFor
            \State $\mathcal{P} := \mathcal{P} \cup \mathbf{p}$
            \State $\tau := \mathrm{true}$
            \State \bf{break}
          \EndIf
        \EndFor
        \If{$\tau = \mathrm{false}$}
          \State{$\mathbf{p}_{0} := p + 1$}
          \If{$|\mathbf{p}| \leq K$}
            \State $\mathcal{P} := \mathcal{P} \cup \mathbf{p}$
          \EndIf
        \EndIf
      \EndWhile
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

An algorithm to enumerate the set $\mathcal{S}$ of all entry-wise
permutations of a given vector $\mathbf{p} \in \mathbb{N}_{0}^{D}$
is shown next in \eqref{alg:ca_enumerate_permutations}. This algorithm
will generate the permutations in reverse lexicographic order,
starting with $\mathbf{p}$.

\begin{algorithm}[h!]
  \caption{Enumerate the set $\mathcal{S}$ of all permutations
    of the entries of $\mathbf{p} \in \mathbb{N}_{0}^{D}$}
  \label{alg:ca_enumerate_permutations}
  \begin{algorithmic}
    \Procedure{Permutations}{$D$, $\mathbf{p}$}
      \State $\mathcal{S} := \{\mathbf{p}\}$
      \State $\tau := \mathrm{true}$
      \While{$\tau = \mathrm{true}$}
        \State $\tau := \mathrm{false}$
        \For{$i = 1, \ldots, D-1$}
          \State $p := \mathbf{p}_{i}$
          \If{$\mathbf{p}_{i-1} > p$}
            \State $I := i$
            \If{$i > 1$}
              \State $J := I$
              \For{$j = 0, \ldots, \lfloor \frac{I}{2} \rfloor -1 $}
                \State $q := \mathbf{p}_{j}$
                \If{$q \leq p$}
                  \State $I := I - 1$
                \EndIf
                \State $\mathbf{p}_{j} := \mathbf{p}_{i-j-1}$
                \State $\mathbf{p}_{i-j-1} := q$
                \If{$\mathbf{p}_{j} > p$}
                  \State $J := j + 1$
                \EndIf
              \EndFor
              \If{$\mathbf{p}_{I-1} \leq p$}
                \State $I := J$
              \EndIf
            \EndIf
            \State $\mathbf{p}_{i} := \mathbf{p}_{I-1}$
            \State $\mathbf{p}_{I-1} := p$
            \State $\mathcal{S} := \mathcal{S} \cup \mathbf{p}$
            \State $\tau := \mathrm{true}$
            \State \bf{break}
          \EndIf
        \EndFor
      \EndWhile
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

In the definition of the weights in formula \eqref{eq:gk_weight_def}
we need to iterate over the set $\mathcal{L} := \{\mathbf{k_{i}}\}$ of all
lattice points $\mathbf{k} \in \mathbb{N}_{0}^{D}$ up to some maximal value of
the $l_{1}$ norm. The algorithm \eqref{alg:ca_enumerate_lattice_points}
shows an efficient method for the enumeration of all such points. It
is well known that the cardinality of $\mathcal{L}$ is:
\begin{equation}
  |\mathcal{L}| = \left(\frac{K+1}{D}\right) \binom{D+K}{K+1} \,.
\end{equation}
For more details see for example \cite{serra-sagrista}.

\begin{algorithm}[h!]
  \caption{Enumerate lattice points in $\{\mathbf{k_{i}}\} =: \mathcal{L} \subset \mathbb{N}_{0}^{D}$
    with $\|\mathbf{k_{i}}\|_{1} \leq N$}
  \label{alg:ca_enumerate_lattice_points}
  \begin{algorithmic}
    \Procedure{EnumerateLatticePoints}{$D$, $N$}
      \State $\mathcal{L} := \{\} $
      \For{$n = 0, \ldots, N$}
        \State $\mathbf{k} := \vec{0} \in \mathbb{N}_{0}^{D}$
        \State $\mathbf{k}_{0} := n$
        \State $\mathcal{L} := \mathcal{L} \cup \mathbf{k}$
        \State $c := 1$
        \While{$\mathbf{k}_{D-1} < n$}
          \If{$c = D$}
            \For{$i = c-1, \ldots, 1$}
              \State $c := i$
              \If{$\mathbf{k}_{i-1} \neq 0$}
                \State \bf{break}
              \EndIf
            \EndFor
            \State $\mathbf{k}_{c-1} := \mathbf{k}_{c-1} - 1$
            \State $c := c +1$
            \State $\mathbf{k}_{c-1} := n$
            \For{$i = 0, \ldots, c-2$}
              \State $\mathbf{k}_{c-1} := \mathbf{k}_{c-1} - \mathbf{k}_{i}$
            \EndFor
            \If{$c < D$}
              \For{$i = c, \ldots, D-1$}
                \State $\mathbf{k}_{i} := 0$
              \EndFor
            \EndIf
            \State $\mathcal{L} := \mathcal{L} \cup \mathbf{k}$
          \EndIf
        \EndWhile
      \EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}


\FloatBarrier
\section{Nested Rules for Orthogonal Polynomials}

In this section we present various results for the classical orthogonal polynomials
and related Gauss quadrature schemes. For each scheme we could find at least one
replacement having nested nodes based on the Genz-Keister construction.

The generator set $\Lambda$ is in each case obtained by recursive higher order
Kronrod extensions $\mathcal{K} := (k_1, \ldots, k_p)$. For each extension level $k_i$
we then get a subset of nodes $\{\lambda_{i_1}, \ldots, \lambda_{i_q}\}$ from the corresponding
polynomial $E_{k_i}$. The final rule now depends on the ordering of these generators
and different orderings can lead to a non-negligible difference in overall stability. Permutation of
the nodes $\lambda_{i_j}$ within each subset does not change the number of function evaluations
required. The original authors came up with the following heuristic for sorting the
generators: begin each subset with its largest generator and then alternate the remaining
generators always using extremal values. They claim that this procedure yields
rules with a good (but not necessarily optimal) stability factor. In our notation
this factor reads:
\begin{equation*}
  C \assign \sum_{\mathbf{p} \in \mathcal{P}} N_{\mathbf{p}} |\omega_{\mathbf{p}}|
\end{equation*}
where for any partition $\mathbf{p}$ with $n$ distinct parts $\mathbf{p}_j$ each
having multiplicity $m_j$ the value $N_{\mathbf{p}}$ is given by:
\begin{equation*}
  N_{\mathbf{p}} = \frac{2^{|m|} D!}
                        {(D-|m|)! \, m_1! \cdots m_n!} \,.
\end{equation*}
In principle one could test all permutations of the generators and search for
one minimizing this stability constant. We will choose this alternating ordering
as default.
The order of a quadrature rule $Q^K$ is given by theorem 2.1 in \cite{genz}
and shown to be:
\begin{equation} \label{eq:gk_rul_order}
  2 K + 1 \,.
\end{equation}
The $K$ in this formula is, for each fixed quadrature
rule, the maximal value of $K$ for which the Genz-Keister construction results
in the given rule. For example in the Hermite case $K=9, \ldots, 14$ all yield
the same node-weight pairs. The order os this rule is then $2\cdot 14 + 1 = 29$.

Lemma 4.1 in \cite{holtz} gives conditions on the one-dimensional rules
such that the Smolyak construction of level $K$ from these rules has
order at least $2K-1$. It can be seen from figures \ref{fig:number_nodes_legendre},
\ref{fig:number_nodes_chebyshevt}, \ref{fig:number_nodes_chebyshevu} and
\ref{fig:number_nodes_hermitephy} that the rules discussed here fulfill the
required conditions as their orders are always large enough.

Finally, corollary 7 from \cite{novak_ritter} gives the degree of exactness
for $K \geq D - 1$ as $2 (K+1-D) + 1$.

\marginpar{TODO: inconsistent?}

\subsection{Legendre Quadrature}

For the Legendre polynomials $P_n$ we can find various Kronrod extensions. The
most suitable one seems to be $\mathcal{K} = (1,2,4,8,16,32)$. The Genz-Keister
construction built upon this set of generators has the following $\vec{z}$
sequence:
\begin{equation*}
  \vec{z} = (0, 0, 1, 0, 2, 1, 0, 0, 4, 3, 2, 1, 0, 0, 0, 0, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, 5, 4, 3, 2, 1)
\end{equation*}
where a large number of non-zero elements occur. Also we can in principle
arbitrarily extend $\mathcal{K}$ by doubling the degree. If we use this
extension we get the one-dimensional quadrature nodes and weights shown
in figure \ref{fig:gk_legendre_nodes_1d}. For most values of the level $K$
the weights behave well but for some they start oscillating and even become
negative. These special values of $K$ correlate with extra zeros in the
$\vec{z}$ sequence. Figure \ref{fig:gk_legendre_nodes_2d} shows the sparse
node distribution in the plane for two-dimensional quadrature rules.
Notice that for $D < 3$, using the Genz-Keister construction results
in more quadrature points than the full tensor product Ansatz. This
fact is examined in figures \ref{fig:gk_legendre_ratio} and \ref{fig:gk_legendre_ratio_large}.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{./img/gk_legendre_nodes_cmp.pdf}
  \caption{Comparison of Gauss-Legendre nodes (right) and nested Genz-Keister nodes (left)
  based on the $\mathcal{K} = (1,2,4,8,16,32)$ Kronrod extension. The points are
  nicely nested and well suited for sparse grids.}
  \label{fig:gk_legendre_nodes_cmp}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{./img/number_nodes_legendre.pdf}
  \caption{Number of nodes for the one-dimensional Gauss-Legendre and Genz-Keister quadrature
  rules of order $n$ or level $K$ respectively.}
  \label{fig:number_nodes_legendre}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{./img/monomial_errors_legendre.pdf}
  \caption{Relative quadrature error for integration of single univariate monomials $x^n$ of increasing degree $n$.
  Each line represents a quadrature rule and the color indicates the number of nodes (colors wrap around once though).
  The upper plot shows Gauss-Legendre rules as reference while the lower one shows the Genz-Keister rules.
  The number of nodes for each of these rules is:
  $1$, $3$,  $7$, $13$, $15$, $25$, $27$, $29$, $31$, $49$, $51$, $53$, $55$, $57$, $59$, $61$, $63$
  and the orders according to \eqref{eq:gk_rul_order} are:
  $1$, $5$, $11$, $13$, $23$, $25$, $27$, $29$, $47$, $49$, $51$, $53$, $55$, $57$, $59$, $61$, $95$
  which perfectly agrees with the figure.
  Starting with the $31$ point rule, the rules become somewhat unstable
  and do not reach the machine epsilon error level. This can be explained
  by growing oscillations in the weights for some of the rules. (Refer to figure
  \ref{fig:gk_legendre_nodes_1d} though the rules affected are beyond the range
  of that plot.) The rule having $63$ nodes is very stable again.}
  \label{fig:monomial_errors_legendre}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{./img/gk_legendre_nodes_1d.pdf}
  \caption{Gauss-Legendre (red) and Genz-Keister (blue) nodes versus
  corresponding weights. The 1- and 3-point rules are identical.
  Note that a few rules have oscillations in the weights, some of them
  are almost zero, others become increasingly negative. This affects the
  stability of the corresponding rules.}
  \label{fig:gk_legendre_nodes_1d}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{./img/gk_legendre_nodes_2d.pdf}
  \caption{Gauss-Legendre (red) and Genz-Keister (blue) nodes for
  two-dimensional rules. The Gauss-Legendre points form a full tensor
  product.}
  \label{fig:gk_legendre_nodes_2d}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{./img/number_nodes_levdim_legendre.pdf}
  \caption{Number $|\Gamma|$ of quadrature nodes for various levels $K$ and dimensions $D$.}
  \label{fig:number_nodes_levdim_legendre}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\linewidth]{./img/smol_legendre_ratio.pdf}
  \caption{Ratio of the number of Gauss-Legendre quadrature points obtained
  via tensor product and classical Smolyak construction. White dots are $D,K$
  combinations where Genz-Keister is advantageous, while for black dots
  Genz-Keister is worse and for gray dots the ratio equals 1.}
  \label{fig:smol_legendre_ratio}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\linewidth]{./img/gk_legendre_ratio.pdf}
  \caption{Ratio of the number of Genz-Keister and Gauss-Legendre tensor product
  points for dimensions $D$ up to 8 and Level $K \leq 12$. White dots are $D,K$
  combinations where Genz-Keister is advantageous, while for black dots
  Genz-Keister is worse and for gray dots the ratio equals 1.}
  \label{fig:gk_legendre_ratio}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\linewidth]{./img/gk_legendre_ratio_large.pdf}
  \caption{Ratio of the number of Genz-Keister and Gauss-Legendre tensor product
  points for dimensions 1 to 4 and Level $K \leq 32$. White dots are $D,K$
  combinations where Genz-Keister is advantageous, while for black dots
  Genz-Keister is worse and for gray dots the ratio equals 1. Notice the tendency
  of the white boundary to go to the right and eventually reach dimensions $D \geq 3$.}
  \label{fig:gk_legendre_ratio_large}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{./img/monomial_errors_legendre_2D.pdf}
  \caption{Quadrature of the bivariate monomials $x^m y^n$ for $0 \leq n, m \leq 50$.
  Each pair $(m,n)$ is color-coded by the lowest level $K$ rule that correctly
  integrates the monomial with a relative error not larger than $10^{-13}$.}
  \label{fig:monomial_errors_legendre_2D}
\end{figure}

For testing the quadrature rules in $D$ dimensions, the following integral
over multi-variate monomials with $\vec{n} \in \mathbb{N}_0^D$ is used:
\begin{equation} \label{eq:legendre_exact_solution}
  \idotsint \limits_{\vec{x} \in [-1,1]^D} \prod_{d=1}^D x_d^{n_d} \di{\vec{x}}
  =
  \prod_{d=1}^D \frac{1 + (-1)^{n_d}}{1 + n_d}
\end{equation}
where we know the exact solution in closed form.

\begin{subfigures}
  \label{fig:monomial_errors_legendre_multivariate}
  \begin{figure}\centering
    \includegraphics[width=\linewidth]{./img/monomial_errors_legendre_multivariate_dimension_2.pdf}
    \caption{Relative errors for the integral \eqref{eq:legendre_exact_solution}
    in $D=2$ dimensions. All variables $x_d$ share the same exponent $n$.}
    \label{fig:monomial_errors_legendre_multivariate_dimension_2}
  \end{figure}
  \begin{figure}\centering
    \includegraphics[width=\linewidth]{./img/monomial_errors_legendre_multivariate_dimension_3.pdf}
    \caption{Relative errors for the integral \eqref{eq:legendre_exact_solution}
    in $D=3$ dimensions. All variables $x_d$ share the same exponent $n$.}
    \label{fig:monomial_errors_legendre_multivariate_dimension_3}
  \end{figure}
  \begin{figure}\centering
    \includegraphics[width=\linewidth]{./img/monomial_errors_legendre_multivariate_dimension_4.pdf}
    \caption{Relative errors for the integral \eqref{eq:legendre_exact_solution}
    in $D=4$ dimensions. All variables $x_d$ share the same exponent $n$.}
    \label{fig:monomial_errors_legendre_multivariate_dimension_4}
  \end{figure}
  \begin{figure}\centering
    \includegraphics[width=\linewidth]{./img/monomial_errors_legendre_multivariate_dimension_5.pdf}
    \caption{Relative errors for the integral \eqref{eq:legendre_exact_solution}
    in $D=5$ dimensions. All variables $x_d$ share the same exponent $n$.}
    \label{fig:monomial_errors_legendre_multivariate_dimension_5}
  \end{figure}
  \begin{figure}\centering
    \includegraphics[width=\linewidth]{./img/monomial_errors_legendre_multivariate_dimension_6.pdf}
    \caption{Relative errors for the integral \eqref{eq:legendre_exact_solution}
    in $D=6$ dimensions. All variables $x_d$ share the same exponent $n$.}
    \label{fig:monomial_errors_legendre_multivariate_dimension_6}
  \end{figure}
\end{subfigures}

\FloatBarrier
\subsection{Chebyshev Quadrature of the first kind}

As in the case of Legendre polynomials, both Chebyshev polynomials $T_n$
and $U_n$ possess many different Kronrod extensions. For the first kind $T_n$
we choose $\mathcal{K} = (1, 2, 4, 6, 12, 24)$ with the $\vec{z}$ sequence:
\begin{equation*}
  \vec{z} = (0, 0, 1, 0, 2, 1, 0, 5, 4, 3, 2, 1, 0, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, 1) \,.
\end{equation*}
Again we can in principle extend $\mathcal{K}$ by doubling the degree.
Using this extension we get the one-dimensional quadrature nodes and weights shown
in figure \ref{fig:gk_chebyshevt_nodes_1d}.
Figure \ref{fig:gk_chebyshevt_nodes_2d} shows the sparse
node distribution in the plane for two-dimensional quadrature rules.
Notice that for $D < 3$, using the Genz-Keister construction results
in more quadrature points than the full tensor product Ansatz, however there
are some exceptions. This fact is examined in figures \ref{fig:gk_chebyshevt_ratio}
and \ref{fig:gk_chebyshevt_ratio_large}.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{./img/gk_chebyshevt_nodes_cmp.pdf}
  \caption{Comparison of Gauss-Chebyshev nodes (right) and nested Genz-Keister nodes (left)
  based on the $\mathcal{K} = (1, 2, 4, 6, 12, 24)$ Kronrod extension.
  The points are nicely nested and well suited for sparse grids.}
  \label{fig:gk_chebyshevt_nodes_cmp}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{./img/number_nodes_chebyshevt.pdf}
  \caption{Number of nodes for the one-dimensional Gauss-Chebyshev and Genz-Keister quadrature
  rules of order $n$ or level $K$ respectively.}
  \label{fig:number_nodes_chebyshevt}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{./img/monomial_errors_chebyshevt.pdf}
  \caption{Relative quadrature error for integration of single univariate monomials $x^n$ of increasing degree $n$.
  Each line represents a quadrature rule and the color indicates the number of nodes (colors wrap around once though).
  The upper plot shows Gauss-Chebyshev rules as reference while the lower one shows the Genz-Keister rules.
  The number of nodes for each of these rules is:
  $1$, $3$,  $7$, $13$, $25$ and the orders according to \eqref{eq:gk_rul_order} are:
  $1$, $5$, $11$, $23$, $47$ which perfectly agrees with the figure.
  All rules examined here are very stable up to machine precision.}
  \label{fig:monomial_errors_chebyshevt}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{./img/gk_chebyshevt_nodes_1d.pdf}
  \caption{Gauss-Chebyshev (red) and Genz-Keister (blue) nodes versus
  corresponding weights. The 1- and 3-point rules are identical.}
  \label{fig:gk_chebyshevt_nodes_1d}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{./img/gk_chebyshevt_nodes_2d.pdf}
  \caption{Gauss-Chebyshev (red) and Genz-Keister (blue) nodes for
  two-dimensional rules. The Gauss-Chebyshev points form a full tensor
  product.}
  \label{fig:gk_chebyshevt_nodes_2d}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{./img/number_nodes_levdim_chebyshevt.pdf}
  \caption{Number $|\Gamma|$ of quadrature nodes for various levels $K$ and dimensions $D$.}
  \label{fig:number_nodes_levdim_chebyshevt}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\linewidth]{./img/smol_chebyshevt_ratio.pdf}
  \caption{Ratio of the number of Gauss-Chebyshev quadrature points obtained
  via tensor product and classical Smolyak construction. White dots are $D,K$
  combinations where Genz-Keister is advantageous, while for black dots
  Genz-Keister is worse and for gray dots the ratio equals 1.}
  \label{fig:smol_chebyshevt_ratio}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\linewidth]{./img/gk_chebyshevt_ratio.pdf}
  \caption{Ratio of the number of Genz-Keister and Gauss-Chebyshev tensor product
  points for dimensions $D$ up to 8 and Level $K \leq 12$. White dots are $D,K$
  combinations where Genz-Keister is advantageous, while for black dots
  Genz-Keister is worse and for gray dots the ratio equals 1.}
  \label{fig:gk_chebyshevt_ratio}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\linewidth]{./img/gk_chebyshevt_ratio_large.pdf}
  \caption{Ratio of the number of Genz-Keister and Gauss-Chebyshev tensor product
  points for dimensions 1 to 4 and Level $K \leq 24$. White dots are $D,K$
  combinations where Genz-Keister is advantageous, while for black dots
  Genz-Keister is worse and for gray dots the ratio equals 1.}
  \label{fig:gk_chebyshevt_ratio_large}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{./img/monomial_errors_chebyshevt_2D.pdf}
  \caption{Quadrature of the bivariate monomials $x^m y^n$ for $0 \leq n, m \leq 50$.
  Each pair $(m,n)$ is color-coded by the lowest level $K$ rule that correctly
  integrates the monomial with a relative error not larger than $10^{-13}$.}
  \label{fig:monomial_errors_chebyshevt_2D}
\end{figure}

For testing the quadrature rules in $D$ dimensions, the following integral
over multi-variate monomials with $\vec{n} \in \mathbb{N}_0^D$ is used:
\begin{equation} \label{eq:chebyshevt_exact_solution}
  \idotsint \limits_{\vec{x} \in [-1,1]^D} \prod_{d=1}^D x_d^{n_d} \frac{1}{\sqrt{1-x_d^2}} \di{\vec{x}}
  =
  \left(\frac{\sqrt{\pi}}{2}\right)^D
  \prod_{d=1}^D \left(1 + (-1)^{n_d}\right)
  \frac{\Gamma\left(\frac{n_d}{2}+\frac{1}{2}\right)}
       {\Gamma\left(\frac{n_d}{2}+1\right)}
\end{equation}
where we know the exact solution in closed form.

\begin{subfigures}
  \label{fig:monomial_errors_chebyshevt_multivariate}
  \begin{figure}\centering
    \includegraphics[width=\linewidth]{./img/monomial_errors_chebyshevt_multivariate_dimension_2.pdf}
    \caption{Relative errors for the integral \eqref{eq:chebyshevt_exact_solution}
    in $D=2$ dimensions. All variables $x_d$ share the same exponent $n$.}
    \label{fig:monomial_errors_chebyshevt_multivariate_dimension_2}
  \end{figure}
  \begin{figure}\centering
    \includegraphics[width=\linewidth]{./img/monomial_errors_chebyshevt_multivariate_dimension_3.pdf}
    \caption{Relative errors for the integral \eqref{eq:chebyshevt_exact_solution}
    in $D=3$ dimensions. All variables $x_d$ share the same exponent $n$.}
    \label{fig:monomial_errors_chebyshevt_multivariate_dimension_3}
  \end{figure}
  \begin{figure}\centering
    \includegraphics[width=\linewidth]{./img/monomial_errors_chebyshevt_multivariate_dimension_4.pdf}
    \caption{Relative errors for the integral \eqref{eq:chebyshevt_exact_solution}
    in $D=4$ dimensions. All variables $x_d$ share the same exponent $n$.}
    \label{fig:monomial_errors_chebyshevt_multivariate_dimension_4}
  \end{figure}
  \begin{figure}\centering
    \includegraphics[width=\linewidth]{./img/monomial_errors_chebyshevt_multivariate_dimension_5.pdf}
    \caption{Relative errors for the integral \eqref{eq:chebyshevt_exact_solution}
    in $D=5$ dimensions. All variables $x_d$ share the same exponent $n$.}
    \label{fig:monomial_errors_chebyshevt_multivariate_dimension_5}
  \end{figure}
  \begin{figure}\centering
    \includegraphics[width=\linewidth]{./img/monomial_errors_chebyshevt_multivariate_dimension_6.pdf}
    \caption{Relative errors for the integral \eqref{eq:chebyshevt_exact_solution}
    in $D=6$ dimensions. All variables $x_d$ share the same exponent $n$.}
    \label{fig:monomial_errors_chebyshevt_multivariate_dimension_6}
  \end{figure}
\end{subfigures}

\FloatBarrier
\subsection{Chebyshev Quadrature of the second kind}

For the second kind $U_n$ of Chebyshev polynomials we use
$\mathcal{K} = (1, 2, 4, 8, 16, 32)$ with the $\vec{z}$ sequence:
\begin{equation*}
  \vec{z} = (0, 0, 1, 0, 3, 2, 1, 0, 7, 6, 5, 4, 3, 2, 1, 0, 15, 14, 13, 12, 11,
             10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, 1)\,.
\end{equation*}
Once more we could extend $\mathcal{K}$ by doubling the degree.
Using this extension we get the one-dimensional quadrature nodes and
weights shown in figure \ref{fig:gk_chebyshevu_nodes_1d}.
Figure \ref{fig:gk_chebyshevu_nodes_2d} shows the sparse
node distribution in the plane for two-dimensional quadrature rules.
For $D = 2$ there are levels where Genz-Keister is better than
Gauss-Chebyshev tensor products but there are also levels where
it behaves the other way round. The details are shown in figures
\ref{fig:gk_chebyshevu_ratio} and \ref{fig:gk_chebyshevu_ratio_large}.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{./img/gk_chebyshevu_nodes_cmp.pdf}
  \caption{Comparison of Gauss-Chebyshev nodes (right) and nested Genz-Keister nodes (left)
  based on the $\mathcal{K} = (1,2,4,8,16,32)$ Kronrod extension. The points are
  nicely nested and well suited for sparse grids.}
  \label{fig:gk_chebyshevu_nodes_cmp}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{./img/number_nodes_chebyshevu.pdf}
  \caption{Number of nodes for the one-dimensional Gauss-Chebyshev and Genz-Keister quadrature
  rules of order $n$ or level $K$ respectively.}
  \label{fig:number_nodes_chebyshevu}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{./img/monomial_errors_chebyshevu.pdf}
  \caption{Relative quadrature error for integration of single univariate monomials $x^n$ of increasing degree $n$.
  Each line represents a quadrature rule and the color indicates the number of nodes (colors wrap around once though).
  The upper plot shows Gauss-Chebyshev rules as reference while the lower one shows the Genz-Keister rules.
  The number of nodes for each of these rules is:
  $1$, $3$,  $7$, $15$, $31$,  $63$ and the orders according to \eqref{eq:gk_rul_order} are:
  $1$, $5$, $13$, $29$, $61$, $125$ which perfectly agrees with the figure.
  The error is in good agreement with the Gauss-Chebyshev rules which is of course
  expected because the rules are identical.}
  \label{fig:monomial_errors_chebyshevu}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{./img/gk_chebyshevu_nodes_1d.pdf}
  \caption{Gauss-Chebyshev (red) and Genz-Keister (blue) nodes versus
  corresponding weights. All $(2^i-1)$-point rules are identical.}
  \label{fig:gk_chebyshevu_nodes_1d}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{./img/gk_chebyshevu_nodes_2d.pdf}
  \caption{Gauss-Chebyshev (red) and Genz-Keister (blue) nodes for
  two-dimensional rules. The Gauss-Chebyshev points form a full tensor
  product.}
  \label{fig:gk_chebyshevu_nodes_2d}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{./img/number_nodes_levdim_chebyshevu.pdf}
  \caption{Number $|\Gamma|$ of quadrature nodes for various levels $K$ and dimensions $D$.}
  \label{fig:number_nodes_levdim_chebyshevu}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\linewidth]{./img/smol_chebyshevu_ratio.pdf}
  \caption{Ratio of the number of Gauss-Chebyshev quadrature points obtained
  via tensor product and classical Smolyak construction. White dots are $D,K$
  combinations where Genz-Keister is advantageous, while for black dots
  Genz-Keister is worse and for gray dots the ratio equals 1.
  Notice that although some of the Gauss rules are already nested, this has
  (as expected) almost no effect when applying the Smolyak construction.
  The only difference between this figure and its siblings is the point
  $D=4$ and $K=8$ which here is white instead of black. Also the boundary
  will reach $D=5$ a few levels later. However there is obviously still
  room for improvement.}
  \label{fig:smol_chebyshevu_ratio}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\linewidth]{./img/gk_chebyshevu_ratio.pdf}
  \caption{Ratio of the number of Genz-Keister and Gauss-Chebyshev tensor product
  points for dimensions $D$ up to 8 and Level $K \leq 12$. White dots are $D,K$
  combinations where Genz-Keister is advantageous, while for black dots
  Genz-Keister is worse and for gray dots the ratio equals 1.}
  \label{fig:gk_chebyshevu_ratio}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\linewidth]{./img/gk_chebyshevu_ratio_large.pdf}
  \caption{Ratio of the number of Genz-Keister and Gauss-Chebyshev tensor product
  points for dimensions 1 to 4 and Level $K \leq 32$. White dots are $D,K$
  combinations where Genz-Keister is advantageous, while for black dots
  Genz-Keister is worse and for gray dots the ratio equals 1.}
  \label{fig:gk_chebyshevu_ratio_large}
\end{figure}

For testing the quadrature rules in $D$ dimensions, the following integral
over multi-variate monomials with $\vec{n} \in \mathbb{N}_0^D$ is used:
\begin{equation} \label{eq:chebyshevu_exact_solution}
  \idotsint \limits_{\vec{x} \in [-1,1]^D} \prod_{d=1}^D x_d^{n_d} \sqrt{1-x_d^2} \di{\vec{x}}
  =
  \left(\frac{\sqrt{\pi}}{4}\right)^D
  \prod_{d=1}^D \left(1 + (-1)^{n_d}\right)
  \frac{\Gamma\left(\frac{n_d}{2}+\frac{1}{2}\right)}
       {\Gamma\left(\frac{n_d}{2}+2\right)}
\end{equation}
where we know the exact solution in closed form.

\begin{subfigures}
  \label{fig:monomial_errors_chebyshevu_multivariate}
  \begin{figure}\centering
    \includegraphics[width=\linewidth]{./img/monomial_errors_chebyshevu_multivariate_dimension_2.pdf}
    \caption{Relative errors for the integral \eqref{eq:chebyshevu_exact_solution}
    in $D=2$ dimensions. All variables $x_d$ share the same exponent $n$.}
    \label{fig:monomial_errors_chebyshevu_multivariate_dimension_2}
  \end{figure}
  \begin{figure}\centering
    \includegraphics[width=\linewidth]{./img/monomial_errors_chebyshevu_multivariate_dimension_3.pdf}
    \caption{Relative errors for the integral \eqref{eq:chebyshevu_exact_solution}
    in $D=3$ dimensions. All variables $x_d$ share the same exponent $n$.}
    \label{fig:monomial_errors_chebyshevu_multivariate_dimension_3}
  \end{figure}
  \begin{figure}\centering
    \includegraphics[width=\linewidth]{./img/monomial_errors_chebyshevu_multivariate_dimension_4.pdf}
    \caption{Relative errors for the integral \eqref{eq:chebyshevu_exact_solution}
    in $D=4$ dimensions. All variables $x_d$ share the same exponent $n$.}
    \label{fig:monomial_errors_chebyshevu_multivariate_dimension_4}
  \end{figure}
  \begin{figure}\centering
    \includegraphics[width=\linewidth]{./img/monomial_errors_chebyshevu_multivariate_dimension_5.pdf}
    \caption{Relative errors for the integral \eqref{eq:chebyshevu_exact_solution}
    in $D=5$ dimensions. All variables $x_d$ share the same exponent $n$.}
    \label{fig:monomial_errors_chebyshevu_multivariate_dimension_5}
  \end{figure}
  \begin{figure}\centering
    \includegraphics[width=\linewidth]{./img/monomial_errors_chebyshevu_multivariate_dimension_6.pdf}
    \caption{Relative errors for the integral \eqref{eq:chebyshevu_exact_solution}
    in $D=6$ dimensions. All variables $x_d$ share the same exponent $n$.}
    \label{fig:monomial_errors_chebyshevu_multivariate_dimension_6}
  \end{figure}
\end{subfigures}

\FloatBarrier
\subsection{Hermite Quadrature}

Figure \ref{fig:smol_hermitephy_ratio} shows the comparison of a full tensor
and a Smolyak construction based on the usual Gauss-Hermite points. Obviously the region
where Smolyak is disadvantageous extends to higher dimensions and this at even relatively
low levels. This is clearly an issue and should give some motivation for studying the
Genz-Keister constructions.
For Hermite polynomials $H_n$ Kronrod extensions are rare, especially extensions
having a high nesting degree. One of the best such extensions found so far is
$\mathcal{K} = (1, 2, 6, 10, 16, 68)$ with the $z$ sequence:
\begin{equation*}
  \vec{z} = (0, 0, 1, 0, 0, 3, 2, 1, 0, 0, 5, 4, 3, 2, 1, 0, 0, 0, 8, 7,
             6, 5, 4, 3, 2, 1, 0, 0, 0, 0, 0, 0, \ldots)
             %0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0)
\end{equation*}
Using this extension we get the one-dimensional quadrature nodes and weights shown
in figure \ref{fig:gk_hermitephy_nodes_1d}.
Figure \ref{fig:gk_hermitephy_nodes_2d} shows the sparse
node distribution in the plane for two-dimensional quadrature rules.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{./img/gk_hermitephy_nodes_cmp.pdf}
  \caption{Comparison of Gauss-Hermite nodes (right) and nested Genz-Keister nodes (left)
  based on the $\mathcal{K} = (1, 2, 6, 10, 16, 68)$ Kronrod extension. The points are
  nicely nested and well suited for sparse grids.}
  \label{fig:gk_hermitephy_nodes_cmp}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{./img/number_nodes_hermitephy.pdf}
  \caption{Number of nodes for the one-dimensional Gauss-Hermite and Genz-Keister quadrature
  rules of order $n$ or level $K$ respectively.}
  \label{fig:number_nodes_hermitephy}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{./img/monomial_errors_hermitephy.pdf}
  \caption{Relative quadrature error for integration of single univariate monomials $x^n$ of increasing degree $n$.
  Each line represents a quadrature rule and the color indicates the number of nodes (colors wrap around once though).
  The upper plot shows Gauss-Hermite rules as reference while the lower one shows the Genz-Keister rules.
  The number of nodes for each of these rules is:
  $1$, $3$, $7$,  $9$, $17$, $19$, $31$, $33$, $35$
  and the orders according to \eqref{eq:gk_rul_order} are:
  $1$, $5$, $7$, $15$, $17$, $29$, $31$, $33$, $51$
  which perfectly agrees with the figure. Given that none of the higher order rules agree with any Gauss-Hermite rule,
  the stability and error behavior is excellent. On the other hand, the rule with $35$ points integrates monomials
  correctly only up to $x^{51}$ with $51 = 2 \cdot 25 + 1$ instead of up to $n = 2 \cdot 35 - 1 = 69$.}
  \label{fig:conv_monom_hermite}
\end{figure}

By comparing to figure \ref{fig:conv_monom_hermite} we can confirm that the rules with $K < 18$ are stable.
The rule obtained with $K=17$ has $35$ nodes and is of order $51$. In the range $18 < K \leq 25$ we get no
new rules but rather the same nodes and weights as with $K = 17$. Rules with even higher $K > 25$ were found
to be highly unstable.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{./img/gk_hermitephy_nodes_1d.pdf}
  \caption{Gauss-Hermite (red) and Genz-Keister (blue) nodes versus
  corresponding weights. The 1- and 3-point rules are identical.}
  \label{fig:gk_hermitephy_nodes_1d}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{./img/gk_hermitephy_nodes_2d.pdf}
  \caption{Gauss-Hermite (red) and Genz-Keister (blue) nodes for
  two-dimensional rules. The Gauss-Hermite points form a full tensor
  product.}
  \label{fig:gk_hermitephy_nodes_2d}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{./img/number_nodes_levdim_hermitephy.pdf}
  \caption{Number $|\Gamma|$ of quadrature nodes for various levels $K$ and dimensions $D$.}
  \label{fig:number_nodes_levdim_hermitephy}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\linewidth]{./img/smol_hermitephy_ratio.pdf}
  \caption{Ratio of the number of Gauss-Hermite quadrature points obtained
  via tensor product and classical Smolyak construction. White dots are $D,K$
  combinations where Genz-Keister is advantageous, while for black dots
  Genz-Keister is worse and for gray dots the ratio equals 1.}
  \label{fig:smol_hermitephy_ratio}
\end{figure}

Notice that for $D < 3$, using the Genz-Keister construction results
in more quadrature points than the full tensor product Ansatz. This
can be read off from figures \ref{fig:gk_hermitephy_ratio}
and \ref{fig:gk_hermitephy_ratio_large}.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\linewidth]{./img/gk_hermitephy_ratio.pdf}
  \caption{Ratio of the number of Genz-Keister and Gauss-Hermite tensor product
  points for dimensions $D$ up to 8 and Level $K \leq 12$. White dots are $D,K$
  combinations where Genz-Keister is advantageous, while for black dots
  Genz-Keister is worse and for gray dots the ratio equals 1.}
  \label{fig:gk_hermitephy_ratio}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\linewidth]{./img/gk_hermitephy_ratio_large.pdf}
  \caption{Ratio of the number of Genz-Keister and Gauss-Hermite tensor product
  points for dimensions 1 to 4 and Level $K \leq 32$. White dots are $D,K$
  combinations where Genz-Keister is advantageous, while for black dots
  Genz-Keister is worse and for gray dots the ratio equals 1. Even if not visible here,
  the white boundary will go more to the right and reach dimension $D = 3$ at level $K = 51$.}
  \label{fig:gk_hermitephy_ratio_large}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{./img/monomial_errors_hermitephy_high.pdf}
  \caption{Relative quadrature error for integration of single univariate monomials $x^n$ of increasing degree $n$.
  Each line represents a quadrature rule and the color indicates the number of nodes (colors wrap around once though).
  The number of nodes for each of these rules is:
  $53$, $55$, $57$, $59$, $61$, $63$, $65$, $67$, $69$, $71$, $73$, $75$,  $77$,
  $79$, $81$, $83$, $85$, $87$, $89$, $91$, $93$, $95$, $97$, $99$, $101$, $103$.
  The rules for $K > 25$ become soon highly unstable. A notable exception is the
  last rule with $K = 51$ having $103$ nodes which shows good behavior and
  is of order $103$. This is obviously extremely inefficient for practical
  use.}
  \label{fig:conv_monom_hermite_high}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{./img/monomial_errors_hermitephy_2D.pdf}
  \caption{Quadrature of the bivariate monomials $x^m y^n$ for $0 \leq n, m \leq 50$.
  Each pair $(m,n)$ is color-coded by the lowest level $K$ rule that correctly
  integrates the monomial with a relative error not larger than $10^{-13}$.}
  \label{fig:monomial_errors_hermitephy_2D}
\end{figure}

For testing the quadrature rules in $D$ dimensions, the following integral
over multi-variate monomials with $\vec{n} \in \mathbb{N}_0^D$ is used:
\begin{equation} \label{eq:hermitephy_exact_solution}
  \idotsint \limits_{\vec{x} \in \mathbb{R}^D} \prod_{d=1}^D x_d^{n_d} \exp\left(-x_d^2\right) \di{\vec{x}}
  =
  \frac{1}{2^D} \prod_{d=1}^D \left(1 + (-1)^{n_d}\right) \Gamma\left(\frac{n_d + 1}{2}\right)
\end{equation}
where we know the exact solution in closed form.

\begin{subfigures}
  \label{fig:monomial_errors_hermitephy_multivariate}
  \begin{figure}\centering
    \includegraphics[width=\linewidth]{./img/monomial_errors_hermitephy_multivariate_dimension_2.pdf}
    \caption{Relative errors for the integral \eqref{eq:hermitephy_exact_solution}
    in $D=2$ dimensions. All variables $x_d$ share the same exponent $n$.}
    \label{fig:monomial_errors_hermitephy_multivariate_dimension_2}
  \end{figure}
  \begin{figure}\centering
    \includegraphics[width=\linewidth]{./img/monomial_errors_hermitephy_multivariate_dimension_3.pdf}
    \caption{Relative errors for the integral \eqref{eq:hermitephy_exact_solution}
    in $D=3$ dimensions. All variables $x_d$ share the same exponent $n$.}
    \label{fig:monomial_errors_hermitephy_multivariate_dimension_3}
  \end{figure}
  \begin{figure}\centering
    \includegraphics[width=\linewidth]{./img/monomial_errors_hermitephy_multivariate_dimension_4.pdf}
    \caption{Relative errors for the integral \eqref{eq:hermitephy_exact_solution}
    in $D=4$ dimensions. All variables $x_d$ share the same exponent $n$.}
    \label{fig:monomial_errors_hermitephy_multivariate_dimension_4}
  \end{figure}
  \begin{figure}\centering
    \includegraphics[width=\linewidth]{./img/monomial_errors_hermitephy_multivariate_dimension_5.pdf}
    \caption{Relative errors for the integral \eqref{eq:hermitephy_exact_solution}
    in $D=5$ dimensions. All variables $x_d$ share the same exponent $n$.}
    \label{fig:monomial_errors_hermitephy_multivariate_dimension_5}
  \end{figure}
  \begin{figure}\centering
    \includegraphics[width=\linewidth]{./img/monomial_errors_hermitephy_multivariate_dimension_6.pdf}
    \caption{Relative errors for the integral \eqref{eq:hermitephy_exact_solution}
    in $D=6$ dimensions. All variables $x_d$ share the same exponent $n$.}
    \label{fig:monomial_errors_hermitephy_multivariate_dimension_6}
  \end{figure}
\end{subfigures}


\FloatBarrier
\section{Software}

The complete software used for this project can be downloaded at:

\begin{center}
  \url{https://github.com/raoulbq/kes.git}
\end{center}

and is released as free software under the GNU General Public License.


\FloatBarrier
\section{Future work}

A question is whether it would be computationally more efficient to compute
everything with arbitrary precision floating point ball arithmetic. By doing that
it might be possible to better handle the exponential growth of coefficients.
On the other hand, computing roots and solving for the weights seems to be
the most expensive part already.

By having efficient root isolation and counting algorithms in \texttt{flint} we would
not have to compute all roots of $E_p$ numerically to high precision just for answering
the question if some of them are complex hence marking the whole extension invalid
\footnote{This solution is also not fully satisfying since we can only
decide that a complex root is really complex but not if a candidate is for sure real.}.

Finally, this work is based on empirical studies on the outcome of algorithmic searches.
It would be desirable to have a rigorous mathematical foundation for the claims made.

Some of the techniques presented here could theoretically be generalized to Gegenbauer
polynomials $C_n^{(\alpha)}(x)$ and ultimately Jacobi polynomials $P_n^{(\alpha,\beta)}(x)$.
The parametric nature of these polynomials makes the implementation more complex. Also,
results will depend on the explicit values of these parameters $\alpha$ and $\beta$,


\marginpar{
\cite{szegoe}
\cite{gautschi}
\cite{gautschi-notaris}
\cite{monegato1978_2}
\cite{gautschi-rivlin}
\cite{monegato1982}
\cite{monegato1978_3}
}


\begin{appendix}
\section{Computed Generators}

The tables in this section contain the generator sets $\Lambda$ for all default
rules examined in the last sections. The generators are ordered in the above-mentioned
alternating order.

\begin{table}
  \centering
  \begin{tabular}{|l|ll|}
  \hline
  {}             & Generator                 & Error \\
  \hline
  $\lambda_{0}$  & $0$                       &  $\pm 0$ \\
  $\lambda_{1}$  & $0.77459666924148337704$  &  $\pm 8.9398e-128$ \\
  $\lambda_{2}$  & $0.96049126870802028342$  &  $\pm 2.9519e-127$ \\
  $\lambda_{3}$  & $0.434243749346802558$    &  $\pm 1.9264e-127$ \\
  $\lambda_{4}$  & $0.99383196321275502221$  &  $\pm 1.2033e-125$ \\
  $\lambda_{5}$  & $0.22338668642896688163$  &  $\pm 2.9048e-127$ \\
  $\lambda_{6}$  & $0.88845923287225699889$  &  $\pm 1.6417e-125$ \\
  $\lambda_{7}$  & $0.62110294673722640294$  &  $\pm 3.1186e-126$ \\
  $\lambda_{8}$  & $0.99909812496766759766$  &  $\pm 4.2615e-122$ \\
  $\lambda_{9}$  & $0.11248894313318662575$  &  $\pm 2.0256e-127$ \\
  $\lambda_{10}$ & $0.98153114955374010687$  &  $\pm 6.0247e-122$ \\
  $\lambda_{11}$ & $0.33113539325797683309$  &  $\pm 5.1636e-126$ \\
  $\lambda_{12}$ & $0.92965485742974005667$  &  $\pm 2.6398e-122$ \\
  $\lambda_{13}$ & $0.53131974364437562397$  &  $\pm 1.0295e-124$ \\
  $\lambda_{14}$ & $0.8367259381688687355$   &  $\pm 7.0227e-123$ \\
  $\lambda_{15}$ & $0.70249620649152707861$  &  $\pm 9.7952e-124$ \\
  $\lambda_{16}$ & $0.99987288812035761194$  &  $\pm 9.0618e-115$ \\
  $\lambda_{17}$ & $0.056344313046592789972$ &  $\pm 2.4195e-127$ \\
  $\lambda_{18}$ & $0.99720625937222195908$  &  $\pm 1.446e-114$ \\
  $\lambda_{19}$ & $0.16823525155220746498$  &  $\pm 5.9532e-126$ \\
  $\lambda_{20}$ & $0.98868475754742947994$  &  $\pm 8.3369e-115$ \\
  $\lambda_{21}$ & $0.27774982202182431507$  &  $\pm 1.5333e-124$ \\
  $\lambda_{22}$ & $0.97218287474858179658$  &  $\pm 3.0935e-115$ \\
  $\lambda_{23}$ & $0.38335932419873034692$  &  $\pm 2.7813e-123$ \\
  $\lambda_{24}$ & $0.94634285837340290515$  &  $\pm 9.2169e-116$ \\
  $\lambda_{25}$ & $0.48361802694584102756$  &  $\pm 4.9013e-122$ \\
  $\lambda_{26}$ & $0.9103711569570042925$   &  $\pm 2.6298e-116$ \\
  $\lambda_{27}$ & $0.57719571005204581484$  &  $\pm 8.4648e-121$ \\
  $\lambda_{28}$ & $0.86390793819369047715$  &  $\pm 4.8765e-117$ \\
  $\lambda_{29}$ & $0.66290966002478059546$  &  $\pm 9.9356e-120$ \\
  $\lambda_{30}$ & $0.80694053195021761186$  &  $\pm 8.102e-118$ \\
  $\lambda_{31}$ & $0.73975604435269475868$  &  $\pm 1.0763e-118$ \\
  \hline
  \end{tabular}
  \caption{Generators in the Legendre case $\mathcal{K} = (1,2,4,8,16,32)$
  computed to 20 decimal digits. Rigorous error bounds are provided by ball
  arithmetic.}
\end{table}

\begin{table}
  \centering
  \begin{tabular}{|l|ll|}
  \hline
  {}             & Generator                 & Error \\
  \hline
  $\lambda_{0}$  & $0$                       &  $\pm 0$ \\
  $\lambda_{1}$  & $0.86602540378443864676$  &  $\pm 1.8457e-255$ \\
  $\lambda_{2}$  & $1$                       &  $\pm 0$ \\
  $\lambda_{3}$  & $0.5$                     &  $\pm 4.44e-255$ \\
  $\lambda_{4}$  & $0.96592582628906828675$  &  $\pm 1.6752e-254$ \\
  $\lambda_{5}$  & $0.25881904510252076235$  &  $\pm 2.5144e-255$ \\
  $\lambda_{6}$  & $0.7071067811865475244$   &  $\pm 2.1372e-254$ \\
  $\lambda_{7}$  & $0.99144486137381041114$  &  $\pm 1.9027e-252$ \\
  $\lambda_{8}$  & $0.13052619222005159155$  &  $\pm 3.1477e-255$ \\
  $\lambda_{9}$  & $0.92387953251128675613$  &  $\pm 3.8807e-252$ \\
  $\lambda_{10}$ & $0.38268343236508977173$  &  $\pm 5.1667e-254$ \\
  $\lambda_{11}$ & $0.79335334029123516458$  &  $\pm 1.531e-252$ \\
  $\lambda_{12}$ & $0.60876142900872063942$  &  $\pm 3.995e-253$ \\
  $\lambda_{13}$ & $0.99785892323860350674$  &  $\pm 4.8189e-248$ \\
  $\lambda_{14}$ & $0.065403129230143066815$ &  $\pm 2.1204e-255$ \\
  $\lambda_{15}$ & $0.98078528040323044913$  &  $\pm 1.0712e-247$ \\
  $\lambda_{16}$ & $0.19509032201612826785$  &  $\pm 5.0556e-254$ \\
  $\lambda_{17}$ & $0.94693012949510566426$  &  $\pm 1.0193e-247$ \\
  $\lambda_{18}$ & $0.3214394653031615807$   &  $\pm 9.8952e-253$ \\
  $\lambda_{19}$ & $0.89687274153268830389$  &  $\pm 5.1395e-248$ \\
  $\lambda_{20}$ & $0.442288690219001282$    &  $\pm 1.0802e-251$ \\
  $\lambda_{21}$ & $0.83146961230254523708$  &  $\pm 2.0304e-248$ \\
  $\lambda_{22}$ & $0.55557023301960222474$  &  $\pm 1.4191e-250$ \\
  $\lambda_{23}$ & $0.75183980747897739641$  &  $\pm 5.3441e-249$ \\
  $\lambda_{24}$ & $0.65934581510006886843$  &  $\pm 9.1351e-250$ \\
  \hline
  \end{tabular}
  \caption{Generators in the Chebyshev (first kind) case $\mathcal{K} = (1, 2, 4, 6, 12, 24)$
  computed to 20 decimal digits. Rigorous error bounds are provided by ball
  arithmetic.}
\end{table}

\begin{table}
  \centering
  \begin{tabular}{|l|ll|}
  \hline
  {}             & Generator                 & Error \\
  \hline
  $\lambda_{0}$  & $0$                       &  $\pm 0$ \\
  $\lambda_{1}$  & $0.7071067811865475244$   &  $\pm 1.1302e-255$ \\
  $\lambda_{2}$  & $0.92387953251128675613$  &  $\pm 3.4002e-255$ \\
  $\lambda_{3}$  & $0.38268343236508977173$  &  $\pm 2.4588e-255$ \\
  $\lambda_{4}$  & $0.98078528040323044913$  &  $\pm 1.0265e-253$ \\
  $\lambda_{5}$  & $0.19509032201612826785$  &  $\pm 3.5259e-255$ \\
  $\lambda_{6}$  & $0.83146961230254523708$  &  $\pm 1.0815e-253$ \\
  $\lambda_{7}$  & $0.55557023301960222474$  &  $\pm 2.496e-254$ \\
  $\lambda_{8}$  & $0.99518472667219688624$  &  $\pm 5.6869e-251$ \\
  $\lambda_{9}$  & $0.098017140329560601994$ &  $\pm 3.0746e-255$ \\
  $\lambda_{10}$ & $0.95694033573220886494$  &  $\pm 1.1254e-250$ \\
  $\lambda_{11}$ & $0.29028467725446236764$  &  $\pm 4.1566e-254$ \\
  $\lambda_{12}$ & $0.88192126434835502971$  &  $\pm 5.8436e-251$ \\
  $\lambda_{13}$ & $0.47139673682599764856$  &  $\pm 5.9365e-253$ \\
  $\lambda_{14}$ & $0.77301045336273696081$  &  $\pm 2.4054e-251$ \\
  $\lambda_{15}$ & $0.63439328416364549822$  &  $\pm 6.3821e-252$ \\
  $\lambda_{16}$ & $0.99879545620517239271$  &  $\pm 3.7653e-245$ \\
  $\lambda_{17}$ & $0.049067674327418014255$ &  $\pm 3.1008e-255$ \\
  $\lambda_{18}$ & $0.98917650996478097345$  &  $\pm 1.0269e-244$ \\
  $\lambda_{19}$ & $0.14673047445536175166$  &  $\pm 5.0159e-254$ \\
  $\lambda_{20}$ & $0.9700312531945439926$   &  $\pm 9.1895e-245$ \\
  $\lambda_{21}$ & $0.24298017990326388995$  &  $\pm 1.0345e-252$ \\
  $\lambda_{22}$ & $0.94154406518302077841$  &  $\pm 7.649e-245$ \\
  $\lambda_{23}$ & $0.33688985339222005069$  &  $\pm 1.6499e-251$ \\
  $\lambda_{24}$ & $0.90398929312344333159$  &  $\pm 3.3936e-245$ \\
  $\lambda_{25}$ & $0.42755509343028209432$  &  $\pm 2.5664e-250$ \\
  $\lambda_{26}$ & $0.8577286100002720699$   &  $\pm 1.4468e-245$ \\
  $\lambda_{27}$ & $0.51410274419322172659$  &  $\pm 3.7758e-249$ \\
  $\lambda_{28}$ & $0.80320753148064490981$  &  $\pm 4.3992e-246$ \\
  $\lambda_{29}$ & $0.59569930449243334347$  &  $\pm 3.0138e-248$ \\
  $\lambda_{30}$ & $0.74095112535495909118$  &  $\pm 1.1218e-246$ \\
  $\lambda_{31}$ & $0.67155895484701840063$  &  $\pm 1.8774e-247$ \\
  \hline
  \end{tabular}
  \caption{Generators in the Chebyshev (second kind) case $\mathcal{K} = (1, 2, 4, 8, 16, 32)$
  computed to 20 decimal digits. Rigorous error bounds are provided by ball
  arithmetic.}
\end{table}

\begin{table}
  \centering
  \begin{tabular}{|l|ll|}
  \hline
  {}             & Generator                & Error \\
  \hline
  $\lambda_{0}$  & $0$                      & $\pm 0$ \\
  $\lambda_{1}$  & $1.2247448713915890491$  & $\pm 2.6102e-255$ \\
  $\lambda_{2}$  & $2.9592107790638377223$  & $\pm 3.2633e-254$ \\
  $\lambda_{3}$  & $0.52403354748695764515$ & $\pm 8.0828e-255$ \\
  $\lambda_{4}$  & $2.0232301911005156592$  & $\pm 4.6195e-254$ \\
  $\lambda_{5}$  & $4.4995993983103888029$  & $\pm 7.1244e-253$ \\
  $\lambda_{6}$  & $0.87004089535290290013$ & $\pm 3.6256e-254$ \\
  $\lambda_{7}$  & $3.66777421594633786$    & $\pm 1.1448e-252$ \\
  $\lambda_{8}$  & $1.8357079751751868738$  & $\pm 4.852e-253$ \\
  $\lambda_{9}$  & $2.2665132620567880275$  & $\pm 8.9175e-253$ \\
  $\lambda_{10}$ & $6.3759392709822359517$  & $\pm 3.8855e-251$ \\
  $\lambda_{11}$ & $0.17606414208200893503$ & $\pm 6.8732e-255$ \\
  $\lambda_{12}$ & $5.6432578578857450628$  & $\pm 1.1977e-250$ \\
  $\lambda_{13}$ & $1.5794121348467670857$  & $\pm 3.6322e-253$ \\
  $\lambda_{14}$ & $5.0360899444730939687$  & $\pm 1.2618e-250$ \\
  $\lambda_{15}$ & $2.5705583765842967091$  & $\pm 5.1481e-252$ \\
  $\lambda_{16}$ & $4.0292201405043713648$  & $\pm 6.5727e-251$ \\
  $\lambda_{17}$ & $3.3491639537131949774$  & $\pm 2.7947e-251$ \\
  \hline
  \end{tabular}
  \caption{Generators in the Hermite case $\mathcal{K} = (1, 2, 6, 10, 16)$
  computed to 20 decimal digits. Rigorous error bounds are provided by ball
  arithmetic. We can confirm the claim made in \cite{genz_keister} for their
  table 4 (both columns) and assure that all digits shown are indeed correct.}
\end{table}

\begin{table}
  \centering
  \begin{tabular}{|l|ll|}
  \hline
  {}             & Generator                & Error \\
  \hline
  $\lambda_{18}$ & $12.371183263294440156$  & $\pm 6.2996e-242$ \\
  $\lambda_{19}$ & $0.36668252574926773363$ & $\pm 1.7765e-253$ \\
  $\lambda_{20}$ & $11.773315693849850411$  & $\pm 2.3346e-240$ \\
  $\lambda_{21}$ & $0.66761453794663251987$ & $\pm 1.6969e-252$ \\
  $\lambda_{22}$ & $11.279571841264790728$  & $\pm 2.642e-239$ \\
  $\lambda_{23}$ & $1.0853772883690724485$  & $\pm 3.7943e-251$ \\
  $\lambda_{24}$ & $10.839884501585234819$  & $\pm 2.0142e-238$ \\
  $\lambda_{25}$ & $1.3554874833640409297$  & $\pm 2.0233e-250$ \\
  $\lambda_{26}$ & $10.435144794449726187$  & $\pm 9.2267e-238$ \\
  $\lambda_{27}$ & $1.8804002593778771426$  & $\pm 3.9786e-249$ \\
  $\lambda_{28}$ & $10.055514590896118546$  & $\pm 3.4517e-237$ \\
  $\lambda_{29}$ & $2.4894835291142853745$  & $\pm 5.0127e-247$ \\
  $\lambda_{30}$ & $9.6950986498409657256$  & $\pm 9.4588e-237$ \\
  $\lambda_{31}$ & $2.7429887276487330543$  & $\pm 3.9256e-246$ \\
  $\lambda_{32}$ & $9.3500178360366242267$  & $\pm 1.9321e-236$ \\
  $\lambda_{33}$ & $3.1578423043107310587$  & $\pm 6.5944e-245$ \\
  $\lambda_{34}$ & $9.0175517361800331664$  & $\pm 3.4879e-236$ \\
  $\lambda_{35}$ & $3.5581744596318809581$  & $\pm 1.268e-243$ \\
  $\lambda_{36}$ & $8.6957029638952971694$  & $\pm 5.2545e-236$ \\
  $\lambda_{37}$ & $3.7936922531585261377$  & $\pm 5.3856e-243$ \\
  $\lambda_{38}$ & $8.3829544155838454626$  & $\pm 5.7185e-236$ \\
  $\lambda_{39}$ & $4.2688636547893383582$  & $\pm 7.0628e-242$ \\
  $\lambda_{40}$ & $8.0781250284796943353$  & $\pm 5.6882e-236$ \\
  $\lambda_{41}$ & $4.6477303329076984149$  & $\pm 1.4317e-240$ \\
  $\lambda_{42}$ & $7.7802807323602445651$  & $\pm 4.7409e-236$ \\
  $\lambda_{43}$ & $4.8019262436547872092$  & $\pm 3.184e-240$ \\
  $\lambda_{44}$ & $7.4886797763487223782$  & $\pm 3.3395e-236$ \\
  $\lambda_{45}$ & $5.2754516328221667421$  & $\pm 2.5212e-239$ \\
  $\lambda_{46}$ & $7.2027436504485393396$  & $\pm 1.7826e-236$ \\
  $\lambda_{47}$ & $5.4830796220220625119$  & $\pm 6.2053e-239$ \\
  $\lambda_{48}$ & $6.9220548983808420548$  & $\pm 7.4588e-237$ \\
  $\lambda_{49}$ & $5.8591159720395398957$  & $\pm 1.8806e-238$ \\
  $\lambda_{50}$ & $6.6464009334963516572$  & $\pm 2.1116e-237$ \\
  $\lambda_{51}$ & $6.1118124629258834825$  & $\pm 3.619e-238$ \\
  \hline
  \end{tabular}
  \caption{Higher generators in the Hermite case $\mathcal{K} = (1, 2, 6, 10, 16, 68)$
  computed to 20 decimal digits. Rigorous error bounds are provided by ball
  arithmetic.}
\end{table}

\end{appendix}


\bibliographystyle{plain}
\bibliography{kes}

\end{document}
