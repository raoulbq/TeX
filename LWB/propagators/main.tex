\input{./header.tex}

\begin{document}

\input{sections/title.tex}

\clearemptydoublepage

\mbox{}
\vfill
\input{sections/abstract.tex}
\vfill
\tableofcontents

\clearpage

\listoffigures
\listofalgorithms

\clearemptydoublepage

% \input{./introduction.tex}
% \input{./wavefunction_propagation.tex}
% \input{./wavepackets.tex}
% \input{./observables.tex}
% \input{./wavepacket_propagation.tex}
% \input{./results.tex}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% TODO: move to separate file when done

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage
\section{Introduction}

Summary of the structure of the remaining report
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\cite{GH_convsemiclassical}
Semiclassical time-dependent Schrödinger equation
%
\begin{align}
	\label{math:tdse}
	\im \eps \; \del_t \psi (\bvec{x},t) = \opH (\eps) \; \psi (\bvec{x},t)
\end{align}
%
with wave function $\psi(\bvec{x},t)$ depending on the spatial variables $\bvec{x} = (x_1,\dots,x_D) \in \R^D$ and the time variable $t \in \R$.

Hamiltonian
\begin{align}
	\opH = \opT + \opV = \opT + \opU + \opW
\end{align}
\begin{align}
	\opT &= - \sum_{j=1}^D \frac{\eps^2}{2m_j} \frac{\del^2}{\del x_j^2} \\
	\opV &= V(x)
\end{align}

Small semiclassical parameter $\eps$ plays an important role in the stability of numerical schemes

Classical dynamics in the limit $\eps \rightarrow 0$, quantum mechanics for $\eps = 1$.

In particular, as underlined in \cite{GH_convsemiclassical}, a small parameter $\eps$ can often impose severe constraints on the step size of splitting methods and significantly increase the error. For example, the error was shown to be proportional to $\sim \eps^{-2})$ for Lie-Trotter splitting, Strang splitting and other related methods.

Motivation - why is time propagation important?
Background

Describe what is going to happen in the rest of the paper


Hagedorn wavepackets explained in \cite{FGL_semiclassical_dynamics}

The solution to the Schrödinger equation can be approximated as a finite linear combination if Hagedorn function \cite{FGL_semiclassical_dynamics}
\begin{align}
	\label{math:hagedornwp}
	\psi(x,t) \approx u(x,t)
	= e^{\im S(t)/\eps} \sum_{k \in \K} c_k(t) \varphi_k^\eps [ q(t),p(t),Q(t),P(t) ] (x)
\end{align}

$\K$ finite multi index set

As the idea behind the splitting the Hamiltonian operator is so central to the time propagation approach used here, we repeat the most important findings from  \cite{FGL_semiclassical_dynamics}:
\begin{itemize}
	\item The free linear Schrödinger equation ($\opV=0$) can be solved exactly and the wavepacket remains in Hagedorn wavepacket form \ref{math:hagedornwp}.
		For time propagation, only the parameters $\bvec{\Pi},S$ need to be updated, the coefficients $\{c_k\}_{k \in \K}$ remain unchanged.
	\item The Schrödinger equation \ref{math:tdse} can be solved exactly in a pure quadratic potential, i.e. in a potential $\opV=U(\bvec{x})$ with $\opT=0$.
		Again, time propagation only affects the parameters $\bvec{\Pi},S$, not the coefficients $\{c_k\}_{k \in \K}$.
	\item In the case of an arbitrary potential $\opV = W(\bvec{x})$ that is not quadratic, a set of Galerkin functions can be propagated by adapting the coefficients $\{c_k\}_{k \in \K}$ without changing the parameters $\bvec{\Pi},S$.
\end{itemize}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Quantum Time Propagation, Operator Splitting and Hagedorn Propagator}

check propositions in hagedorn paper.

how does one analytically propagate?
operators don't commute
operator splitting to the rescue


The Hamiltonian is split into three parts
where $\opU(\bvec{q}(t),\bvec{x})$ is the second order Taylor approximation of the potential $\opV$ around $\bvec{q}(t)$ and $\opW(\bvec{q}(t),\bvec{x})$ is the corresponding remainder.

$\opV = V(\bvec{x}) = U(\bvec{q},\bvec{x}) + W(\bvec{q},\bvec{x})$

\begin{align}
	U(\bvec{q},\bvec{x}) &:= V(\bvec{q}) + \nabla V(\bvec{q}) (\bvec{x}-\bvec{q})
	+ \frac{1}{2} (\bvec{x}-\bvec{q})^T \nabla^2 V(\bvec{q}) (\bvec{x}-\bvec{q}) \\
	W(\bvec{q},\bvec{x}) &:= V(\bvec{x}) - U(\bvec{q},\bvec{x})
\end{align}

The kinetic part $\opT$ and the quadratic part of the potential $\opU$ can be integrated exactly (see \cite{FGL_semiclassical_dynamics}).


The search for accurate time propagation schemes has become an area of research by itself, see papers of A and B


\clearpage
\section{Time evolution schemes}

present a selection of propagators

\subsection{Common building blocks for Quantum Time Propagators}
%

General notes: what variables are accessible?


The time stepping with operators $\opT$ and $\opV = U(\op{x})$ follows directly from the propositions in \cite{FGL_semiclassical_dynamics} and is outlined in the algorithms \ref{alg:stepT} and \ref{alg:stepU} respectively.

As pointed out in the introduction, the time propagation for non-quadratic potentials $W(\bvec{x})$ can be achieved by updating the coefficients $\{ c_k \}_{k \in \K}$.
The update rule is
%
\begin{align}
	\bvec{c}(t) = \exp \left( - \frac{\im t}{\eps} \bmat{F} \right) \bvec{c}(0)
\end{align}
%
where the matrix $\bmat{F} = \{ f_{k,l} \}_{k,l \in \K}$ has entries
%
\begin{align}
	f_{k,l} = \matrixel{\varphi_k}{W}{\varphi_l}
	= \int_{\R^N} \conj{\varphi_k(\bvec{x})} W(\bvec{x}) \varphi_l(\bvec{x}) \; \dif \bvec{x}
\end{align}


\begin{algorithm}[h]
	\caption{Propagate with Kinetic Energy Operator $\opT$}
	\label{alg:stepT}
	\begin{algorithmic}
	\State
	\Procedure{stepT}{$\eta$}
		\State $q = q + \eta M^{-1} p$
		\State $Q = Q + \eta M^{-1} P$
		\State $S = S + \frac{\eta}{2} p^T M^{-1} p$
	\EndProcedure
	\end{algorithmic}
\end{algorithm}
%
\begin{algorithm}[h]
	\caption{Propagate with (Quadratic) Potential Energy Operator}
	\label{alg:stepU}
	\begin{algorithmic}
	\State
	\Procedure{stepU}{$\eta$}
		\State $p = p - \eta \nabla V (q)$
		\State $P = P - \eta \nabla^2 V (q) Q$
		\State $S = S - \eta V (q)$
	\EndProcedure
	\end{algorithmic}
\end{algorithm}













\subsection{Hagedorn Propagator}
\label{sub:hagedorn_propagator}
%
The Hagedorn propagator, shown in algorithm \ref{alg:hagedorn}, is one of the simplest propagators that can be built by exploiting the numerical aspects discussed above.
As pointed out in \cite{FGL_semiclassical_dynamics}, this simple time stepping scheme has many beneficial properties like the preservation of the $L^2$ norm of the wavepacket, time reversibility and stability in the classical limit $\eps \rightarrow 0$.
Also, in the limit of $\K$ approaching the full basis set, the variational approximation used for the propagation with the non-quadratic part $\opW$ becomes exact.
\begin{algorithm}[h]
	\caption{Single timestep with Hagedorn propagator}
	\label{alg:hagedorn}
	\begin{algorithmic}
	\State
		\Procedure{Hagedorn.Propagate}{$\Dt$}
		\State
			\State \Call{stepT}{$\frac{\Dt}{2}$}
			\Comment{Step of size $\Dt/2$ with $\opT$}
			\State \Call{stepU}{$\Dt$}
			\Comment{Step of size $\Dt$ with $\opU$}
			\State \Call{stepW}{$\Dt$}
			\Comment{Step of size $\Dt$ with $\opW$}
			\State \Call{stepT}{$\frac{\Dt}{2}$}
			\Comment{Step of size $\Dt/2$ with $\opT$}
		\State
		\EndProcedure
	\end{algorithmic}
\end{algorithm}


\subsection{Semiclassical Propagator}
\label{sub:semiclassical_propagator}
%
The central idea of the semiclassical splitting, as introduced in \cite{GH_convsemiclassical},
is to split the propagation with operators $\opT$ and $\opU$ into many smaller, alternating steps, thereby reducing the dominating error\footnote{for small $\eps$,
the main source of error lies in the updating of $\Pi$ and $S$} in the update of $\bvec{\Pi}$ and $S$.
While there is some additional computational cost caused by a higher number of updates for the parameters $\bvec{\Pi}$ and $S$, the extra effort is usually negligible compared to the propagation with $\opW$ which requires numerical evaluation of multi-dimensional integrals. 
\par\medskip
%
In addition, due to the numerical properties of the semiclassical splitting, 
it even allows to take larger timesteps $\Dt$ than conventional
splitting methods like the YL-splitting, while maintaining the same error.
\par\medskip
%
Finally and most importantly, the error is no longer proportional to $1/\eps^2$ but instead
scales linearly in the semiclassical parameter $\eps$,
meaning that a smaller $\eps$ will now reduce the error instead of increasing it.
The error scales with $\eps (\Delta t)^2$ for the semiclassical splitting using the Y-splitting,
but the dependency on the timestep $\Delta t$ can be improved even further by using different
splittings which effectively corresponds to higher order coefficient pairs $w_T$ and $w_U$.
\par\medskip
%
The steps for the semiclassical propagator are shown in algorithm \ref{alg:semiclassical} and 
further details can be found in the original paper \cite{GH_convsemiclassical}.
%
\begin{algorithm}[h]
	\caption{Single timestep with Semiclassical propagator}
	\label{alg:semiclassical}
	\begin{algorithmic}
	\State
	\Procedure{Semiclassical.Propagate}{$\Dt$}
		\State
		\State $M := \lceil 1 + \frac{\sqrt{\Dt}}{\eps^{3/4}} \rceil$
		\Comment{Divide $\Dt$ into smaller steps}
		\State
		\State \Call{intSplit}{$\frac{\Dt}{2}, \frac{M}{2}, \{ w_T, w_U \}$}
		\Comment{$M/2$ split steps with $T+U$}
		\State \Call{stepW}{$\Dt$}
		\Comment{Single step with $W$}
		\State \Call{intSplit}{$\frac{\Dt}{2}, \frac{M}{2}, \{ w_T, w_U \}$}
		\Comment{$M/2$ split steps with $T+U$}
		\State
	\EndProcedure
	\end{algorithmic}
\end{algorithm}


\subsection{Magnus Propagator}
\label{sub:magnus_propagator}
%
As was noted by Magnus in \cite{Magnus1954}, the solution to a differential equation of the form
%
\begin{align}
	y'(t) = a(t) y(t) \qquad t \ge 0
\end{align}
%
can be written as
%
\begin{align}
	\label{math:magnussolution}
	y(t) = e^{\sigma (t)} y_0
\end{align}
%
where $\sigma (t)$ is an infinite sum of iterated integrals and commutators, also known as the Magnus series.
The idea behind the Magnus approximation was extensively studied using the Baker-Campbell-Hausdorff (BCH) formula and rooted trees techniques, more details can be found in \cite{Blanes2006}, \cite{Blanes2000}, \cite{Iserles1999}.
\par\medskip
%
In order to approximate the solution from equation \ref{math:magnussolution}, one can take only a finite number of terms from this series whereby a truncation error is committed
(additional error sources in this method are the discretization of integrals and the approximation of matrix exponentials).
%
This method of the Magnus Propagator has several beneficial numerical properties that are described in \cite{Iserles1999}.
In particular, for solutions that evolve within a Lie group, the same holds for the approximate numerical solution calculated through a truncated Magnus series. 
It was also shown in the same paper that the Magnus series can compete with - and in fact may even outplay - classical schemes like Runge-Kutta or Gauss-Legendre.
Although the method is not a symplectic scheme in the usual sense, \cite{Iserles1999} has shown that in practical applications it conserves the Hamiltonian energy just as well as symplectic integrators.
\par\medskip
Moreover, the numerical stability and good performance of the Magnus propagator are not limited to problems where the solution evolves within a Lie Group, but also apply to various problems when this is not the case.
Algorithm \ref{alg:magnus} shows the \emph{MG4} method as presented in \cite{Iserles1999} and implemented in C++ in the scope of this work.

\begin{algorithm}[h]
	\caption{Single timestep with Magnus propagator}
	\label{alg:magnus}
	\begin{algorithmic}
	\State
	\Procedure{Magnus.Propagate}{$\Dt$}
		\State
		\State $h_1 = \frac{3-\sqrt{3}}{6} \Dt$, $h_2 = \frac{2\sqrt{3}}{6} \Dt$
		\Comment Gauss-Legendre coefficients on $[0,\Dt]$
		\State $M_{k} = 1+\sqrt{h_{k} \eps^{-3/8}}, \quad k=1,2$
		\Comment number of timesteps for splitting
		\State
		\State \Call{intSplit}{$h_1, M_1, \{w_T, w_U\}$}
		\Comment advance till $\frac{3-\sqrt{3}}{6} \Dt$
		\State $\bmat{A}_1 = - \frac{\im}{\eps^2} \cdot$ \Call{buildF}{\mbox{}}
		\Comment temporarily store interaction matrix
		\State \Call{intSplit}{$h_2, M_2, \{w_T, w_U\}$}
		\Comment advance till $\frac{3+\sqrt{3}}{6} \Dt$
		\State $\bmat{A}_2 = - \frac{\im}{\eps^2} \cdot$ \Call{buildF}{\mbox{}}
		\Comment temporarily store interaction matrix
		\State $\bmat{\Sigma} = \frac{1}{2} \Dt (\bmat{A}_1 + \bmat{A}_2) + \frac{\sqrt{3}}{12} (\Dt)^2 (\bmat{A}_2 \cdot \bmat{A}_1 - \bmat{A}_1 \cdot \bmat{A}_2)$
		\Comment compute $\sigma (t)$
		\State $\bvec{c} = \exp \left( \bmat{\Sigma} \right) \bvec{c}$
		\Comment update coefficients
		\State \Call{intSplit}{$h_1, M_1, \{w_T, w_U\}$}
		\Comment advance till $\frac{6}{6} \Dt$
		\State
	\EndProcedure
	\end{algorithmic}
\end{algorithm}

\subsection{Processing Propagators}
\label{sub:pre764_propagator}
%
The idea of processing propagators is to carry out the time evolution with a Hamiltonian that is slightly perturbed from the initial one.
To achieve this, a pre and post processing step is applied. \\
More formally, it holds that
%
\begin{align}
	e^{- \Dt \opH (\Dt)} = e^P e^{- \Dt K} e^{-P}
\end{align}
%
where the pre and post processing steps are applied via the multiplication with matrices $e^P$ and $e^{-P}$ (also referred to as \emph{processors}).
While the processors only need to be applied once at the very beginning and end of the propagation (in order to return to the original Hamiltonian), the multiplication with the \emph{kernel} $e^{-\Dt K}$ is repeated $M$ times, once for every timestep. \\
As a consequence, one wants to choose the processor $e^P$ in such a way that the evaluation of the kernel $e^{-\Dt K}$ is as simple as possible, requiring a minimum of expensive function evaluations.
\par\medskip
%
Unlike most commonly used integration schemes, the family of processing propagators are symplectic integrators.
They are not suited for every kind of Hamiltonian, and the work of Blanes, Casas and Ros in \cite{Blanes1999} gives a method for finding the  neccessary conditions that need to be satisfied in order for processing methods to be applicable.
\par\medskip
%
Algorithm \ref{alg:pre764} presents the \emph{Pre764} processing method which is a ?sixth? order processing method that was derived in \cite{Blanes1999}.
%
\begin{algorithm}[h]
	\caption{Single timestep with Pre764 propagator}
	\label{alg:pre764}
	\begin{algorithmic}
	\State
	\Procedure{Pre764.PrePropagate}{$\Dt$}
		\State
		\State $M = 1+ \left\lfloor \sqrt{\Dt \eps^{-\frac{3}{4}}} \right\rfloor$
		\Comment compute number of time steps
		\For{$j=0,...,v-1$} \Comment $v=6$ for Pre(7,6,4)
			\State \Call{intSplit}{$-Z_j \Dt, M, \{w_T, w_U\}$}
			\Comment $M$ alternating steps with $\opT$ and $\opU$
			\State \Call{stepW}{$\upic, -Y_j \Dt$}
			\Comment single step with $\opW$
		\EndFor
		\State
	\EndProcedure
		\\\hrulefill
		\State
	\Procedure{Pre764.Propagate}{$\Dt$}
		\State
		\State $M = 1+ \left\lfloor \sqrt{\Dt \eps^{-\frac{3}{4}}} \right\rfloor$
		\Comment compute number of time steps
		\For{$j=0,...,k-1$} \Comment $k=4$ for Pre(7,6,4)
			\State \Call{stepW}{$\alpha_j \Dt$}
			\Comment single step with $\opW$
			\State \Call{intSplit}{$\beta_j \Dt, M, \{w_T, w_U\}$}
			\Comment $M$ alternating steps with $\opT$ and $\opU$
		\EndFor
		\State
	\EndProcedure
		\\\hrulefill
		\State
	\Procedure{Pre764.PostPropagate}{$\Dt$}
		\State
		\State $M = 1+ \left\lfloor \sqrt{\Dt \eps^{-\frac{3}{4}}} \right\rfloor$
		\Comment compute number of time steps
		\For{$j=v-1,...,0$} \Comment $v=6$ for Pre(7,6,4)
			\State \Call{stepW}{$Y_j \Dt$}
			\Comment single step with $\opW$
			\State \Call{intSplit}{$Z_j \Dt, M, \{w_T, w_U\}$}
			\Comment $M$ alternating steps with $\opT$ and $\opU$
		\EndFor
		\State
	\EndProcedure
	\end{algorithmic}
\end{algorithm}


\subsection{McL Propagators}
\label{sub:mcl_propagator}
%
TODO: add comments to algorithm
TODO: Add 84 algorithm
TODO: compute M, compute dt
\begin{algorithm}[h]
	\caption{Single timestep with McL propagators}
	\label{alg:mcl}
	\begin{algorithmic}
		\Procedure{McL42.Propagate}{$\Dt$}
			\State \Call{intSplit}{$A_0 \dt, M, \{w_T, w_U\}$}
			\State \Call{stepW}{$B_0 \dt$}
			\State \Call{intSplit}{$A_1 \dt, M, \{w_T, w_U\}$}
			\State \Call{stepW}{$B_1 \dt$}
			\State \Call{intSplit}{$A_2 \dt, M, \{w_T, w_U\}$}
		\EndProcedure
		\\\hrulefill
		\Procedure{McL84.Propagate}{$\Dt$}
			\State \Call{intSplit}{$A_0 \dt, M, \{w_T, w_U\}$}
			\State \Call{stepW}{$B_0 \dt$}
			\State \Call{intSplit}{$A_1 \dt, M, \{w_T, w_U\}$}
			\State \Call{stepW}{$B_1 \dt$}
			\State \Call{intSplit}{$A_2 \dt, M, \{w_T, w_U\}$}
			\State \Call{stepW}{$B_2 \dt$}
			\State \Call{intSplit}{$A_3 \dt, M, \{w_T, w_U\}$}
		\EndProcedure
	\end{algorithmic}
\end{algorithm}


\clearpage
\section{Implementation in C++}

\cite{libwaveblocks}
What was the main challenge? What was controllable (which code could be changed), what not? 
Quick alternating o

The challenges were twofold: 
First, identifying of all the common basic building blocks and expressing all algorithms in terms of these components
Second, implementing all basic building blocks in a generic but efficient manner
Third, minimize the overhead for switching between function calls

 - encapsulate the functionality in a clean interface without loosing flexibility and 
 - write efficient/fast code

Tell how each of these challenges were overcome


Motivation of software design choices

	- Why class structure/inheritance (explain hierarchy)
	- CRTP / static polymorphism \cite{C_CRTP}
	- recognizing IP
	- callback function
	- implementation of intSplit (TU,UT, partial specialization)
	- polymorphism through enable-if




\clearpage
\section{Benchmark / Case Study / Example}


\clearpage
\section{Conclusion}

final observations
suggestions for future work














%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%































\clearemptydoublepage

\appendix
% \input{./deriv_ew.tex}
% \input{./color_code.tex}
% \input{./ack.tex}

\clearemptydoublepage

\bibliographystyle{plain}
\bibliography{references,mt,bt,chem,wp,own,propagators}

\end{document}
