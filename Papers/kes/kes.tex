\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{color}
\definecolor{linkcol}{rgb}{0,0,0.4}
\definecolor{citecol}{rgb}{0.5,0,0}
\usepackage[pagebackref,hyperindex=true]{hyperref}
\hypersetup{colorlinks=true,linkcolor=linkcol,citecolor=citecol,urlcolor=linkcol}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{footnote}

\include{header_math}


\synctex=1
\parindent 0pt

%opening
\title{Exhaustive search for higher-order Kronrod-Patterson Extensions}
\author{R. Bourquin}

\begin{document}

\maketitle


\section{Mathematical principles}

The $n$ nodes $\{\gamma_i\}_{i=1}^{n}$ of any Gauss quadrature rule for a
given density distribution $\omega(t)$ can be found as the roots of a
polynomial $P_n$ of degree $n$. The existence of corresponding weights
$\{\omega_i\}_{i=1}^{n}$ is the ensured by the following theorem from
\cite{mehrotra-papp} originally stated by Kronrod in \cite{kronrod}:

\begin{theorem}
  \label{th:existence_weights}
  For every probability density function $\omega(t)$ and every set
  $\{\gamma_i\}_{i=1}^{n} \subset \mathbb{R}$ of $n$ nodes there exists
  a set of unique weights $\{\omega_i\}_{i=1}^{n}$ such that the quadrature
  Formula for integration with respect to $\omega(t)$ has a polynomial
  degree of exactness of at least $n-1$. These weights are the unique solution
  of the linear system of equations:
  \begin{equation}
    \label{eq:linsys_for_weights}
    \sum_{i=1}^n \omega_i \gamma_i^k = \int_{\Omega} t^k \omega(t) \di{t}
  \end{equation}
  for $k = 0, \ldots, n-1$.
\end{theorem}

Next we need another theorem giving the conditions under which we can
extend a given set of nodes by a bunch of new nodes.

\begin{theorem}
  \label{th:defining_extension}
  Let $\omega(t)$ be the probability density function of a distribution
  supported on $\Omega \subseteq \mathbb{R}$ with finite moments. Let $P_n(t)$
  be a univariate polynomial of degree $n$ with $n$ distinct real roots,
  and suppose that there exists a polynomial $E_p$ of degree $p$ satisfying:
  \begin{equation}
    \label{eq:defining_extension}
    \int_\Omega P_n(t) E_p(t) t^i \omega(t) \di(t) = 0
  \end{equation}
  for all $i = 0, \ldots, p-1$. Assume further that the roots of $E_p$
  are all real and of multiplicity one, and distinct from
  those of $P_n$. Then there exists a qudrature formula supported on the
  roots of $P_n E_p$, whose degree of polynomial exactness is at least
  $n + 2p -1$.
\end{theorem}

A simple proof of this theorem is given in the original article \cite{mehrotra-papp}.

\marginpar{
\cite{genz-keister}
\cite{laurie}
\cite{patterson1968}
\cite{kahaner-monegato}
\cite{monegato1976}
}

\section{Algorithmic procedure}

The main algorithm consists of three steps building upon each other.

\begin{itemize}
  \item Given the polynomial $P_n(t)$ of degree $n$ defining the rule
    with nodes $\{\gamma_i\}_{i=1}^{n}$ and weights $\{\omega_i\}_{i=1}^{n}$.
  \item Choose $p \geq 1$.
    Find a new polynomial $E_p(t)$ with $\deg E_p = p$ such that:
    \begin{equation}
      \int_{\Omega} P_n(t) \, E_p(t) \, t^i \, \omega(t) \, \di{t} = 0
    \end{equation}
    for all $i = 0, \ldots, p-1$, see theorem \ref{th:defining_extension}.
    We require that $E_p$ is monic and obtain a square linear system.
    If this system is solvable, then the extension $E_p$ exists.
    \marginpar{Go into details with "exists`` and the like}
    Otherwise we can \emph{not} extend the given $n$ point rule by
    adding exactly $p$ new nodes to a $n+p$ point rule.
  \item Compute the roots $\{\gamma^\prime_i\}_{i=1}^{p}$ of $E_p$.
    If not all roots lie within the region $\Omega$ then this extension
    does not construct a valid quadrature rule.
  \item Compute the weights $\{\omega^\prime_i\}_{i=1}^{n+p}$ for the new
    quadrature rule. It is important to note that the weights of the old
    unextended rule usually will change too. Hence it is not possible to
    compute only new weights $\{\omega^\prime_i\}_{i=n+1}^{p}$ but we must
    recompute all $n+p$ weights at once. For the unified final set of nodes:
    \begin{equation}
      \{\gamma_i\}_{i=1}^{n+p} := \{\gamma_i\}_{i=1}^{n} \cup \{\gamma^\prime_i\}_{i=1}^{p}
    \end{equation}
    we compute the weights by formula \eqref{eq:linsys_for_weights}:
    \begin{equation}
      \sum_{i=1}^{n+p} \omega^\prime_i t_i^k = \int_{\Omega} t^k \omega(t) \di(t)
    \end{equation}
    for all $k=0, \ldots, n+p-1$. This is again a linear system
    of equations. The right hand side we have the moments of the
    distribution $\omega(t)$. It can happen that some of the weights
    are negative. This might affect the overall stability on the quadrature
    rule but is tolerated for now.
\end{itemize}

The steps for computing a single extension $E_p$ of $P_n$ are shown in pseudo-code
in algorithm \eqref{alg:find_extension}. Another version computing iteratively
multiple nested extensions is shown in \eqref{alg:find_multiextension}.


\subsection{Finding extensions}

The general degree $p$ monic polynomial $E_p$ with symbolic coefficients is
written as:

\begin{equation}
  E_p(t) := t^p + \sum_{k=0}^{p-1} a_k t^k
\end{equation}

and we need to determine the set of coefficients $\{a_i\}_{i=0}^{p-1}$.
Applying next the theorem \ref{th:defining_extension} from above and starting
with the integral formulation \eqref{eq:defining_extension} we find step by step:

\begin{equation}
\begin{split}
  \int_\Omega P_n(t) E_p(t) t^i \omega(t) \,\di(t)
  & = \int_\Omega P_n(t) \left(t^p + \sum_{k=0}^{p-1} a_k t^k\right) t^i \omega(t) \,\di(t) \\
  & = \int_\Omega P_n(t) t^p t^i \omega(t) \,\di(t)
    + \int_\Omega P_n(t) \left(\sum_{k=0}^{p-1} a_k t^k\right) t^i \omega(t) \,\di(t) \\
  & = \sum_{k=0}^{p-1} a_k \int_\Omega P_n(t) t^k t^i \omega(t) \,\di(t)
    + \int_\Omega P_n(t) t^p t^i \omega(t) \,\di(t) \,.
\end{split}
\end{equation}

Now it is time to remember that this integral should equate zero. Hence we find
from the last line the following linear system $\mat{A} \vec{a} = \vec{r}$
for the unknown coefficients $\vec{a} := \{a_i\}_{i=0}^{p-1}$ as:

\begin{equation}
  \label{eq:linsys_for_extension}
  \begin{bmatrix}
    {}     & \vdots                                        & {} \\
    \hdots & \int_\Omega P_n(t) t^k t^i \omega(t) \,\di(t) & \hdots \\
    {}     & \vdots                                        & {} \\
  \end{bmatrix}
  \begin{pmatrix}
    a_0 \\
    \vdots \\
    a_k \\
    \vdots \\
    a_{p-1}
  \end{pmatrix}
  =
  \begin{pmatrix}
  \vdots \\
  - \int_\Omega P_n(t) t^p t^i \omega(t) \,\di(t) \\
  \vdots \\
  \end{pmatrix}
\end{equation}

where the first index $i = 0, \ldots, p-1$ runs along a column
and the second index $k = 0, \ldots, p-1$ runs along any row
of the $p \times p$ matrix. On the right hand side we have essentially
a bunch of moments of the probability density distribution $\omega(t)$.
Provided a closed form for the moment generating function exists,
this vector can be computed very easily.


\subsection{Rational moments}

A limitation of our current implementation (see section \ref{sec:implementation_aspects})
is that we can work only with distributions $\omega(t)$ that have rational moments.
However, in case of the most important distributions used as weight functions for
defining the Legendre, Chebyshev, Laguerre and Hermite orthogonal polynomials this
is a well known truth and summarized in table \ref{eq:orthogonal_polynomials} below.

\begin{savenotes}
\begin{table}[h!]
  \centering
  \begin{tabular}{|l|l|l|l|}
    \hline
    Distribution  & $\omega(t)$    & $t \in \Omega$      & Polynomial $P_n(t)$ \\
    \hline
    Uniform       & $1$            & $[-1, 1]$           & Legendre $P_n$ \\
    Chebyshev $T$ & $\frac{1}{\sqrt{1-x^2}}$ & $[-1, 1]$ & Chebyshev $T_n$ \\
    Chebyshev $U$\footnote{The Wigner semicircle distribution up to normalization.}
                  & $\sqrt{1-x^2}$ & $[-1, 1]$           & Chebyshev $U_n$ \\
    Exponential   & $\exp(-t)$     & $[0, \infty]$       & Laguerre $L_n$ \\
    Normal        & $\exp(-t^2)$   & $[-\infty, \infty]$ & Hermite $H_n$ \\
    Normal        & $\exp\!\left(-\frac{t^2}{2}\right)$
                  & $[-\infty, \infty]$                  & Hermite $H_n$ \\
    \hline
  \end{tabular}
  \caption{\label{eq:orthogonal_polynomials}
  Domain and weight function of classical orthogonal polynomials.}
\end{table}
\end{savenotes}

By explicit computation one can easily show that the following closed
form expressions for the moments hold:

\begin{savenotes}
\begin{align} \label{eq:moments_explicit}
  \int_{-1}^{1} t^n \di{t} & = \frac{1 + (-1)^n}{n + 1} =
  \begin{cases}
    \frac{2}{n + 1} & \quad n \quad \mathrm{even} \\
    0               & \quad n \quad \mathrm{odd}
  \end{cases} \label{eq:moments_legendre} \\
  \int_{-1}^{1} t^n \frac{1}{\sqrt{1-t^2}} \di{t} & =
  \begin{cases}
    \frac{2 \sqrt{\pi}}{n} \frac{\Gamma\left(\frac{n+1}{2}\right)}
                                {\Gamma\left(\frac{n}{2}\right)} & \quad n \quad \mathrm{even}
                                                                   \footnote{For $n=0$ one takes the limes.} \\
    0                                                            & \quad n \quad \mathrm{odd}
  \end{cases} \label{eq:moments_chebyshevt} \\
  \int_{-1}^{1} t^n \sqrt{1-t^2} \di{t} & =
    \begin{cases}
      \frac{\sqrt{\pi}}{2} \frac{\Gamma\left(\frac{n+1}{2}\right)}
                                {\Gamma\left(2+\frac{n}{2}\right)} & \quad n \quad \mathrm{even} \\
      0                                                            & \quad n \quad \mathrm{odd}
  \end{cases} \label{eq:moments_chebyshevu} \\
  \int_{0}^{\infty} t^n \exp(-t) \di{t} & = \Gamma\left(n + 1\right) \label{eq:moments_laguerre} \\
  \int_{-\infty}^{\infty} t^{n} \exp\left(-\frac{t^{2}}{2}\right) \di{t} & =
  \begin{cases}
    2^{\frac{n}{2}} \sqrt{2} \,\Gamma\left(\frac{n+1}{2}\right) & \quad n \quad \mathrm{even} \\
    0                                               & \quad n \quad \mathrm{odd}
  \end{cases} \label{eq:moments_hermite_pro} \\
  \int_{-\infty}^{\infty} t^n \exp(-t^2) \di{t} & =
  \begin{cases}
    \Gamma\left(\frac{n + 1}{2}\right) & \quad n \quad \mathrm{even} \\
    0                                  & \quad n \quad \mathrm{odd}
  \end{cases} \label{eq:moments_hermite_phy}
\end{align}
\end{savenotes}

In the case of the Hermite polynomial we find that for even $n$:

\begin{equation}
  \Gamma\left(\frac{n + 1}{2}\right) =
  \frac{\sqrt{\pi}}{2^{\frac{n}{2}}} \prod_{i=1}^{\frac{n}{2}} (2 i - 1)
\end{equation}

The constant transcendental factor $\sqrt{\pi}$ will luckily drop out in our final equations
because it is contained in every entry of the matrix $\mat{A}$ as well as the right hand
side $\vec{r}$. This is a trick that allows us to omit any constant irrational or transcendental
factor.

\begin{algorithm}
  \caption{Compute an extension $E_p$ of degree $p$ over $P_n$}
  \label{alg:find_extension}
  \begin{algorithmic}
    \Procedure{ComputeExtension}{$P_n(x)$, $p$}
    \State $\mat{A} := \textsc{BuildMatrix}(P_n, p)$
    \Comment Construct the linear system as in \eqref{eq:linsys_for_extension}
    \State $\vec{r} := \textsc{BuildRHS}(P_n, p)$
    \State $\{a_i\}_{i=0}^{p-1} := \textsc{SolveLinear}(\mat{A}, \vec{r})$
    \If{$\exists i: a_i \neq 0$}
    \Comment Check if system is solvable
      \State $E_p = t^p + \sum_{i=0}^{p-1} a_i t^i$
    \Else
      \State $E_p \equiv 0$
    \EndIf \\
    \Return $E_p$
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}
  \caption{Compute a tower of $k$ extensions
           $P_n \subset E_{p_1} \subset E_{p_2} \subset \ldots \subset E_{p_k}$ }
  \label{alg:find_multiextension}
  \begin{algorithmic}
    \Procedure{ComputeExtensionTower}{$P_n(x)$, $[p_1, \ldots, p_k]$}
    \State $P_0 := P_n$
    \For{$i = 1, \ldots, k$}
      \State $E_i := \textsc{ComputeExtension}(P_{i-1}, p_i)$
      \State $P_i := P_{i-1} \cdot E_i$
    \EndFor \\
    \Return $E := \prod_{i=1}^k E_i$
    \EndProcedure
  \end{algorithmic}
\end{algorithm}


\subsection{Computing nodes}

Computing the nodes amounts to finding all roots of a possibly high degree
polynomial. In classical numerics there are various stability issues related
to this task and a general solution is often not possible. Using arbitrary precision
ball arithmetic as defined by van der Hoeven in \cite{vdH:ball:greifswald, vdH:ball}
we can avoid almost all these issues by just increasing the precision
whenever necessary. By making use of the rigorous error bounds inherent in any ball
we can easily decide when we have to increase precision to obtain fully accurate
results in the end.

However it should not be neglected that this comes at a higher cost in computation time
compared to normal floating point arithmetic. Even though \texttt{arb} is highly optimized,
computing roots to a high working precision can take a long time.

The following routine is shown here just for the sake of completeness. Internally
we pass on by calling a suitable function from the \texttt{arb} library. The function
called uses the Durand-Kerner method according the the library documentation. An
assumption required is that the polynomial is square-free which is necessary for
all valid extensions anyway.

\begin{algorithm}
  \caption{Compute the nodes up to a given precision $b_{\gamma}$}
  \begin{algorithmic}
    \Procedure{ComputeNodes}{$P_n(x)$, $b_{\gamma}$}
    \State $\{\gamma_i\}_{i=1}^{n} := \textsc{FindAllRoots}(P_n(x), b_{\gamma})$ \\
    \Return $\{\gamma_i\}_{i=1}^{n}$
    \EndProcedure
  \end{algorithmic}
\end{algorithm}


\subsection{Computing weights}

In this section we will look at the computation of weights in more detail.
Although not really complicated a systematic understanding is inevitable for
a correct implementation.

Given a set of nodes $\{\gamma_i\}_{i=1}^{n} \in \mathbb{R}$ we want
to find the corresponding weights $\vec{\omega} := \{\omega_i\}_{i=1}^{n} \in \mathbb{R}$.
We start with the equation \eqref{eq:linsys_for_weights} shown above:

\begin{equation}
  \sum_{i=1}^{n} \omega_i \gamma_i^k = \int_{\Omega} t^k \omega(t) \di{t} \,,
  \quad k = 0, \ldots, n-1
\end{equation}

This yields the following inhomogeneous linear system $\mat{A} \vec{\omega} = \vec{r}$:

\begin{equation}
  \begin{bmatrix}
    \gamma_1^0     & \hdots & \gamma_i^0     & \hdots & \gamma_n^0 \\
    \vdots         & {}     & \vdots         & {}     & \vdots \\
    \gamma_1^k     & \hdots & \gamma_i^k     & \hdots & \gamma_n^k \\
    \vdots         & {}     & \vdots         & {}     & \vdots \\
    \gamma_1^{n-1} & \hdots & \gamma_i^{n-1} & \hdots & \gamma_n^{n-1}
  \end{bmatrix}
  \begin{pmatrix}
    \omega_1 \\
    \vdots \\
    \omega_i \\
    \vdots \\
    \omega_n
  \end{pmatrix}
  =
  \begin{pmatrix}
  \int_{\Omega} t^0 \omega(t) \,\di{t} \\
  \vdots \\
  \int_{\Omega} t^k \omega(t) \,\di{t} \\
  \vdots \\
  \int_{\Omega} t^{n-1} \omega(t) \,\di{t}
  \end{pmatrix}
\end{equation}

where $k = 0, \ldots, n-1$ is the row index and $i = 1, \ldots, n$
is the column index of the matrix $\mat{A}$. This system is square
and of shape $n \times n$. Theorem \ref{th:existence_weights} assures there is
a unique solution. Given that the nodes are in general algebraic numbers
and can not be resolved formally we computed approximations by complex
balls. Even in case we knew the nodes in closed form, there is obviously
no way to solve this system within the rationals and we would have to resort
to the algebraic number field. Therefore we approximate the weights by complex
balls the same way. Computing the solution vector $\vec{\omega}$ to a target
precision of $b_{\omega}$ bits is actually not straight forward. The reason is
that we know the nodes with a precision of $b_{\gamma}$ bits only. It can then
happen that this is not precise enough to solve the system and retrieve $b_{\omega}$
bits for the weights.

The way out of this dilemma consist of an iterative ansatz. First we try to
solve the system and then check the precision $b_{\omega}^{\prime}$ of the
weights. If $b_{\omega}^{\prime} \geq b_{\omega}$ then the precision goal was
met and we can stop. Otherwise we double the required precision
$b_{\gamma}^{\prime} := 2 b_{\gamma}$ and recompute the nodes first. After
that we can retry solving this system and see if the precision goal is met
this time. If not we let the algorithm iterate until the goal of $b_{\omega}$ bits
is eventually fulfilled or an upper bound hit. The procedure is shown in pseudo-code
in listing \ref{alg:compute_weights}.

\begin{algorithm}
  \caption{Compute the weights up to a given precision $b_{\omega}$}
  \label{alg:compute_weights}
  \begin{algorithmic}
    \Procedure{ComputeWeights}{$P_n(x)$, $\omega(t)$, $b_{\omega}$}
      \State $b_{\gamma} := \frac{1}{2} b_{\omega}$
      \Repeat
        \State $b_{\gamma} := 2 b_{\gamma}$
        \State $\{\gamma_i\}_{i=1}^{n} := \textsc{ComputeNodes}(P_n(x), b_{\gamma})$
        \State $\mat{A} := \textsc{BuildMatrix}(\{\gamma_i\}_{i=1}^{n})$
        \State $\vec{r} := \textsc{BuildRHS}(\omega(t))$
        \State $\{\omega_i\}_{i=1}^{n} := \textsc{SolveLinear}(\mat{A}, \vec{r})$
        \State $b^{\prime}_{\omega} := \textsc{CheckAccuracy}(\{\omega_i\}_{i=1}^{n})$
      \Until{$b^{\prime}_{\omega} \geq b_{\omega}$} \\
      \Return $\{\omega_i\}_{i=1}^{n}$
    \EndProcedure
  \end{algorithmic}
\end{algorithm}


\section{Implementation aspects}
\label{sec:implementation_aspects}

The whole algorithm is implemented in \texttt{C} and relies heavily
on the computational number theory library \texttt{flint} \cite{flint, Hart2010}.
This library provides among many other things highly efficient exact rational
numbers with arbitrary large numerator and denominator integers. Therefore we
have the complete arithmetics of the field $\mathbb{Q}$ available. It also
implements the polynomial rings $\mathbb{Z}[x]$ and $\mathbb{Q}[x]$ and hence we
can compute and express the polynomials defining the nodes of our nested extension
tower. There are at least two reasons we require an efficient implementation of
$\mathbb{Q}[x]$. First we need to be able to do fast arithmetics with polynomials,
specifically multiplication and checking whether a given polynomial is indeed square-free.
Second, the coefficients grow exponentially large and we must use arbitrary precision
rational numbers for expressing them. Other things we use from \texttt{flint} are
matrices over $\mathbb{Q}$. The matrices provide us with means to solve linear systems
by rational arithmetic using a specially adapted fraction free version of Gauss elimination.

Given all that we can check whether an extension $E_p$ to any given rule $P_n$
exists by using only exact rational arithmetic. The price we pay is that we can
handle only distributions $\omega(t)$ that have rational moments.


\marginpar{How do we solve the things}
\marginpar{Some words about the arbitrary precision ansatz}
\marginpar{And a few words about rigorous errors bounds of balls}

\marginpar{
\cite{flint}
\cite{Hart2010}
\cite{arb}
}


\section{Direct single extensions}

In this section we will consider only single Kronrod extensions. Given a polynomial
$P_n$ of either Legendre or Laguerre or Hermite type and of degree $n$, we compute
the extension $E_p$ of order $p$ for some suitable choice of $p$. We make use of algorithm
\ref{alg:find_extension} to obtain the polynomial $E_p$ defining the extension in
the first place. Next we compute nodes and weights. If requested, validity checks
are performed to ensure that the nodes are within the region of integration:
\begin{equation}
  \forall i = 1, \ldots, n+p: \gamma_i \in \Omega \subseteq \mathbb{R}
\end{equation}
and that the weights are positive:
\begin{equation}
  \forall i = 1, \ldots, n+p: \omega_i > 0 \,.
\end{equation}

Since the aim of this work is an exhaustive search for valid rules we apply
this computation for a series of increasing $n$ and test all $p$ up to some
upper bound. This then guarantees that we have found all extensions of
some given Gauss type rule $P_n$ up to extension order $p_{\textrm{max}}$.
To cover as much as possible the range of rules used in practice we set
$n_{\mathrm{max}} = 100$ and also $p_{\textrm{max}} = 100$. In the extreme case
there is now a polynomial of degree $200$ defining a rule with the same number
of node-weight pairs.

\begin{algorithm}
  \caption{Exhaustive search up to $n_{\textrm{max}}$ and $p_{\textrm{max}}$}
  \label{alg:compute_weights}
  \begin{algorithmic}
    \Procedure{ExhaustiveSearch}{$n_{\textrm{max}}$, $p_{\textrm{max}}$}
      \State $\mat{M} \in \{0,1\}^{n \times p}$
      \Comment Bitmap for storing the found rules
      \For{$n = 1, \ldots, n_{\textrm{max}}$}
        \State Get $P_n(t)$
        \Comment Suitable orthogonal polynomial of order $n$
        \For{$p = n+1, \ldots, p_{\textrm{max}}$}
          \State $E_p := \textsc{ComputeExtension}(P_n, p)$
          \If{$E_p \not\equiv 0$}
            \State $\mat{M}_{n,p} := 1$
          \Else
            \State $\mat{M}_{n,p} := 0$
          \EndIf
        \EndFor
      \EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

The output of this algorithm applied to the three polynomial classes mentioned
above is shown in the figures \ref{fig:map_leg_100_100}, \ref{fig:map_lag_20_100}
and \ref{fig:map_herm_50_100}.


\marginpar{Some explanation for each polynomial case}
\marginpar{todo: replot with negative weights included}
\marginpar{Consider even larger maps?}


\subsection{Existence and non-existence results}

From the rather sparse theory on this subject we know only of very few rigorous
existence results for Kronrod-Patterson extensions.

In the Legendre case there is a proof saying that for each $n$ there is
always an extension with $p = n + 1$ \cite{szegoe}. This is recovered by our
computation and shows up in figure \ref{fig:map_leg_100_100} as the first upper
diagonal line. Additionally to their existence, these rules also have positive
weights in all cases as shown in \cite{monegato1978}. The existence theorems can
be generalized to hold also for Chebycheff, Gegenbauer and ultimatively Jacobi
polynomials \cite{gautschi-notaris, gautschi, notaris1990, monegato1978_2}.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{./img/map_leg_100_100.png}
  \caption{Map of the extensions $E_p$ of Gauss-Legendre quadrature rules
           $P_n$ for $n \leq 100$ and $p$ up to $100$.}
  \label{fig:map_leg_100_100}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{./img/map_chebt_50_50.png}
  \caption{Map of the extensions $E_p$ of Gauss-Chebyshev quadrature rules
           $T_n$ for $n \leq 50$ and $p$ up to $50$.}
  \label{fig:map_chebt_50_50}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{./img/map_chebu_50_50.png}
  \caption{Map of the extensions $E_p$ of Gauss-Chebyshev quadrature rules
           $U_n$ for $n \leq 50$ and $p$ up to $50$.}
  \label{fig:map_leg_100_100}
\end{figure}

For Laguerre polynomials there are no classical Kronrod extensions with $p = n+1$
at all. Higher order extensions are very sparse too, we could not find extensions
for any $12 < n \leq 100$ while keeping $p \leq 150$. There is no strong reason to
believe this would change if allowing for even higher $p$. Apart from that, such
rules would probably be of no practical use anyway.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{./img/map_lag_20_100.png}
  \caption{Map of the extensions $E_p$ of Gauss-Laguerre quadrature rules
           $L_n$ for $n \leq 20$ and $p$ up to $100$. The part from
           $20 < n \leq 100$ not shown here does not contain any single
           valid extension.}
  \label{fig:map_lag_20_100}
\end{figure}

In the case of Hermite polynomials our computation indeed reveals the three possible
classical Kronrod rules for $n=1, p=2$ and $n = 2, p = 3$ and $n = 4, p = 5$. This
can be seen in the very top left corner of figure \ref{fig:map_herm_50_100} and is
in perfect agreement with the literature \cite{monegato1976, kahaner-monegato, vladislav}.
In fact if we examine the three rules more closely, we will find that the case
$n = 4, p = 5$ does not have positive weights and is in turn ruled out by the
authors of the aforementioned papers.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{./img/map_herm_50_100.png}
  \caption{Map of the extensions $E_p$ of Gauss-Hermite quadrature rules
           $H_n$ for $n \leq 50$ and $p$ up to $100$. The part from
           $50 < n \leq 100$ not shown here does not contain any single
           valid extension.}
  \label{fig:map_herm_50_100}
\end{figure}


\section{Recursive enumeration of quadrature rules}


In the last section we computed a single extensions $E_p$ over a
given rule. This is enough in case of adaptive quadrature where all one
wants is to make an error estimate of the Gaussian quadrature by evaluation
of another quadrature rule having higher order. In that case the property of
nested nodes $\{\gamma_i\}_{i=1}^n \subset \{\gamma_i\}_{i=1}^{n+p}$ can reduce
computation cost.

Another use case however is the construction of quadrature
rules for higher dimensional integrals. For the number of dimensions in the
range from $4$ up to some ten this can be done efficiently by the well known
Smolyak construction.




\marginpar{About extension towers}
\marginpar{Tree graphs go here}
\marginpar{Table of some of the most interesting rules}

\marginpar{
cite smolyak, complexity bound in nesting
}



\section{Genz-Keister Construction}


Genz and Keister found an explicit construction by which efficient
special quadrature rules for an arbitrary number
of dimensions can be built. The resulting rules are
called \emph{fully-symmetric} for reasons that will become
clear later. In this section we review this construction of Genz
and Keister as given in \cite{genz, genz_keister}. We follow mostly their
development but focus mainly on the computational aspects and less
the theoretical derivation. Additionally we extend the construction
to Gauss-Chebyshev quadrature (both kinds) and analyze the resulting rules.


\subsection{The construction}

The quadrature rule $Q^{D,K}$ of \emph{level} $K \geq 0$ and
for use in $D$ dimensions is defined as:
\begin{equation} \label{eq:gk_basic_formula}
  \int_\Omega f(\vec{x}) \di{x} =:
  I[f] \approx Q^{D,K}[f]
       := \sum_{\mathbf{p} \in \mathcal{P}}
            f\left(\Gamma_{\mathbf{p}}\right)
            \omega_{\mathbf{p}}
\end{equation}
where $\mathcal{P}$ is the set of all integer partitions as defined below.
The node sets $\Gamma$ and weights $\omega$ are indexed by partitions
$\mathbf{p} \in \mathcal{P}$.
Define the set $\mathcal{P}$ of all admissible integer partitions
$\mathbf{p} := (\mathbf{p}_{1}, \ldots, \mathbf{p}_{D}) \in \mathbb{N}_{0}^{D}$
having $D$ parts (some of which can be zero) and $|\mathbf{p}| \leq K$
with $K \geq 0$ as:
\begin{equation} \label{eq:partition_set_def}
  \mathcal{P} :=
  \left\{
    \mathbf{p} \,
    \middle| K \geq \mathbf{p}_{1} \geq \cdots \geq \mathbf{p}_{D} \geq 0
    \wedge
    |\mathbf{p}| \leq K
  \right\}
  \,.
\end{equation}
An algorithm for computing that set $\mathcal{P}$
is shown in \eqref{alg:ca_enumerate_integer_partitions}.
Before we look deeper into the details of this construction,
we need to introduce the set $\Lambda$ of so called \emph{generators}:
\begin{equation}
  \Lambda := \{\lambda_{0}, \lambda_{1}, \ldots, \lambda_{J}\}
\end{equation}
where we require that $\lambda_{0} \equiv 0$ and all $\lambda_{i}$ be
pair-wise distinct. There are obviously $J+1$ real non-negative generators.
A single quadrature point $\gamma \in \mathbb{R}^D$ is then an ordered
multiset of size $D$ of elements from $\Lambda$. Note that $\gamma$ is not
just a subset because elements are allowed to appear multiple times. The
specific items are then selected by an integer vector $\mathbf{k} \in \mathbb{N}_0^D$,
explicitly:
\begin{equation}
  \gamma_\mathbf{k} := \Lambda_\mathbf{k} = \left(\lambda_{k_1}, \ldots, \lambda_{k_D}\right) \,.
\end{equation}
We define $\delta$ as the number of components of $\gamma_\mathbf{k}$ that are 0.
As we require that only $\lambda_0$ is zero, $\delta$ is equivalent to the number
of zeros in $\mathbf{k}$.
Next we define the set $\overline{\gamma_\mathbf{k}}$ containing all
possible sign flips:
\begin{equation}
  \overline{\gamma_\mathbf{k}} \assign
  \sigma \gamma_\mathbf{k} =
  \{
  \left(\sigma_1 \gamma_1, \ldots, \sigma_D \lambda_D\right)
  \}_{\sigma \in \{-1,0,1\}^D}
\end{equation}
where $\sigma_d \in \{-1, 1\}$ or $\sigma_d = 0$ if and only if $\gamma_d = 0$.
The point $\gamma_\mathbf{k}$ gets mirrored into all $2^D$ orthants by $\sigma$.
Clearly, this set $\overline{\gamma_\mathbf{k}}$ is of size $2^{D-\delta}$ for
the reason that some points coincide with their own mirror images.

At this point we can go back and understand
the notation of equation \eqref{eq:gk_basic_formula}
where $\Gamma_\mathbf{p}$ stands for a whole set of nodes given by:
\begin{equation}
  \Gamma_\mathbf{p} \assign
  \bigcup_{\mathbf{q} \in \mathcal{S}_\mathbf{p}} \overline{\gamma_\mathbf{q}}
\end{equation}
and $\mathcal{S}_\mathbf{p}$ is the set of all permutations of the $D$
elements of $\mathbf{p} \in \mathcal{P}$. An algorithm for the enumeration
of all permutations is given in \eqref{alg:ca_enumerate_permutations}.
Finally we find:
\begin{equation}
  f\left(\Gamma_\mathbf{p}\right) \assign
  \sum_{\mathbf{q} \in \mathcal{S}_p}
  \sum_{\gamma \in \overline{\gamma_\mathbf{q}}}
  f\left(\gamma_1, \ldots, \gamma_D\right) \,.
\end{equation}

What remains is the explanation of $\omega_\mathbf{p}$. The formula $(2.4)$
given in \cite{genz} looks quite simple but the efficient implementation needs
some care. For every admissible partition $\mathbf{p} \in \mathcal{P}$ the
corresponding weight can be computed by:
\begin{equation} \label{eq:gk_weight_def}
  \omega_{\mathbf{p}} := 2^{-(D-\delta)}
                         \sum_{|\mathbf{k}| \leq K - |\mathbf{p}|}
                         \prod_{d=1}^{D}
                           \frac{a_{\mathbf{k}_{d}+\mathbf{p}_{d}}}{P(\mathbf{k}_{d},\mathbf{p}_{d})}
\end{equation}
where we define the denominator:
\begin{equation} \label{eq:gk_weight_def_denom}
  P(\mathbf{k}_{d},\mathbf{p}_{d}) :=
  \prod_{\substack{i=0 \\
                   i\neq\mathbf{p}_{d}}}
       ^{\mathbf{k}_{d}+\mathbf{p}_{d}}
    \left( \lambda_{\mathbf{p}_{d}}^{2}-\lambda_{i}^{2} \right)
\end{equation}
and the multi-index $\mathbf{k} \in \mathbb{N}_{0}^{D}$. Note that the
prefactor is exactly $1 / |\overline{\gamma_\mathbf{k}}|$.
Algorithm \eqref{alg:ca_enumerate_lattice_points} implements a procedure
for enumeration of all relevant multi-indices.
This formula above presents us several parts we need to compute.
Some of these parts can even be tabulated once for a maximal and
fixed $J$ value and independent of the dimension $D$.
Let us start with the numerator. There we need the value $a_i$ which is defined
as follows:
\begin{equation} \label{eq:gk_def_ai}
  a_{i} := \int_\Omega p_{i}(x) w(x) \di{x}, \quad i = 0, \ldots, J+1
\end{equation}
and the domain $\Omega$ and the weight function $w(x)$ are chosen
appropriately (see below). The polynomials $p_{i}(x)$ are defined as:
\begin{equation}
\begin{split}
  p_{0}(x) & := 1 \\
  p_{i}(x) & := \prod_{j=0}^{i-1} \left(x^{2} - \lambda_{j}^{2}\right)
\end{split}
\end{equation}
where the empty product equals 1. It holds that $\deg p_i = 2i$.
Since all the real numbers $\lambda_{j}$ are known we can indeed
expand the product and write $p_i$ as $\sum_{j=0}^{2i} c_j x^j$
for some coefficients $c_j$. This enables us to compute the integral
in equation \eqref{eq:gk_def_ai} term-wise by using linearity:
\begin{equation}
  a_i = \sum_{j=0}^{2i} c_j \int_\Omega x^j w(x) \di{x} = \sum_{j=0}^{2i} c_j M_j
\end{equation}
where $M_j$ is the $j$-th moment and chosen according to table
\eqref{eq:orthogonal_polynomials} and the explicit formulae shown thereafter.
For the Legendre, Chebyshev and Hermite case, the explicit formulae are
\eqref{eq:moments_legendre}, \eqref{eq:moments_chebyshevt}, \eqref{eq:moments_chebyshevt}
and \eqref{eq:moments_hermite_phy}.
Optionally we can replace very small values by zero. As we will see later
it is important to be able to decide whether $a_{i} = 0$. Because we
compute with real numbers (either floating point numbers or real ball arithmetic)
we can however never solve this problem exactly like in rational arithmetics.

\begin{algorithm}[h!]
  \caption{Compute table $\vec{A}$ of $a_{i}$ factors}
  \label{alg:gk_compute_weight_factors}
  \begin{algorithmic}
    \Procedure{ComputeAValues}{$\Lambda$, $M_{j}$}
      \State $\vec{A} := \vec{0} \in \mathbb{R}^{J+1}$
      \State $p := 1$
      \For{$i=0, \ldots, J+1$}
        \State $a := 0$
        \For{$d = 0, \ldots, \deg p$}
          \State $a := a + \textsc{Coefficient}(p, d) \, M_d$
        \EndFor
        \State $\vec{A}_i := a$
        \State $p := p \left(x^2 - \lambda_i^2\right)$
      \EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

Computing the denominator as defined in \eqref{eq:gk_weight_def_denom}
is straight forward. Since we required the $\lambda_i$ to be pairwise
distinct this value never becomes zero and division poses no issue.

We notice that the product in formula \eqref{eq:gk_weight_def} only depends on
$\mathbf{p}_{d} =: \xi$ and the sum $\mathbf{p}_{d}+\mathbf{k}_{d} =: \eta$.
Therefore we can precompute a table of size $J+1 \times J+1$ indexed by $(\xi, \eta)$
whose entries are given by:
\begin{equation}
  \mat{T}_{\xi, \eta} := \frac{a_{\mathbf{k}_{d}+\mathbf{p}_{d}}}{P(\mathbf{k}_{d},\mathbf{p}_{d})} \,.
\end{equation}
In the example below the top left corner of $\mat{T}$ is shown and we only
ever need the upper right triangular part:

\begin{center}
\begin{tabular}{|c|cccc|}
  \hline
  {}    & $\eta=0$ & $\eta=1$ & $\eta=2$ & $\eta=3$ \\
  \hline
  $\xi=0$ & $\frac{a_0}{1}$
          & $\frac{a_1}{(\lambda_0^2-\lambda_1^2)}$
          & $\frac{a_2}{(\lambda_0^2-\lambda_1^2)(\lambda_0^2-\lambda_2^2)}$
          & $\frac{a_3}{(\lambda_0^2-\lambda_1^2)(\lambda_0^2-\lambda_2^2)(\lambda_0^2-\lambda_3^2)}$ \\
  $\xi=1$ & 0
          & $\frac{a_1}{(\lambda_1^2-\lambda_0^2)}$
          & $\frac{a_2}{(\lambda_1^2-\lambda_0^2)(\lambda_1^2-\lambda_2^2)}$
          & $\frac{a_3}{(\lambda_1^2-\lambda_0^2)(\lambda_1^2-\lambda_2^2)(\lambda_1^2-\lambda_3^2)}$ \\
  $\xi=2$ & 0
          & 0
          & $\frac{a_2}{(\lambda_2^2-\lambda_0^2)(\lambda_2^2-\lambda_1^2)}$
          & $\frac{a_3}{(\lambda_2^2-\lambda_0^2)(\lambda_2^2-\lambda_1^2)(\lambda_2^2-\lambda_3^2)}$ \\
  $\xi=3$ & 0
          & 0
          & 0
          & $\frac{a_3}{(\lambda_3^2-\lambda_0^2)(\lambda_3^2-\lambda_1^2)(\lambda_3^2-\lambda_2^2)}$ \\
  \hline
\end{tabular}
\end{center}

Given the list $\Lambda$ of generators and all the values $a_{i}$ collected into
the list $\vec{A}$we can compute the table $\mat{T}$ efficiently by algorithm
\eqref{alg:gk_compute_weight_factors}. By the use of this table, the implementation
of formula \eqref{eq:gk_weight_def} transforms into a series of trivial table
look-up steps. However, precomputation of $\mat{T}$ is expensive for larger $J$
but on the other hand needs to be done only once for each $\Lambda$ and $w(x)$.

\begin{algorithm}[h!]
  \caption{Compute table $\mat{T}_{\xi,\eta}$ of weight factors}
  \label{alg:gk_compute_weight_factors}
  \begin{algorithmic}
    \Procedure{WeightFactors}{$\Lambda$, $\{a_{0},\ldots,a_{n+1}\}$}
      \State $n := |\Lambda|$
      \State $\mat{T} \in \mathbb{R}^{n\times n}$
      \Comment Compute $T$ row by row
      \For{$\xi = 0, \ldots, n-1$}
        \State $t := 1$
        \For{$\eta = 0, \ldots, n-1$}
          \If{$\xi \neq \eta$}
            \State $t := t \left(\lambda_{\xi}^{2} - \lambda_{\eta}^{2}\right)$
          \EndIf
          \If{$\eta \geq \xi$}
            \State $\mat{T}_{\xi,\eta} := \frac{a_{\eta}}{t}$
          \EndIf
        \EndFor
      \EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}


% Z sequence

% compute_z_sequence(const ai_t& A) {
%     /* Precompute the Z-sequence
%      *
%      * A: Table with precomputed a_i values
%      */
%     int n = arb_mat_ncols(&A);
%
%     std::vector<int> Z(0);
%
%     int v = 0;
%     for(int i=0; i < n; i++) {
%         if(v == 0) {
%             while( arb_is_zero(arb_mat_entry(&A, 0, i+v)) ) {
%                 v++;
%             }
%         } else {
%             v--;
%         }
%         Z.push_back(v);
%     }
%     return Z;

At the end of the day we arrive at the following two algorithms
\eqref{alg:gk_compute_nodes} and \eqref{alg:gk_compute_weights}
for computing the node set $\Gamma_\mathbf{p}$ and weights $\omega_\mathbf{p}$
for an arbitrary given partition $\mathbf{p} \in \mathcal{P}$.

\begin{algorithm}[h!]
  \caption{Compute nodes $\Gamma_\mathbf{p}$ for given $\mathbf{p} \in \mathcal{P} \subset \mathbb{N}_0^D$}
  \label{alg:gk_compute_nodes}
  \begin{algorithmic}
    \Procedure{Nodes}{$\mathbf{p}$, $\Lambda$}
      \State $\Gamma_\mathbf{p} := \{\}$
      \State $\delta := \textsc{NumberOfZeros}(\mathbf{p})$
      \State $\mathcal{S} := \textsc{Permutations}(D, \mathbf{p})$
      \For{$\mathbf{q} \in \mathcal{S}$}
        \For{$v = 0, \ldots, 2^{(D - \delta)}-1$}
          \State $u := 0$
          \For{$d = 0, \ldots, D-1$}
            \State $\gamma_d := \Lambda_{\mathbf{q}_d}$
            \If{$\mathbf{q}_d \neq 0$}
              \Comment Compute sign flip
              \If{$\lfloor\frac{v}{2^u}\rfloor \mod 2 = 1$}
                \State $\gamma_d := - \gamma_d$
              \EndIf
              \State $u := u + 1$
            \EndIf
          \EndFor
          \State $\Gamma_\mathbf{p} := \Gamma_\mathbf{p} \cup \gamma$
        \EndFor
      \EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}


\begin{algorithm}[h!]
  \caption{Compute weight $\omega_\mathbf{p}$ for given $\mathbf{p} \in \mathcal{P} \subset \mathbb{N}_0^D$}
  \label{alg:gk_compute_weights}
  \begin{algorithmic}
    \Procedure{Weights}{$\mathbf{p}$, $K$, $\mat{T}$}
      \State $\delta := \textsc{NumberOfZeros}(\mathbf{p})$
      \State $\omega_\mathbf{p} := 0$
      \State $\mathcal{L} := \textsc{EnumerateLatticePoints}(D, K - |\mathbf{p}|)$
      \For{$\mathbf{k} \in \mathcal{L}$}
        \State $w := 1$
        \For{$d = 0, \ldots, D-1$}
          \State $w := w \, \mat{T}_{\mathbf{p}_d, \mathbf{k}_d + \mathbf{p}_d}$
        \EndFor
        \State $\omega_\mathbf{p} := \omega_\mathbf{p} + w$
      \EndFor
      \State $\omega_\mathbf{p} := 2^{-(D-\delta)} \omega_\mathbf{p}$
    \EndProcedure
  \end{algorithmic}
\end{algorithm}


\subsubsection{Combinatorial Algorithms}


In this section we summarize the combinatorial algorithms that
can be used during the Genz-Keister construction. In the programming
language \texttt{python} they can be implemented very efficiently by
the use of \texttt{yield} inside so called \emph{generator expressions}.

The algorithm \eqref{alg:ca_enumerate_integer_partitions} can
be used for enumeration of the set $\mathcal{P}$ defined in
\eqref{eq:partition_set_def}. This works for any given value
of $D \geq 1$ and maximal element size $K \geq 0$. The elements
$\mathbf{p} \in \mathcal{P}$ will be generated by increasing value
of $|\mathbf{p}|$ until the boundary $K$ is hit.

\marginpar{Cite partition paper}

\begin{algorithm}[h!]
  \caption{Enumerate the set $\mathcal{P}$ of all integer partitions}
  \label{alg:ca_enumerate_integer_partitions}
  \begin{algorithmic}
    \Procedure{EnumeratePartitions}{$D$, $K$}
      \State $\mathcal{P} := \{\}$
      \State $\mathbf{p} := \vec{0} \in \mathbb{N}_{0}^{D}$
      \While{$|\mathbf{p}| \leq K$}
        \State $\tau := \mathrm{false}$
        \State $p := \mathbf{p}_{0}$
        \For{i = 1, \ldots D-1}
          \State $p := p + \mathbf{p}_i$
          \If{$\mathbf{p}_{0} \leq \mathbf{p}_{i} + 1$}
            \State $\mathbf{p}_{i} := 0$
          \Else
            \State $\mathbf{p}_{0} := p - i (\mathbf{p}_{i} + 1)$
            \For{j = 1, \ldots, i}
              \State $\mathbf{p}_{j} := \mathbf{p}_{i} + 1$
            \EndFor
            \State $\mathcal{P} := \mathcal{P} \cup \mathbf{p}$
            \State $\tau := \mathrm{true}$
            \State \bf{break}
          \EndIf
        \EndFor
        \If{$\tau = \mathrm{false}$}
          \State{$\mathbf{p}_{0} := p + 1$}
          \If{$|\mathbf{p}| \leq K$}
            \State $\mathcal{P} := \mathcal{P} \cup \mathbf{p}$
          \EndIf
        \EndIf
      \EndWhile
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

An algorithm to enumerate the set $\mathcal{S}$ of all entry-wise
permutations of a given vector $\mathbf{p} \in \mathbb{N}_{0}^{D}$
is shown next in \eqref{alg:ca_enumerate_permutations}. This algorithm
will generate the permutations in reverse lexicographic order,
starting with $\mathbf{p}$.

\begin{algorithm}[h!]
  \caption{Enumerate the set $\mathcal{S}$ of all permutations
    of the entries of $\mathbf{p} \in \mathbb{N}_{0}^{D}$}
  \label{alg:ca_enumerate_permutations}
  \begin{algorithmic}
    \Procedure{Permutations}{$D$, $\mathbf{p}$}
      \State $\mathcal{S} := \{\mathbf{p}\}$
      \State $\tau := \mathrm{true}$
      \While{$\tau = \mathrm{true}$}
        \State $\tau := \mathrm{false}$
        \For{$i = 1, \ldots, D-1$}
          \State $p := \mathbf{p}_{i}$
          \If{$\mathbf{p}_{i-1} > p$}
            \State $I := i$
            \If{$i > 1$}
              \State $J := I$
              \For{$j = 0, \ldots, \lfloor \frac{I}{2} \rfloor -1 $}
                \State $q := \mathbf{p}_{j}$
                \If{$q \leq p$}
                  \State $I := I - 1$
                \EndIf
                \State $\mathbf{p}_{j} := \mathbf{p}_{i-j-1}$
                \State $\mathbf{p}_{i-j-1} := q$
                \If{$\mathbf{p}_{j} > p$}
                  \State $J := j + 1$
                \EndIf
              \EndFor
              \If{$\mathbf{p}_{I-1} \leq p$}
                \State $I := J$
              \EndIf
            \EndIf
            \State $\mathbf{p}_{i} := \mathbf{p}_{I-1}$
            \State $\mathbf{p}_{I-1} := p$
            \State $\mathcal{S} := \mathcal{S} \cup \mathbf{p}$
            \State $\tau := \mathrm{true}$
            \State \bf{break}
          \EndIf
        \EndFor
      \EndWhile
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

In the definition of the weights in formula \eqref{eq:gk_weight_def}
we need to iterate over the set $\mathcal{L} := \{\mathbf{k}_{i}\}_{i}$ of all
lattice points $\mathbf{k} \in \mathbb{N}_{0}^{D}$ up to some maximal value of
the $l_{1}$ norm. The algorithm \eqref{alg:ca_enumerate_lattice_points}
shows an efficient method for the enumeration of all such points. It
is well known that the cardinality of $\mathcal{L}$ is:
\begin{equation}
  |\mathcal{L}| = \left(\frac{K+1}{D}\right) \binom{D+K}{K+1} \,.
\end{equation}
For more details see for example \cite{serra-sagrista}.

\begin{algorithm}[h!]
  \caption{Enumerate lattice points in $\{\mathbf{k_{i}}\}_{i} =: \mathcal{L} \subset \mathbb{N}_{0}^{D}$
    with $\|\mathbf{k_{i}}\|_{1} \leq N$}
  \label{alg:ca_enumerate_lattice_points}
  \begin{algorithmic}
    \Procedure{EnumerateLatticePoints}{$D$, $N$}
      \State $\mathcal{L} := \{\} $
      \For{$n = 0, \ldots, N$}
        \State $\mathbf{k} := \vec{0} \in \mathbb{N}_{0}^{D}$
        \State $\mathbf{k}_{0} := n$
        \State $\mathcal{L} := \mathcal{L} \cup \mathbf{k}$
        \State $c := 1$
        \While{$\mathbf{k}_{D-1} < n$}
          \If{$c = D$}
            \For{$i = c-1, \ldots, 1$}
              \State $c := i$
              \If{$\mathbf{k}_{i-1} \neq 0$}
                \State \bf{break}
              \EndIf
            \EndFor
            \State $\mathbf{k}_{c-1} := \mathbf{k}_{c-1} - 1$
            \State $c :+ c +1$
            \State $\mathbf{k}_{c-1} := n$
            \For{$i = 0, \ldots, c-2$}
              \State $\mathbf{k}_{c-1} := \mathbf{k}_{c-1} - \mathbf{k}_{i}$
            \EndFor
            \If{$c < D$}
              \For{$i = c, \ldots, D-1$}
                \State $\mathbf{k}_{i} := 0$
              \EndFor
            \EndIf
            \State $\mathcal{L} := \mathcal{L} \cup \mathbf{k}$
          \EndIf
        \EndWhile
      \EndFor
    \EndProcedure
  \end{algorithmic}
\end{algorithm}


\subsection{Results}





% Number of nodes

% Gauss-Hermite compare

% Heat-maps

% Point distribution








\section{Future work}

A question is whether it would be computationally more efficient to compute
everything with arbitrary precision floating point ball arithmetic. By doing that
it might be possible to better handle the exponential growth of coefficients.
On the other hand, computing roots and solving for the weights seems to be
the most expensive part already.

By having efficient root isolation and counting algorithms in \texttt{flint} we would
not have to compute all roots of $E_p$ numerically to high precision just for answering
the question if some of them are complex hence marking the whole extension invalid
\footnote{This solution is also not fully satisfying since we can only
decide that a complex root is really complex but not if a candidate is for sure real.}.

Finally, this work is based on empirical studies on the outcome of algorithmic searches.
It would be desirable to have a rigorous mathematical foundation for the claims made.


\marginpar{
\cite{szegoe}
\cite{gautschi}
\cite{gautschi-notaris}
\cite{monegato1978_2}
\cite{gautschi-rivlin}
\cite{monegato1982}
\cite{monegato1978_3}
}

\bibliographystyle{plain}
\bibliography{kes}

\end{document}
